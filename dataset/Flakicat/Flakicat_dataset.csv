id,project,test_name,full_code,label,category
1,hadoop,TestDelegationTokenRenewer.testAddRemoveRenewAction,"@Test
public void testAddRemoveRenewAction() throws IOException, InterruptedException {
TestFileSystem tfs = new TestFileSystem();
renewer.addRenewAction(tfs);
for (int i = 0; i < 60; i++) {
Thread.sleep(RENEW_CYCLE);
if (tfs.testToken.renewCount > 0) {
renewer.removeRenewAction(tfs);
break;
}
}
assertTrue(""Token not renewed even after 1 minute"", tfs.testToken.renewCount > 0);
assertTrue(""Token not removed"", tfs.testToken.renewCount < MAX_RENEWALS);
assertTrue(""Token not cancelled"", tfs.testToken.cancelled);
}",async wait,0
2,neo4j,RobustJobSchedulerWrapperTest.shouldBeAbleToCancelJob,"@Test
public void shouldBeAbleToCancelJob() throws Exception {
RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper(actualScheduler, log);
AtomicInteger count = new AtomicInteger();
JobHandle jobHandle = robustWrapper.scheduleRecurring(""JobName"", 1, count::incrementAndGet);
assertEventually(""run count"", count::get, Matchers.greaterThanOrEqualTo(100), DEFAULT_TIMEOUT_MS, MILLISECONDS);
robustWrapper.cancelAndWaitTermination(jobHandle);
int finalCount = count.get();
Thread.sleep(50);
assertEquals(finalCount, count.get());
}",concurrency,1
3,xtext-core,RequestManagerTest.testRunWriteAfterRead,"@Test
public void testRunWriteAfterRead() {
final Function1<CancelIndicator, Integer> _function = (CancelIndicator it) -> {
return Integer.valueOf(this.sharedState.incrementAndGet());
};
this.requestManager.<Integer>runRead(_function);
final Function0<Object> _function_1 = () -> {
return null;
};
final Function2<CancelIndicator, Object, Integer> _function_2 = (CancelIndicator $0,Object $1) -> {
int _xblockexpression = ((int) (0));
{
Assert.assertEquals(1, this.sharedState.get());
_xblockexpression = this.sharedState.incrementAndGet();
}
return Integer.valueOf(_xblockexpression);
};
this.requestManager.<Object, Integer>runWrite(_function_1, _function_2).join();
Assert.assertEquals(2, this.sharedState.get());
}",concurrency,1
4,timely,MetricAdapterTest.testToMetricResponse,"@Test
public void testToMetricResponse() throws Exception {
String subscriptionId = ""12345"";
long ts = 1000L;
List<Tag> tags = new ArrayList<>();
tags.add(new Tag(""tag1"", ""value1""));
Metric m = Metric.newBuilder().name(""sys.cpu.user"").value(ts, 2.0).tags(tags).tag(VISIBILITY_TAG, ""(a&b)|(c&d)"").build();
String json = JsonUtil.getObjectMapper().writeValueAsString(MetricResponse.fromMetric(m, subscriptionId));
String expected = ""{\""metric\"":\""sys.cpu.user\"",\""timestamp\"":1000,\""value\"":2.0,\""tags\"":[{\""tag1\"":\""value1\""},{\""viz\"":\""(a&b)|(c&d)\""}],\""subscriptionId\"":\""12345\"",\""complete\"":false}"";
Assert.assertEquals(expected, json);
}",unordered collections,3
5,hadoop,TestPathData.testToFile,"@Test
public void testToFile() throws Exception {
item = new PathData(""."", conf);
assertEquals(new File(testDir.toString()), item.toFile());
item = new PathData(""d1/f1"", conf);
assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
item = new PathData(testDir + ""/d1/f1"", conf);
assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
}",test order dependency,4
6,dex,test_parseLString,"@Test
public void test_parseLString() throws Exception {
DateFormat format = DateFormat.getDateTimeInstance(DateFormat.FULL, DateFormat.FULL, Locale.US);
try {
Date date = format.parse(format.format(current).toString());
assertEquals(current.getDate(), date.getDate());
assertEquals(current.getDay(), date.getDay());
assertEquals(current.getMonth(), date.getMonth());
assertEquals(current.getYear(), date.getYear());
assertEquals(current.getHours(), date.getHours());
assertEquals(current.getMinutes(), date.getMinutes());
} catch(ParseException pe) {
fail(""ParseException was thrown for current Date.""); }
try {
format.parse(""January 16, 1970 8:03:52 PM CET"");
fail(""ParseException was not thrown."");
} catch(ParseException pe) { }
}",time,2
7,activemq,TempStorageBlockedBrokerTest.runProducerWithHungConsumer,"@Test
public void runProducerWithHungConsumer() throws Exception {
final long origTempUsage = broker.getSystemUsage().getTempUsage().getUsage();
ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(""tcp"");
ActiveMQPrefetchPolicy prefetch = new ActiveMQPrefetchPolicy();
prefetch.setTopicPrefetch(10);
factory.setPrefetchPolicy(prefetch);
Connection consumerConnection = factory.createConnection();
consumerConnection.start();
Session consumerSession = consumerConnection.createSession(false, AUTO_ACKNOWLEDGE);
MessageConsumer consumer = consumerSession.createConsumer(destination);
final Connection producerConnection = factory.createConnection();
producerConnection.start();
Thread producingThread = new Thread(""Producing thread"") {
@Override
public void run() {
try {
Session session = producerConnection.createSession(false, AUTO_ACKNOWLEDGE);
MessageProducer producer = session.createProducer(destination);
producer.setDeliveryMode(deliveryMode);
for (int idx = 0; idx < MESSAGES_COUNT; ++idx) {
Message message = session.createTextMessage(new String(buf) + idx);
producer.send(message);
messagesSent.incrementAndGet();
Thread.sleep(10);
LOG.info(""Sent Message "" + idx);
LOG.info(""Temp Store Usage "" + broker.getSystemUsage().getTempUsage().getUsage());
}
producer.close();
session.close();
} catch (Throwable ex) {
ex.printStackTrace();
}
}
};
producingThread.start();
int count = 0;
Message m = null;
while ((m = consumer.receive(messageReceiveTimeout)) != null) {
count++;
LOG.info(((""Recieved Message ("" + count) + ""):"") + m);
messagesConsumed.incrementAndGet();
try {
Thread.sleep(100);
} catch (Exception e) {
LOG.info(""error sleeping"");
}
}
LOG.info(""Connection Timeout: Retrying"");
while ((m = consumer.receive(messageReceiveTimeout)) != null) {
count++;
LOG.info(((""Recieved Message ("" + count) + ""):"") + m);
messagesConsumed.incrementAndGet();
try {
Thread.sleep(100);
} catch (Exception e) {
LOG.info(""error sleeping"");
}
}
LOG.info(""consumer session closing: consumed count: "" + count);
consumerSession.close();
producingThread.join();
final long tempUsageBySubscription = broker.getSystemUsage().getTempUsage().getUsage();
LOG.info(((""Orig Usage: "" + origTempUsage) + "", currentUsage: "") + tempUsageBySubscription);
producerConnection.close();
consumerConnection.close();
LOG.info(((""Subscrition Usage: "" + tempUsageBySubscription) + "", endUsage: "") + broker.getSystemUsage().getTempUsage().getUsage());
assertEquals(""Incorrect number of Messages Sent: "" + messagesSent.get(), messagesSent.get(), MESSAGES_COUNT);
assertEquals(""Incorrect number of Messages Consumed: "" + messagesConsumed.get(), messagesConsumed.get(), MESSAGES_COUNT);
}",async wait,0
8,hadoop,TestLocalDirAllocator.testRemoveContext,"@Test
public void testRemoveContext() throws IOException {
String dir = buildBufferDir(ROOT, 0);
String contextCfgItemName = ""application_1340842292563_0004.app.cache.dirs"";
conf.set(contextCfgItemName, dir);
LocalDirAllocator localDirAllocator = new LocalDirAllocator(contextCfgItemName);
localDirAllocator.getLocalPathForWrite(""p1/x"", SMALL_FILE_SIZE, conf);
assertTrue(LocalDirAllocator.isContextValid(contextCfgItemName));
LocalDirAllocator.removeContext(contextCfgItemName);
assertFalse(LocalDirAllocator.isContextValid(contextCfgItemName));
}",test order dependency,4
9,hadoop,TestRMContainerAllocator.testSimple,"@Test
public void testSimple() throws Exception {
Configuration conf = new Configuration();
MyResourceManager rm = new MyResourceManager(conf);
rm.start();
DrainDispatcher dispatcher = ((DrainDispatcher) (rm.getRMContext().getDispatcher()));
RMApp app = rm.submitApp(1024);
dispatcher.await();
MockNM amNodeManager = rm.registerNode(""amNM:1234"", 2048);
amNodeManager.nodeHeartbeat(true);
dispatcher.await();
ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt().getAppAttemptId();
rm.sendAMLaunched(appAttemptId);
dispatcher.await();
JobId jobId = MRBuilderUtils.newJobId(appAttemptId.getApplicationId(), 0);
Job mockJob = mock(Job.class);
when(mockJob.getReport()).thenReturn(MRBuilderUtils.newJobReport(jobId, ""job"", ""user"", RUNNING, 0, 0, 0, 0, 0, 0, ""jobfile""));
MyContainerAllocator allocator = new MyContainerAllocator(rm, conf, appAttemptId, mockJob);
MockNM nodeManager1 = rm.registerNode(""h1:1234"", 10240);
MockNM nodeManager2 = rm.registerNode(""h2:1234"", 10240);
MockNM nodeManager3 = rm.registerNode(""h3:1234"", 10240);
dispatcher.await();
ContainerRequestEvent event1 = createReq(jobId, 1, 1024, new String[]{ ""h1"" });
allocator.sendRequest(event1);
ContainerRequestEvent event2 = createReq(jobId, 2, 1024, new String[]{ ""h2"" });
allocator.sendRequest(event2);
List<TaskAttemptContainerAssignedEvent> assigned = allocator.schedule();
dispatcher.await();
Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size());
ContainerRequestEvent event3 = createReq(jobId, 3, 1024, new String[]{ ""h3"" });
allocator.sendRequest(event3);
assigned = allocator.schedule();
dispatcher.await();
Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size());
nodeManager1.nodeHeartbeat(true);
nodeManager2.nodeHeartbeat(true);
nodeManager3.nodeHeartbeat(true);
dispatcher.await();
assigned = allocator.schedule();
dispatcher.await();
checkAssignments(new ContainerRequestEvent[]{ event1, event2, event3 }, assigned, false);
}",async wait,0
10,activemq,ExpiredMessagesTest.testRecoverExpiredMessages,"@Test
public void testRecoverExpiredMessages() throws Exception {
ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory( ) ;
connection = factory.createConnection();
connection.start();
session = connection.createSession(false, AUTO_ACKNOWLEDGE);
producer = session.createProducer(destination);
producer.setTimeToLive(2000);
producer.setDeliveryMode(PERSISTENT);
Thread producingThread = new Thread(""Producing Thread"") {
public void run() {
try {
int i = 0;
while ((i++) < 1000) {
Message message = (useTextMessage) ? session.createTextMessage(""test"") : session.createObjectMessage(""test"");
producer.send(message);
}
producer.close();
} catch (Throwable ex) {
ex.printStackTrace();
}
}
};
producingThread.start();
producingThread.join();
DestinationViewMBean view = createView(destination);
LOG.info(((((((((((""Stats: size: "" + view.getQueueSize()) + "", enqueues: "") + view.getDequeueCount()) + "", dequeues: "") + view.getDequeueCount()) + "", dispatched: "") + view.getDispatchCount()) + "", inflight: "") + view.getInFlightCount()) + "", expiries: "") + view.getExpiredCount());
LOG.info(""stopping broker"");
broker.stop();
broker.waitUntilStopped();
Thread.sleep(5000);
LOG.info(""recovering broker"");
final boolean deleteAllMessages = false;
broker = createBroker(deleteAllMessages, 5000);
Wait.waitFor(new Wait.Condition() {
public boolean isSatisified() throws Exception {
boolean result = false;
try {
DestinationViewMBean view = createView(destination);
LOG.info(((((((((((""Stats: size: "" + view.getQueueSize()) + "", enqueues: "") + view.getDequeueCount()) + "", dequeues: "") + view.getDequeueCount()) + "", dispatched: "") + view.getDispatchCount()) + "", inflight: "") + view.getInFlightCount()) + "", expiries: "") + view.getExpiredCount());
result = view.getQueueSize() == 0;
} catch (Exception notFoundExpectedOnSlowMachines) {
}
return result;
}
});
view = createView(destination);
assertEquals(""Expect empty queue, QueueSize: "", 0, view.getQueueSize());
assertEquals(""all dequeues were expired"", view.getDequeueCount(), view.getExpiredCount());
}",async wait,0
11,androidx,getNanoTime,"@Test
public void getNanoTime() {
if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) {
long time = mRecyclerView.getNanoTime();
assertNotEquals(0, time);
assertNotEquals(time, mRecyclerView.getNanoTime());
} else {
assertEquals(0, mRecyclerView.getNanoTime());
}
}",time,2
12,ecchronos,TestRepairGroup.testGetPartialRepairTasks,"@Test
public void testGetPartialRepairTasks() {
Node node = mockNode(""DC1"");
Node node2 = mockNode(""DC1"");
ImmutableList<LongTokenRange> vnodes = ImmutableList.of(new LongTokenRange(1, 2), new LongTokenRange(2, 3), new LongTokenRange(4, 5));
ReplicaRepairGroup replicaRepairGroup = new ReplicaRepairGroup(ImmutableSet.of(node, node2), vnodes);
RepairGroup repairGroup = builderFor(replicaRepairGroup).build(priority);
Collection<RepairTask> tasks = repairGroup.getRepairTasks();
assertThat(tasks.size()).isEqualTo(3);
Set<LongTokenRange> repairTaskRanges = new HashSet<>();
for (RepairTask repairTask : tasks) {
assertThat(repairTask.getTokenRanges().size()).isEqualTo(1);
LongTokenRange range = repairTask.getTokenRanges().iterator().next();
repairTaskRanges.add(range);
assertThat(repairTask.getReplicas()).containsExactlyInAnyOrder(node, node2);
assertThat(repairTask.getTableReference()).isEqualTo(tableReference);
assertThat(repairTask.getRepairConfiguration().getRepairParallelism()).isEqualTo(PARALLEL);
}
assertThat(repairTaskRanges).containsExactlyElementsOf(vnodes);
}",unordered collections,3
13,androidx,testTimer_withListenerAndCleanUp,"@Test
@LargeTest
public void testTimer_withListenerAndCleanUp() throws InterruptedException {
TestTimeLimitExceededListener listenerSpy = spy(mListener);
mWorkTimer.startTimer(WORKSPEC_ID_1, 0, listenerSpy);
Thread.sleep(10);
verify(listenerSpy, times(1)).onTimeLimitExceeded(WORKSPEC_ID_1);
assertThat(mWorkTimer.getTimerMap().size(), is(0));
assertThat(mWorkTimer.getListeners().size(), is(0));
}",async wait,0
14,neo4j,RobustJobSchedulerWrapperTest.recurringJobWithExceptionShouldKeepRunning,"@Test
public void recurringJobWithExceptionShouldKeepRunning() throws Exception
{
RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper( actualScheduler, log );
AtomicInteger count = new AtomicInteger();
IllegalStateException e = new IllegalStateException();
int nRuns = 100;
JobHandle jobHandle = robustWrapper.scheduleRecurring( ""JobName"", 1, () -> {
if ( count.get() < nRuns )
{
count.incrementAndGet();
throw e;
}
}
);
assertEventually( ""run count"", count::get, Matchers.equalTo( nRuns ), DEFAULT_TIMEOUT_MS , MILLISECONDS );
robustWrapper.cancelAndWaitTermination( jobHandle );
verify( log, timeout( DEFAULT_TIMEOUT_MS ).times( nRuns ) ).warn( ""Uncaught exception"", e );
}",concurrency,1
15,pair-distribution-app,testGenerateNewDayPairs,"@Test
public void testGenerateNewDayPairs() {
PairCombinations pairs = getPairsList();
List<Developer> devs = getStandardDevs();
List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
subject.buildDevelopersPairingDays(pairs, devs);
DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());
assertThat(dayPairs.getTracks().size(), is(2));
assertThat(dayPairs.getTracks(), contains(""track1"", ""track2""));
assertThat(dayPairs.getPairByTrack(""track1""),
is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
assertThat(dayPairs.getPairByTrack(""track2""),
is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4""))))));
boolean trackOneHasContext = dayPairs.getPairByTrack(""track1"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track1"").getSecondDev().hasContext();
boolean trackTwoHasContext = dayPairs.getPairByTrack(""track2"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track2"").getSecondDev().hasContext();
assertThat(trackOneHasContext, is(true));
assertThat(trackTwoHasContext, is(true));
}",unordered collections,3
16,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireObjectEvent,"@Test
public void testFireObjectEvent() throws Exception {
final NamingEventCoordinator coordinator = new NamingEventCoordinator();
final CollectingListener objectListener = new CollectingListener(1);
coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
final CollectingListener subtreeListener = new CollectingListener(0);
coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
final CollectingListener oneLevelListener = new CollectingListener(0);
coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE);
objectListener.latch.await(1, TimeUnit.SECONDS);
assertEquals(1, objectListener.capturedEvents.size());
assertTrue(oneLevelListener.capturedEvents.isEmpty());
assertTrue(subtreeListener.capturedEvents.isEmpty());
}",test order dependency,4
17,zeebe,PriorityElectionTimerTest.shouldHighPriorityNodeStartElectionFirst,"@Test
public void shouldHighPriorityNodeStartElectionFirst() {
final AtomicBoolean highPrioElectionTriggered = spy(new AtomicBoolean());
final AtomicBoolean lowPrioElectionTriggered = spy(new AtomicBoolean());
final int targetPriority = 4;
final PriorityElectionTimer timerHighPrio = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> highPrioElectionTriggered.set(true), log, targetPriority, targetPriority);
final PriorityElectionTimer timerLowPrio = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> lowPrioElectionTriggered.set(true), log, targetPriority, 1);
timerLowPrio.reset();
timerHighPrio.reset();
Awaitility.await().until(highPrioElectionTriggered::get);
Awaitility.await().until(lowPrioElectionTriggered::get);
final var inorder = Mockito.inOrder(highPrioElectionTriggered, lowPrioElectionTriggered);
inorder.verify(highPrioElectionTriggered).set(true);
inorder.verify(lowPrioElectionTriggered).set(true);
}",async wait,0
18,fastjson,MultiMapTes.test_multimap,"@Test
public void test_multimap() throws Exception {
Map<String, Integer> map = ImmutableMap.of(""a"", 1, ""b"", 1, ""c"", 2);
SetMultimap<String, Integer> multimap = Multimaps.forMap(map);
Multimap<Integer, String> inverse = Multimaps.invertFrom(multimap, HashMultimap.<Integer, String>create());
String json = JSON.toJSONString(inverse);
assertEquals(""{1:[\""a\"",\""b\""],2:[\""c\""]}"", json);
}",unordered collections,3
19,camel,KafkaConsumerTopicIsPatternIT.kafkaTopicIsPattern,"@Test
public void kafkaTopicIsPattern() throws Exception {
to.expectedMessageCount(5);
to.expectedBodiesReceivedInAnyOrder(""message-0"", ""message-1"", ""message-2"", ""message-3"", ""message-4"");
to.allMessages().header(TOPIC).isEqualTo(""test"");
to.expectedHeaderValuesReceivedInAnyOrder(LAST_RECORD_BEFORE_COMMIT, null, null, null, null, null);
for (int k = 0; k < 5; k++) {
String msg = ""message-"" + k;
ProducerRecord<String, String> data = new ProducerRecord<>(TOPIC, ""1"", msg);
producer.send(data);
}
to.assertIsSatisfied(3000);
assertEquals(5, StreamSupport.stream(recordsCaptured.get(0).records(TOPIC).spliterator(), false).count());
}",test order dependency,4
20,cdap,WorkflowHttpHandlerTest.testWorkflowForkFailure,"@Test
public void testWorkflowForkFailure() throws Exception {
Assert.assertEquals(200, deploy(WorkflowFailureInForkApp.class).getStatusLine().getStatusCode());
Id.Application appId = Application.from(DEFAULT, NAME);
Id.Workflow workflowId = Workflow.from(appId, NAME);
Id.Program firstMRId = Program.from(appId, MAPREDUCE, FIRST_MAPREDUCE_NAME);
Id.Program secondMRId = Program.from(appId, MAPREDUCE, SECOND_MAPREDUCE_NAME);
String outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
File fileToSync = new File(tmpFolder.newFolder() + ""/sync.file"");
File fileToWait = new File(tmpFolder.newFolder() + ""/wait.file"");
startProgram(workflowId, ImmutableMap.of(""inputPath"", createInput(""testWorkflowForkFailureInput""), ""outputPath"", outputPath, ""sync.file"", fileToSync.getAbsolutePath(), ""wait.file"", fileToWait.getAbsolutePath(), (""mapreduce."" + WorkflowFailureInForkApp.SECOND_MAPREDUCE_NAME) + "".throw.exception"", ""true""));
waitState(workflowId, RUNNING.name());
waitState(workflowId, STOPPED.name());
verifyProgramRuns(workflowId, ""failed"");
List<RunRecord> mapReduceProgramRuns = getProgramRuns(firstMRId, KILLED.name());
Assert.assertEquals(1, mapReduceProgramRuns.size());
mapReduceProgramRuns = getProgramRuns(secondMRId, FAILED.name());
Assert.assertEquals(1, mapReduceProgramRuns.size());
}",concurrency,1
21,atlasdb,extraSweepersGiveUpAfterFailingToAcquireEnoughTimes,"@Test
public void extraSweepersGiveUpAfterFailingToAcquireEnoughTimes() throws InterruptedException {
int shards = 16;
int sweepers = 4;
int threads = shards / (sweepers / 2);
TimelockService stickyLockService = createStickyLockService();
createAndInitializeSweepersAndWaitForOneBackgroundIteration(sweepers, shards, threads, stickyLockService);
ArgumentCaptor<LockRequest> captor = ArgumentCaptor.forClass(LockRequest.class);
verify(stickyLockService, atLeast(shards * (shards / threads + 1) / 2 + shards * (threads * sweepers - shards)));
verify(stickyLockService, atMost(shards * ((threads + 1) * sweepers - shards) - sweepers * (sweepers - 1) / 2));
Set<String> requestedLockIds = captor.getAllValues().stream()
.map(LockRequest::getLockDescriptors)
.map(Iterables::getOnlyElement)
.map(LockDescriptor::getLockIdAsString)
.collect(Collectors.toSet());
Set<String> expectedLockIds = IntStream.range(0, shards).boxed()
.map(ShardAndStrategy::conservative)
.map(ShardAndStrategy::toText)
.collect(Collectors.toSet());
assertThat(requestedLockIds).hasSameElementsAs(expectedLockIds);
}",concurrency,1
22,pulsar,TopicReaderTest.testMultiReaderIsAbleToSeekWithTimeOnMiddleOfTopic,"@Test
public void testMultiReaderIsAbleToSeekWithTimeOnMiddleOfTopic() throws Exception {
final String topicName = ""persistent"";
final int numOfMessage = 10;
final int halfMessages = numOfMessage / 2;
admin.topics().createPartitionedTopic(topicName, 3);
Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName).create();
long l = System.currentTimeMillis();
for (int i = 0; i < numOfMessage; i++) {
producer.send(String.format(""msg num %d"", i).getBytes());
}
Reader<byte[]> reader = pulsarClient.newReader().topic(topicName).startMessageId(earliest).create();
int plusTime = (halfMessages + 1) * 100;
reader.seek(l + plusTime);
Set<String> messageSet = Sets.newHashSet();
for (int i = halfMessages + 1; i < numOfMessage; i++) {
Message<byte[]> message = reader.readNext();
String receivedMessage = new String(message.getData());
Assert.assertTrue(messageSet.add(receivedMessage), ""Received duplicate message "" + receivedMessage);
}
reader.close();
producer.close();
}",time,2
23,jsondoc,JSONDocApiAuthBuilderTest.testApiAuthToken,"@Test
public void testApiAuthToken() {
ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(Controller.class), URI).iterator().next();
Assert.assertEquals(""TOKEN"", apiDoc.getAuth().getType());
Assert.assertEquals("""", apiDoc.getAuth().getScheme());
Assert.assertEquals(""abc"", apiDoc.getAuth().getTesttokens().iterator().next());
for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
if (apiMethodDoc.getPath().contains(""/inherit"")) {
Assert.assertEquals(""TOKEN"", apiMethodDoc.getAuth().getType());
Assert.assertEquals("""", apiMethodDoc.getAuth().getScheme());
Assert.assertEquals(""abc"", apiMethodDoc.getAuth().getTesttokens().iterator().next());
}
if (apiMethodDoc.getPath().contains(""/override"")) {
Assert.assertEquals(""TOKEN"", apiMethodDoc.getAuth().getType());
Assert.assertEquals(""Bearer"", apiMethodDoc.getAuth().getScheme());
Assert.assertEquals(""xyz"", apiMethodDoc.getAuth().getTesttokens().iterator().next());
}
}
}",unordered collections,3
24,trino,TestExchangeClient.testAddLocation,"@Test
public void testAddLocation() throws Exception {
DataSize maxResponseSize = DataSize.of(10, MEGABYTE);
MockExchangeRequestProcessor processor = new MockExchangeRequestProcessor(maxResponseSize);
TaskId task1 = new TaskId(new StageId(""query"", 1), 0, 0);
TaskId task2 = new TaskId(new StageId(""query"", 1), 1, 0);
TaskId task3 = new TaskId(new StageId(""query"", 1), 2, 0);
URI location1 = URI.create(""http:www.example1.com"");
URI location2 = URI.create(""http:www.example2.com"");
URI location3 = URI.create(""http:www.example3.com"");
processor.addPage(location1, createSerializedPage(1));
processor.addPage(location1, createSerializedPage(2));
TestingExchangeClientBuffer buffer = new TestingExchangeClientBuffer(DataSize.of(1, MEGABYTE));
@SuppressWarnings(""resource"")
ExchangeClient exchangeClient = new ExchangeClient(""localhost"", DataIntegrityVerification.ABORT, buffer, maxResponseSize, 1, new Duration(1, TimeUnit.MINUTES), true, new TestingHttpClient(processor, scheduler), scheduler, new SimpleLocalMemoryContext(newSimpleAggregatedMemoryContext(), ""test""), pageBufferClientCallbackExecutor, ( taskId, failure) -> {
});
assertThat(buffer.getAllTasks()).isEmpty();
assertThat(buffer.getPages().asMap()).isEmpty();
assertThat(buffer.getFinishedTasks()).isEmpty();
assertThat(buffer.getFailedTasks().asMap()).isEmpty();
assertFalse(buffer.isNoMoreTasks());
exchangeClient.addLocation(task1, location1);
assertThat(buffer.getAllTasks()).containsExactly(task1);
assertTaskIsNotFinished(buffer, task1);
processor.setComplete(location1);
buffer.whenTaskFinished(task1).get(10, SECONDS);
assertThat(buffer.getPages().get(task1)).hasSize(2);
assertThat(buffer.getFinishedTasks()).containsExactly(task1);
exchangeClient.addLocation(task2, location2);
assertThat(buffer.getAllTasks()).containsExactlyInAnyOrder(task1, task2);
assertTaskIsNotFinished(buffer, task2);
processor.setComplete(location2);
buffer.whenTaskFinished(task2).get(10, SECONDS);
assertThat(buffer.getFinishedTasks()).containsExactlyInAnyOrder(task1, task2);
assertThat(buffer.getPages().get(task2)).hasSize(0);
exchangeClient.addLocation(task3, location3);
assertThat(buffer.getAllTasks()).containsExactlyInAnyOrder(task1, task2, task3);
assertTaskIsNotFinished(buffer, task3);
exchangeClient.noMoreLocations();
assertTrue(buffer.isNoMoreTasks());
assertThat(buffer.getAllTasks()).containsExactlyInAnyOrder(task1, task2, task3);
assertTaskIsNotFinished(buffer, task3);
exchangeClient.close();
assertEventually(() -> assertEquals(exchangeClient.getStatus().getPageBufferClientStatuses().get(0).getHttpRequestState(), ""not scheduled"", ""httpRequestState""));
assertEventually(() -> assertEquals(exchangeClient.getStatus().getPageBufferClientStatuses().get(1).getHttpRequestState(), ""not scheduled"", ""httpRequestState""));
assertEventually(() -> assertEquals(exchangeClient.getStatus().getPageBufferClientStatuses().get(2).getHttpRequestState(), ""not scheduled"", ""httpRequestState""));
assertThat(buffer.getFinishedTasks()).containsExactlyInAnyOrder(task1, task2, task3);
assertThat(buffer.getFailedTasks().asMap()).isEmpty();
assertTrue(exchangeClient.isFinished());
}",async wait,0
25,hadoop,TestDelegationToken.testDelegationTokenSecretManager,"@Test
public void testDelegationTokenSecretManager() throws Exception {
DelegationTokenSecretManager dtSecretManager = cluster.getNameNode().getNamesystem().getDelegationTokenSecretManager();
Token<DelegationTokenIdentifier> token = generateDelegationToken(""SomeUser"", ""JobTracker"");
try {
dtSecretManager.renewToken(token, ""FakeRenewer"");
Assert.fail(""should have failed"");
} catch (AccessControlException ace) {
}
dtSecretManager.renewToken(token, ""JobTracker"");
DelegationTokenIdentifier identifier = new DelegationTokenIdentifier();
byte[] tokenId = token.getIdentifier();
identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
Assert.assertTrue(null != dtSecretManager.retrievePassword(identifier));
LOG.info(""Sleep to expire the token"");
Thread.sleep(6000);
try {
dtSecretManager.retrievePassword(identifier);
Assert.fail(""Token should have expired"");
} catch (InvalidToken e) {
}
dtSecretManager.renewToken(token, ""JobTracker"");
LOG.info(""Sleep beyond the max lifetime"");
Thread.sleep(5000);
try {
dtSecretManager.renewToken(token, ""JobTracker"");
Assert.fail(""should have been expired"");
} catch (InvalidToken it) {
}
}",concurrency,1
26,uaa,testMatchesSpeedTest,"@Test
public void testMatchesSpeedTest() throws Exception {
int iterations = 15;
String password = new RandomValueStringGenerator().generate();
String encodedBcrypt = cachingPasswordEncoder.encode(password);
long nanoStart = System.nanoTime();
for (int i = 0; i < iterations; i++) {
assertTrue(cachingPasswordEncoder.getPasswordEncoder().matches(password, encodedBcrypt));
long nanoStop = System.nanoTime();
long bcryptTime = nanoStop - nanoStart;
nanoStart = System.nanoTime();
for (int i = 0; i < iterations; i++) {
nanoStop = System.nanoTime();
long cacheTime = nanoStop - nanoStart;
assertTrue(bcryptTime > (10 * cacheTime));
}
}
}",time,2
27,ozone,TestSCMUpdateServiceGrpcServer.testClientUpdateWithDelayedRevoke,"@Test
public void testClientUpdateWithDelayedRevoke() throws Exception {
OzoneConfiguration conf = new OzoneConfiguration();
SCMUpdateServiceGrpcServer server = new SCMUpdateServiceGrpcServer(getUpdateServiceConfig(conf), mockCRLStore);
ClientCRLStore clientCRLStore = new ClientCRLStore();
SCMUpdateClientConfiguration updateClientConfiguration = conf.getObject(SCMUpdateClientConfiguration.class);
updateClientConfiguration.setClientCrlCheckInterval(Duration.ofSeconds(2));
conf.setFromObject(updateClientConfiguration);
SCMUpdateServiceGrpcClient client = new SCMUpdateServiceGrpcClient(""localhost"", conf, clientCRLStore);
server.start();
client.start();
try {
List<BigInteger> certIds = new ArrayList<>();
for (int i = 0; i < 10; i++) {
BigInteger certId = mockCRLStore.issueCert();
certIds.add(certId);
}
revokeCertNow(certIds.get(0));
server.notifyCrlUpdate();
GenericTestUtils.waitFor(() -> client.getUpdateCount() == 1, 100, 2000);
Assert.assertEquals(1, client.getUpdateCount());
Assert.assertEquals(0, client.getErrorCount());
revokeCert(certIds.get(5), Instant.now().plus(Duration.ofSeconds(5)));
server.notifyCrlUpdate();
GenericTestUtils.waitFor(() -> client.getUpdateCount() > 1, 100, 2000);
Assert.assertEquals(2, client.getUpdateCount());
Assert.assertEquals(0, client.getErrorCount());
Assert.assertEquals(1, client.getClientCRLStore().getPendingCrlIds().size());
GenericTestUtils.waitFor(() -> client.getPendingCrlRemoveCount() == 1, 100, 20000);
Assert.assertTrue(client.getClientCRLStore().getPendingCrlIds().isEmpty());
} catch (Exception e) {
e.printStackTrace();
} finally {
client.stop(true);
server.stop();
}
}",async wait,0
28,hadoop,TestDFSIO.testReadSkip,"@Test
public void testReadSkip() throws Exception {
FileSystem fs = cluster.getFileSystem();
long tStart = System.currentTimeMillis();
bench.getConf().setLong(""test.io.skip.size"", 1);
bench.randomReadTest(fs);
long execTime = System.currentTimeMillis() - tStart;
bench.analyzeResult(fs, TestType.TEST_TYPE_READ_SKIP, execTime);
}",test order dependency,4
29,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testCreateSubcontext,"@Test
public void testCreateSubcontext() throws Exception {
assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext);
assertTrue(testActionPermission(JndiPermission.ACTION_CREATE_SUBCONTEXT, namingContext, ""securitytest"") instanceof NamingContext);
}",test order dependency,4
30,pulsar,ZKSessionTest.testReacquireLocksAfterSessionLost,"@Test
public void testReacquireLocksAfterSessionLost() throws Exception {
@Cleanup
MetadataStoreExtended store = MetadataStoreExtended.create(zks.getConnectionString(), MetadataStoreConfig.builder().sessionTimeoutMillis(2000).build());
BlockingQueue<SessionEvent> sessionEvents = new LinkedBlockingQueue<>();
store.registerSessionListener(sessionEvents::add);
@Cleanup
CoordinationService coordinationService = new CoordinationServiceImpl(store);
@Cleanup
LockManager<String> lm1 = coordinationService.getLockManager(String.class);
String path = newKey();
ResourceLock<String> lock = lm1.acquireLock(path, ""value-1"").join();
zks.expireSession(((ZKMetadataStore) (store)).getZkSessionId());
SessionEvent e = sessionEvents.poll(5, TimeUnit.SECONDS);
assertEquals(e, ConnectionLost);
e = sessionEvents.poll(10, TimeUnit.SECONDS);
assertEquals(e, SessionLost);
e = sessionEvents.poll(10, TimeUnit.SECONDS);
assertEquals(e, Reconnected);
e = sessionEvents.poll(10, TimeUnit.SECONDS);
assertEquals(e, SessionReestablished);
Awaitility.await().untilAsserted(() -> {
assertFalse(lock.getLockExpiredFuture().isDone());
});
assertTrue(store.get(path).join().isPresent());
}",async wait,0
31,hutool,EnumUtilTest.getFieldNamesTest,"@Test
public void getFieldNamesTest() {
List<String> names = EnumUtil.getFieldNames(TestEnum.class);
Assert.assertEquals(CollUtil.newArrayList(""type"", ""name""), names);
}",unordered collections,3
32,druid,ResponseContextTest.serializeWithTruncateArrayTest,"@Test
public void serializeWithTruncateArrayTest() throws IOException {
final ResponseContext ctx = ResponseContext.createEmpty();
ctx.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3), interval(4), interval(5), interval(6)));
ctx.put(EXTN_STRING_KEY, Strings.repeat(""x"", INTERVAL_LEN * 7));
final DefaultObjectMapper objectMapper = new DefaultObjectMapper();
final String fullString = objectMapper.writeValueAsString(ctx.getDelegate());
final ResponseContext.SerializationResult res1 = ctx.serializeWith(objectMapper, Integer.MAX_VALUE);
Assert.assertEquals(fullString, res1.getResult());
final int maxLen = ((((INTERVAL_LEN * 4) + UNCOVERED_INTERVALS.getName().length()) + 4) + TRUNCATED.getName().length()) + 6;
final ResponseContext.SerializationResult res2 = ctx.serializeWith(objectMapper, maxLen);
final ResponseContext ctxCopy = ResponseContext.createEmpty();
ctxCopy.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3)));
ctxCopy.put(TRUNCATED, true);
Assert.assertEquals(ctxCopy.getDelegate(), deserializeContext(res2.getResult(), objectMapper));
}",unordered collections,3
33,kafka,shouldTogglePrepareForBulkLoadDuringRestoreCalls,"@Test
public void shouldTogglePrepareForBulkLoadDuringRestoreCalls() throws Exception {
final List<KeyValue<byte[], byte[]>> entries = new ArrayList<>();
entries.add(new KeyValue<>(""1"".getBytes(""UTF-8""), ""a"".getBytes(""UTF-8"")));
entries.add(new KeyValue<>(""2"".getBytes(""UTF-8""), ""b"".getBytes(""UTF-8"")));
entries.add(new KeyValue<>(""3"".getBytes(""UTF-8""), ""c"".getBytes(""UTF-8"")));
final AtomicReference<Exception> conditionNotMet = new AtomicReference<>();
final AtomicInteger conditionCheckCount = new AtomicInteger();
Thread conditionCheckThread = new Thread(new Runnable() {
@Override
public void run() {
assertRocksDBTurnsOnBulkLoading(conditionCheckCount, conditionNotMet);
assertRockDBTurnsOffBulkLoad(conditionCheckCount, conditionNotMet);
}
});
subject.init(context, subject);
conditionCheckThread.start();
context.restore(subject.name(), entries);
conditionCheckThread.join(2000);
assertTrue(conditionNotMet.get() == null);
assertTrue(conditionCheckCount.get() == 2);
}",concurrency,1
34,sling,ClassloadingTest.testSimpleClassloading,"@Test
public void testSimpleClassloading() throws Exception {
final AtomicInteger count = new AtomicInteger(0);
final List<Event> finishedEvents = Collections.synchronizedList(new ArrayList<Event>());
final ServiceRegistration jcReg = this.registerJobConsumer(TOPIC, new JobConsumer() {
@Override
public JobResult process(Job job) {
count.incrementAndGet();
return JobResult.OK;
}
});
final ServiceRegistration ehReg = this.registerEventHandler(TOPIC_JOB_FINISHED, new EventHandler() {
@Override
public void handleEvent(Event event) {
finishedEvents.add(event);
}
});
try {
final JobManager jobManager = this.getJobManager();
final List<String> list = new ArrayList<String>();
list.add(""1"");
list.add(""2"");
final EventPropertiesMap map = new EventPropertiesMap();
map.put(""a"", ""a1"");
map.put(""b"", ""b2"");
final Map<String, Object> props = new HashMap<String, Object>();
props.put(""string"", ""Hello"");
props.put(""int"", new Integer(5));
props.put(""long"", new Long(7));
props.put(""list"", list);
props.put(""map"", map);
jobManager.addJob(TOPIC, null, props);
while (finishedEvents.size() < 1) {
Thread.sleep(100);
}
Thread.sleep(100);
assertEquals(0, jobManager.getStatistics().getNumberOfQueuedJobs());
assertEquals(1, count.get());
assertEquals(0, jobManager.findJobs(ALL, TOPIC, -1, ((Map<String, Object>[]) (null))).size());
final String jobTopic = ((String) (finishedEvents.get(0).getProperty(NOTIFICATION_PROPERTY_JOB_TOPIC)));
assertNotNull(jobTopic);
assertEquals(""Hello"", finishedEvents.get(0).getProperty(""string""));
assertEquals(new Integer(5), Integer.valueOf(finishedEvents.get(0).getProperty(""int"").toString()));
assertEquals(new Long(7), Long.valueOf(finishedEvents.get(0).getProperty(""long"").toString()));
assertEquals(list, finishedEvents.get(0).getProperty(""list""));
assertEquals(map, finishedEvents.get(0).getProperty(""map""));
} finally {
jcReg.unregister();
ehReg.unregister();
}
}",async wait,0
35,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupContextLink,"@Test
public void testLookupContextLink() throws Exception {
final Name name = new CompositeName(""test/value"");
namingStore.bind(name, ""testValue"");
final Name linkName = new CompositeName(""link"");
namingStore.bind(linkName, new LinkRef(""./test""));
Object result = namingContext.lookup(""link/value"");
assertEquals(""testValue"", result);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""),
new JndiPermission(""test/value"", ""lookup"")), namingContext, ""link/value"");
assertEquals(""testValue"", result);
}",test order dependency,4
36,pulsar,BacklogQuotaManagerTest.testConsumerBacklogEvictionTimeQuotaWithEmptyLedger,"@Test
public void testConsumerBacklogEvictionTimeQuotaWithEmptyLedger() throws Exception {
assertEquals(admin.namespaces().getBacklogQuotaMap(""prop/ns-quota""), Maps.newHashMap());
admin.namespaces().setBacklogQuota(""prop/ns-quota"", BacklogQuota.builder().limitTime(TIME_TO_CHECK_BACKLOG_QUOTA).retentionPolicy(consumer_backlog_eviction).build(), message_age);
PulsarClient client = PulsarClient.builder().serviceUrl(adminUrl.toString()).statsInterval(0, TimeUnit.SECONDS).build();
final String topic = ""persistent"";
final String subName = ""c1"";
Consumer<byte[]> consumer = client.newConsumer().topic(topic).subscriptionName(subName).subscribe();
Producer<byte[]> producer = createProducer(client, topic);
producer.send(new byte[1024]);
consumer.receive();
admin.topics().unload(topic);
PersistentTopicInternalStats internalStats = admin.topics().getInternalStats(topic);
assertEquals(internalStats.ledgers.size(), 2);
assertEquals(internalStats.ledgers.get(1).entries, 0);
TopicStats stats = admin.topics().getStats(topic);
assertEquals(stats.getSubscriptions().get(subName).getMsgBacklog(), 1);
TimeUnit.SECONDS.sleep(TIME_TO_CHECK_BACKLOG_QUOTA);
Awaitility.await().pollInterval(Duration.ofSeconds(1)).atMost(Duration.ofSeconds(TIME_TO_CHECK_BACKLOG_QUOTA)).untilAsserted(() -> {
rolloverStats();
PersistentTopicInternalStats latestInternalStats = admin.topics().getInternalStats(topic);
assertEquals(latestInternalStats.ledgers.size(), 2);
assertEquals(latestInternalStats.ledgers.get(1).entries, 0);
TopicStats latestStats = admin.topics().getStats(topic);
assertEquals(latestStats.getSubscriptions().get(subName).getMsgBacklog(), 0);
});
client.close();
}",async wait,0
37,pulsar,InactiveTopicDeleteTest.testTopicLevelInActiveTopicApi,"@Test
public void testTopicLevelInActiveTopicApi() throws Exception {
super.resetConfig();
conf.setSystemTopicEnabled(true);
conf.setTopicLevelPoliciesEnabled(true);
super.baseSetup();
Thread.sleep(2000);
final String topicName = ""persistent://prop/ns-abc/testMaxInactiveDuration-"" + UUID.randomUUID().toString();
admin.topics().createPartitionedTopic(topicName, 3);
InactiveTopicPolicies inactiveTopicPolicies = admin.topics().getInactiveTopicPolicies(topicName);
assertNull(inactiveTopicPolicies);
InactiveTopicPolicies policies = new InactiveTopicPolicies();
policies.setDeleteWhileInactive(true);
policies.setInactiveTopicDeleteMode(InactiveTopicDeleteMode.delete_when_no_subscriptions);
policies.setMaxInactiveDurationSeconds(10);
admin.topics().setInactiveTopicPolicies(topicName, policies);
for (int i = 0; i < 50; i++) {
if (admin.topics().getInactiveTopicPolicies(topicName) != null) {
break;
}
Thread.sleep(100);
}
assertEquals(admin.topics().getInactiveTopicPolicies(topicName), policies);
admin.topics().removeInactiveTopicPolicies(topicName);
for (int i = 0; i < 50; i++) {
if (admin.topics().getInactiveTopicPolicies(topicName) == null) {
break;
}
Thread.sleep(100);
}
assertNull(admin.topics().getInactiveTopicPolicies(topicName));
super.internalCleanup();
}",async wait,0
38,hadoop,TestDFSIO.testReadBackward,"@Test
public void testReadBackward() throws Exception {
FileSystem fs = cluster.getFileSystem();
long tStart = System.currentTimeMillis();
bench.getConf().setLong(""test.io.skip.size"", -DEFAULT_BUFFER_SIZE);
bench.randomReadTest(fs);
long execTime = System.currentTimeMillis() - tStart;
bench.analyzeResult(fs, TestType.TEST_TYPE_READ_BACKWARD, execTime);
}",test order dependency,4
39,quarkus,testTimedMethod,"@Test
void testTimedMethod() throws InterruptedException {
assertTrue(Jobs.latch01.await(5, TimeUnit.SECONDS));
assertTrue(Jobs.latch02.await(5, TimeUnit.SECONDS));
Timer timer1 = registry.get(""scheduled.methods"")
.tag(""method"", ""everySecond"")
.tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"")
.tag(""exception"", ""none"")
.timer();
assertNotNull(timer1);
assertTrue(timer1.count() > 0);
Timer timer2 = registry.get(""foo"")
.tag(""method"", ""anotherEverySecond"")
.tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"")
.tag(""exception"", ""none"")
.timer();
assertNotNull(timer2);
assertTrue(timer2.count() > 0);
}",time,2
40,hadoop,TestDFSIO.testReadRandom,"@Test
public void testReadRandom() throws Exception {
FileSystem fs = cluster.getFileSystem();
long tStart = System.currentTimeMillis();
bench.getConf().setLong(""test.io.skip.size"", 0);
bench.randomReadTest(fs);
long execTime = System.currentTimeMillis() - tStart;
bench.analyzeResult(fs, TestType.TEST_TYPE_READ_RANDOM, execTime);
}",test order dependency,4
41,ecchronos,TestRepairTask.testRepairSuccessfully,"@Test
public void testRepairSuccessfully() throws InterruptedException {
Collection<LongTokenRange> ranges = new ArrayList<>();
LongTokenRange range1 = new LongTokenRange(1, 2);
LongTokenRange range2 = new LongTokenRange(3, 4);
ranges.add(range1);
ranges.add(range2);
final RepairTask repairTask = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(ranges).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build();
CountDownLatch cdl = startRepair(repairTask, false);
Notification notification = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(range1));
notification.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2));
proxy.notify(notification);
notification = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(range2));
notification.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2));
proxy.notify(notification);
notification = new Notification(""progress"", ""repair:1"", 2, ""Done with repair"");
notification.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2));
proxy.notify(notification);
cdl.await();
assertThat(repairTask.getUnknownRanges()).isNull();
assertThat(repairTask.getCompletedRanges()).containsExactlyElementsOf(ranges);
assertThat(proxy.myOptions.get(RANGES_KEY)).isNotEmpty();
verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true));
verify(repairSessions.get(range1)).start();
verify(repairSessions.get(range2)).start();
verify(repairSessions.get(range1)).finish(eq(SUCCESS));
verify(repairSessions.get(range2)).finish(eq(SUCCESS));
}",unordered collections,3
42,tomcat,TestWebappClassLoaderExecutorMemoryLeak.testTimerThreadLeak,"@Test
public void testTimerThreadLeak() throws Exception {
Tomcat tomcat = getTomcatInstance();
Context ctx = tomcat.addContext("""", System.getProperty(""java.io.tmpdir""));
if (ctx instanceof StandardContext) {
((StandardContext) (ctx)).setClearReferencesStopThreads(true);
}
ExecutorServlet executorServlet = new ExecutorServlet();
Tomcat.addServlet(ctx, ""taskServlet"", executorServlet);
ctx.addServletMapping(""/"", ""taskServlet"");
tomcat.start();
getUrl((""http://google.com""));
ctx.stop();
try {
Thread.sleep(1000);
} catch (InterruptedException ie) {
}
Assert.assertTrue(executorServlet.tpe.isShutdown());
Assert.assertTrue(executorServlet.tpe.isTerminated());
}",async wait,0
43,spring-data-envers,5637994be37747e82b2d6d5b34555e2bee791fe6.testWithRevisions,"@Test
public void testWithRevisions() {
Country de = new Country();
de.code = ""de"";
de.name = ""Deutschland"";
countryRepository.save(de);
de.name = ""Germany"";
countryRepository.save(de);
Revisions<Integer, Country> revisions = countryRepository.findRevisions(de.id);
assertThat(revisions).hasSize(2);
Iterator<Revision<Integer, Country>> iterator = revisions.iterator();
Integer firstRevisionNumber = iterator.next().getRevisionNumber().get();
Integer secondRevisionNumber = iterator.next().getRevisionNumber().get();
assertThat(countryRepository.findRevision(de.id, firstRevisionNumber).get().getEntity().name)
.isEqualTo(""Deutschland"");
assertThat(countryRepository.findRevision(de.id, secondRevisionNumber).get().getEntity().name).isEqualTo(""Germany"");
}",test order dependency,4
44,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupEmptyName,"@Test
public void testLookupEmptyName() throws Exception {
Object result = namingContext.lookup(new CompositeName());
assertTrue(result instanceof NamingContext);
result = namingContext.lookup(new CompositeName(""""));
assertTrue(result instanceof NamingContext);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, null);
assertTrue(result instanceof NamingContext);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, """");
assertTrue(result instanceof NamingContext);
}",test order dependency,4
45,Firestorm,HealthCheckCoordinatorGrpcTest.healthCheckTest,"@Test
public void healthCheckTest() throws Exception {
RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(""1"", 1, 1, 1, 1, Sets.newHashSet(SHUFFLE_SERVER_VERSION));
Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount());
List<ServerNode> nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION));
assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount());
assertEquals(2, nodes.size());
RssGetShuffleAssignmentsResponse response = coordinatorClient.getShuffleAssignments(request);
assertFalse(response.getPartitionToServers().isEmpty());
for (ServerNode node : nodes) {
assertTrue(node.isHealthy());
}
byte[] bytes = new byte[writeDataSize];
new Random().nextBytes(bytes);
try (final FileOutputStream out = new FileOutputStream(tempDataFile)) {
out.write(bytes);
}
Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
CoordinatorTestUtils.waitForRegister(coordinatorClient, 2);
nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION));
for (ServerNode node : nodes) {
assertFalse(node.isHealthy());
}
assertEquals(0, nodes.size());
response = coordinatorClient.getShuffleAssignments(request);
assertEquals(INTERNAL_ERROR, response.getStatusCode());
tempDataFile.delete();
int i = 0;
do {
Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION));
i++;
if (i == 10) {
fail();
}
} while (nodes.size() != 2 );
for (ServerNode node : nodes) {
assertTrue(node.isHealthy());
}
assertEquals(2, nodes.size());
response = coordinatorClient.getShuffleAssignments(request);
assertFalse(response.getPartitionToServers().isEmpty());
}",async wait,0
46,json-schema-validator,CollectorContextTest.testCollectorContextWithKeyword,"@Test
public void testCollectorContextWithKeyword() throws Exception {
ValidationResult validationResult = validate(""{\""test-property1\"":\""sample1\"",\""test-property2\"":\""sample2\""}"");
Assertions.assertEquals(0, validationResult.getValidationMessages().size());
List<String> contextValues = ((List<String>) (validationResult.getCollectorContext().get(SAMPLE_COLLECTOR)));
Assertions.assertEquals(0, validationResult.getValidationMessages().size());
Assertions.assertEquals(2, contextValues.size());
Assertions.assertEquals(contextValues.get(0), ""actual_value_added_to_context1"");
Assertions.assertEquals(contextValues.get(1), ""actual_value_added_to_context2"");
}",unordered collections,3
47,hadoop,TestPeerCache.testEviction,"@Test
public void testEviction() throws Exception {
final int CAPACITY = 3;
PeerCache cache = PeerCache.getInstance(CAPACITY, 100000);
DatanodeID dnIds[] = new DatanodeID[CAPACITY + 1];
FakePeer peers[] = new FakePeer[CAPACITY + 1];
for (int i = 0; i < dnIds.length; ++i) {
dnIds[i] = new DatanodeID(""192.168.0.1"",
""fakehostname_"" + i, ""fake_storage_id_"" + i,
100, 101, 102);
peers[i] = new FakePeer(dnIds[i], false);
}
for (int i = 0; i < CAPACITY; ++i) {
cache.put(dnIds[i], peers[i]);
}
assertEquals(CAPACITY, cache.size());
cache.put(dnIds[CAPACITY], peers[CAPACITY]);
assertEquals(CAPACITY, cache.size());
assertSame(null, cache.get(dnIds[0], false));
for (int i = 1; i < CAPACITY; ++i) {
Peer peer = cache.get(dnIds[i], false);
assertSame(peers[i], peer);
assertTrue(!peer.isClosed());
peer.close();
}
assertEquals(1, cache.size());
cache.close();
}",test order dependency,4
48,cdap,PreviewDataPipelineTest.testLogicalTypePreviewRun,"@Test
public void testLogicalTypePreviewRun(Engine engine) throws Exception {
PreviewManager previewManager = getPreviewManager();
String sourceTableName = ""singleInput"";
String sinkTableName = ""singleOutput"";
Schema schema = Schema.recordOf(
""testRecord"",
Schema.Field.of(""name"", Schema.of(Schema.Type.STRING)),
Schema.Field.of(""date"", Schema.of(Schema.LogicalType.DATE)),
Schema.Field.of(""ts"", Schema.of(Schema.LogicalType.TIMESTAMP_MILLIS))
);
ETLBatchConfig etlConfig = ETLBatchConfig.builder()
.addStage(new ETLStage(""source"", MockSource.getPlugin(sourceTableName, schema)))
.addStage(new ETLStage(""transform"", IdentityTransform.getPlugin()))
.addStage(new ETLStage(""sink"", MockSink.getPlugin(sinkTableName)))
.addConnection(""source"", ""transform"")
.addConnection(""transform"", ""sink"")
.setEngine(engine)
.setNumOfRecordsPreview(100)
.build();
PreviewConfig previewConfig = new PreviewConfig(SmartWorkflow.NAME, ProgramType.WORKFLOW,
Collections.<String, String>emptyMap(), 10);
addDatasetInstance(Table.class.getName(), sourceTableName,
DatasetProperties.of(ImmutableMap.of(""schema"", schema.toString())));
DataSetManager<Table> inputManager = getDataset(NamespaceId.DEFAULT.dataset(sourceTableName));
ZonedDateTime expectedMillis = ZonedDateTime.of(2018, 11, 11, 11, 11, 11, 123 * 1000 * 1000,
ZoneId.ofOffset(""UTC"", ZoneOffset.UTC));
StructuredRecord recordSamuel = StructuredRecord.builder(schema).set(""name"", ""samuel"")
.setDate(""date"", LocalDate.of(2002, 11, 18)).setTimestamp(""ts"", expectedMillis).build();
StructuredRecord recordBob = StructuredRecord.builder(schema).set(""name"", ""bob"")
.setDate(""date"", LocalDate.of(2003, 11, 18)).setTimestamp(""ts"", expectedMillis).build();
MockSource.writeInput(inputManager, ImmutableList.of(recordSamuel, recordBob));
AppRequest<ETLBatchConfig> appRequest = new AppRequest<>(APP_ARTIFACT_RANGE, etlConfig, previewConfig);
ApplicationId previewId = previewManager.start(NamespaceId.DEFAULT, appRequest);
Tasks.waitFor(PreviewStatus.Status.COMPLETED, new Callable<PreviewStatus.Status>() {
@Override
public PreviewStatus.Status call() throws Exception {
PreviewStatus status = previewManager.getStatus(previewId);
return status == null ? null : status.getStatus();
}
}, 5, TimeUnit.MINUTES);
checkPreviewStore(previewManager, previewId, ""source"", 2);
List<JsonElement> data = previewManager.getData(previewId, ""source"").get(DATA_TRACER_PROPERTY);
StructuredRecord actualRecordSamuel = GSON.fromJson(data.get(0), StructuredRecord.class);
Assert.assertEquals(actualRecordSamuel.get(""date""), ""2002-11-18"");
Assert.assertEquals(actualRecordSamuel.get(""ts""), ""2018-11-11T11:11:11.123Z[UTC]"");
StructuredRecord actualRecordBob = GSON.fromJson(data.get(1), StructuredRecord.class);
Assert.assertEquals(actualRecordBob.get(""date""), ""2003-11-18"");
Assert.assertEquals(actualRecordBob.get(""ts""), ""2018-11-11T11:11:11.123Z[UTC]"");
checkPreviewStore(previewManager, previewId, ""transform"", 2);
checkPreviewStore(previewManager, previewId, ""sink"", 2);
validateMetric(2, previewId, ""source.records.in"", previewManager);
validateMetric(2, previewId, ""source.records.out"", previewManager);
validateMetric(2, previewId, ""transform.records.in"", previewManager);
validateMetric(2, previewId, ""transform.records.out"", previewManager);
validateMetric(2, previewId, ""sink.records.out"", previewManager);
validateMetric(2, previewId, ""sink.records.in"", previewManager);
DataSetManager<Table> sinkManager = getDataset(sinkTableName);
Assert.assertNull(sinkManager.get());
deleteDatasetInstance(NamespaceId.DEFAULT.dataset(sourceTableName));
Assert.assertNotNull(previewManager.getRunId(previewId));
}",time,2
49,OpenSearch,testReplicaThreadedThroughputDegradationAndRejection,"@Test
public void testReplicaThreadedThroughputDegradationAndRejection() throws Exception {
Settings settings = Settings.builder().put(IndexingPressure.MAX_INDEXING_BYTES.getKey(), ""10KB"")
.put(ShardIndexingPressureSettings.SHARD_INDEXING_PRESSURE_ENABLED.getKey(), true)
.put(ShardIndexingPressureSettings.SHARD_INDEXING_PRESSURE_ENFORCED.getKey(), true)
.put(ShardIndexingPressureMemoryManager.THROUGHPUT_DEGRADATION_LIMITS.getKey(), 1)
.put(ShardIndexingPressureSettings.REQUEST_SIZE_WINDOW.getKey(), 100)
.build();
final int NUM_THREADS = scaledRandomIntBetween(100, 120);
ShardIndexingPressure shardIndexingPressure = new ShardIndexingPressure(settings, clusterService);
Index index = new Index(""IndexName"", ""UUID"");
ShardId shardId1 = new ShardId(index, 0);
fireConcurrentAndParallelRequestsForUniformThroughPut(NUM_THREADS, shardIndexingPressure, shardId1, 100, 100,
OperationType.REPLICA);
fireAllThenCompleteConcurrentRequestsWithUniformDelay(ShardIndexingPressureSettings.REQUEST_SIZE_WINDOW.get(settings),
shardIndexingPressure, shardId1, 100, 200, OperationType.REPLICA);
expectThrows(OpenSearchRejectedExecutionException.class,
() -> shardIndexingPressure.markReplicaOperationStarted(shardId1, 11 * 1024, false));
assertEquals(0, shardIndexingPressure.coldStats().getIndexingPressureShardStats(shardId1).getCurrentReplicaBytes());
assertEquals(15, shardIndexingPressure.coldStats().getIndexingPressureShardStats(shardId1).getCurrentReplicaLimits());
}",concurrency,1
50,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testCompositeBindingOps,"@Test
public void testCompositeBindingOps() throws Exception {
final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/alookup"");
final ModelNode addOp = Operations.createAddOperation(addr);
addOp.get(NamingSubsystemModel.BINDING_TYPE).set(NamingSubsystemModel.LOOKUP);
final ModelNode compositeOp = Operations.CompositeOperationBuilder.create().addStep(addOp).addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/a"")).build().getOperation();
ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
}",test order dependency,4
51,hadoop,TestHftpFileSystem.testHftpDefaultPorts,"@Test
public void testHftpDefaultPorts() throws IOException {
resetFileSystem();
Configuration conf = new Configuration();
URI uri = URI.create();
HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort());
assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort());
assertEquals(uri, fs.getUri());
assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName());
}",test order dependency,4
52,dropwizards,07dfaed697427e208d65049f80a5d1949833b7cd.testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut,"@Test
public void testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut() throws Exception {
Field field = StatusPrinter.class.getDeclaredField(""ps"");
field.setAccessible(true);
PrintStream out = (PrintStream) field.get(null);
assertThat(out).isSameAs(System.out);
}",test order dependency,4
53,nacos,525672272ecb00cd769a13c7b21a8e51cf873f25.testDeserializeExtend,"@Test
public void testDeserializeExtend() {
String tcpString = ""{\""type\"":\""TEST\"",\""testValue\"":null}"";
AbstractHealthChecker actual = HealthCheckerFactory.deserialize(tcpString);
assertEquals(TestChecker.class, actual.getClass());
}",test order dependency,4
54,androidx,testGenerateCleanupCallback_deletesOldFinishedWork,"@Test
public void testGenerateCleanupCallback_deletesOldFinishedWork() {
Work work1 = new Work.Builder(TestWorker.class)
.withInitialState(SUCCEEDED)
.withPeriodStartTime(0L)
.build();
Work work2 = new Work.Builder(TestWorker.class).withPeriodStartTime(Long.MAX_VALUE).build();
insertWorkSpecAndTags(work1);
insertWorkSpecAndTags(work2);
SupportSQLiteOpenHelper openHelper = mDatabase.getOpenHelper();
SupportSQLiteDatabase db = openHelper.getWritableDatabase();
WorkDatabase.generateCleanupCallback().onOpen(db);
WorkSpecDao workSpecDao = mDatabase.workSpecDao();
assertThat(workSpecDao.getWorkSpec(work1.getId()), is(nullValue()));
assertThat(workSpecDao.getWorkSpec(work2.getId()), is(not(nullValue())));
}",time,2
55,junit-quickcheck,ReflectionTest.findingAnnotationsRecursively,"@Test
public void findingAnnotationsRecursively() {
Method method = findMethod(this.getClass(), ""withMarker"", String.class);
List<Annotation> annotations = allAnnotations(method.getParameters()[0]);
assertEquals(4, annotations.size());
assertEquals(X.class, annotations.get(0).annotationType());
assertEquals(Y.class, annotations.get(1).annotationType());
assertEquals(Z.class, annotations.get(2).annotationType());
assertEquals(W.class, annotations.get(3).annotationType());
}",unordered collections,3
56,noxy,ReverseProxyServiceTest.testRequestMetaForSuccessfulRequest,"@Test
public void testRequestMetaForSuccessfulRequest() throws Exception {
ListenerMeta listenerMeta = listenerMetaIndexProvider.get().getListenerMetas().get(0);
OnlineServerMetaIndexProvider onlineServerMetaIndexProvider = listenerMeta.getOnlineServerMetaIndexProvider();
await().until(() -> {
assertThat(onlineServerMetaIndexProvider.get().getBalancer().size(), equalTo(3));
});
String content = fetch(""http://example.com/request-meta"");
RequestMeta requestMeta = RequestMeta.fromJSON(content);
requestMeta.getHeaders().remove(""Via"");
requestMeta.getHeaders().remove(""Cache-Control"");
requestMeta.getHeaders().remove(""Accept"");
requestMeta.getHeaders().remove(""Pragma"");
assertEquals(""foo"", requestMeta.getHeaders().get(""X-foo""));
content = requestMeta.toJSON();
corporaAsserter.assertEquals(""testRequestMetaForSuccessfulRequest"", content);
}",unordered collections,3
57,androidx,testMenuInvalidationAfterDestroy,"@Test
public void testMenuInvalidationAfterDestroy() throws Throwable {
final A activity = getActivity();
getInstrumentation().runOnMainSync(new Runnable() {
@Override
public void run() {
activity.reset();
assertNull(activity.getMenu());
activity.supportInvalidateOptionsMenu();
getInstrumentation().callActivityOnDestroy(activity);
}
});
Thread.sleep(100);
assertNull(activity.getMenu());
}",async wait,0
58,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindAndRetrieveObjectFactoryFromNamingContext,"@Test
public void testBindAndRetrieveObjectFactoryFromNamingContext() throws Exception {
final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
namingStore.bind(new CompositeName(""test""), reference);
final Object result = namingContext.lookup(""test"");
assertTrue(result instanceof String);
assertEquals(""Test ParsedResult"", result);
}",test order dependency,4
59,beam,testBacklogLimiter,"@Test
public void testBacklogLimiter() {
long duration = runWithRate(2 * RateLimiting.DEFAULT_MAX_PARALLELISM,-1.0 , new DelayFn<Integer>());
Assert.assertThat(duration,greaterThan(2 * DelayFn.DELAY_MS));
}",time,2
60,zookeeper,BookieClientTest.testWriteGaps,"@Test
public void testWriteGaps() throws Exception {
final Object notifyObject = new Object();
byte[] passwd = new byte[20];
Arrays.fill(passwd, ((byte) ('a')));
InetSocketAddress addr = new InetSocketAddress(""127.0.0.1"", port);
ResultStruct arc = new ResultStruct();
BookieClient bc = new BookieClient(new ClientConfiguration(), channelFactory, executor);
ChannelBuffer bb;
bb = createByteBuffer(1, 1, 1);
bc.addEntry(addr, 1, passwd, 1, bb, wrcb, null, FLAG_NONE);
synchronized(arc) {
bc.readEntry(addr, 1, 1, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(0, arc.rc);
assertEquals(1, arc.entry.getInt());
}
bb = createByteBuffer(2, 1, 2);
bc.addEntry(addr, 1, passwd, 2, bb, wrcb, null, FLAG_NONE);
bb = createByteBuffer(3, 1, 3);
bc.addEntry(addr, 1, passwd, 3, bb, wrcb, null, FLAG_NONE);
bb = createByteBuffer(5, 1, 5);
bc.addEntry(addr, 1, passwd, 5, bb, wrcb, null, FLAG_NONE);
bb = createByteBuffer(7, 1, 7);
bc.addEntry(addr, 1, passwd, 7, bb, wrcb, null, FLAG_NONE);
synchronized(notifyObject) {
bb = createByteBuffer(11, 1, 11);
bc.addEntry(addr, 1, passwd, 11, bb, wrcb, notifyObject, FLAG_NONE);
notifyObject.wait();
}
synchronized(arc) {
bc.readEntry(addr, 1, 6, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(NoSuchEntryException, arc.rc);
}
synchronized(arc) {
bc.readEntry(addr, 1, 7, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(0, arc.rc);
assertEquals(7, arc.entry.getInt());
}
synchronized(arc) {
bc.readEntry(addr, 1, 1, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(0, arc.rc);
assertEquals(1, arc.entry.getInt());
}
synchronized(arc) {
bc.readEntry(addr, 1, 2, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(0, arc.rc);
assertEquals(2, arc.entry.getInt());
}
synchronized(arc) {
bc.readEntry(addr, 1, 3, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(0, arc.rc);
assertEquals(3, arc.entry.getInt());
}
synchronized(arc) {
bc.readEntry(addr, 1, 4, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(NoSuchEntryException, arc.rc);
}
synchronized(arc) {
bc.readEntry(addr, 1, 11, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(0, arc.rc);
assertEquals(11, arc.entry.getInt());
}
synchronized(arc) {
bc.readEntry(addr, 1, 5, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(0, arc.rc);
assertEquals(5, arc.entry.getInt());
}
synchronized(arc) {
bc.readEntry(addr, 1, 10, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(NoSuchEntryException, arc.rc);
}
synchronized(arc) {
bc.readEntry(addr, 1, 12, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(NoSuchEntryException, arc.rc);
}
synchronized(arc) {
bc.readEntry(addr, 1, 13, recb, arc, FLAG_NONE);
arc.wait(1000);
assertEquals(NoSuchEntryException, arc.rc);
}
}",async wait,0
61,graylog2-server,indexCreationDateReturnsIndexCreationDateOfExistingIndexAsDateTime,"@Test
public void indexCreationDateReturnsIndexCreationDateOfExistingIndexAsDateTime() {
final DateTime now = DateTime.now(DateTimeZone.UTC);
final String indexName = client().createRandomIndex(""indices_it_"");
final Optional<DateTime> indexCreationDate = indices.indexCreationDate(indexName);
assertThat(indexCreationDate).isNotEmpty()
.hasValueSatisfying(date -> Assertions.assertThat(date).isEqualToIgnoringMillis(now));
}",time,2
62,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testJavaContext,"@Test
public void testJavaContext() throws Exception {
System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
System.setProperty(Context.URL_PKG_PREFIXES, ""org.jboss.as.naming.interfaces"");
InitialContext initialContext = new InitialContext();
Context context = (Context) initialContext.lookup(""java:"");
assertTrue(context instanceof NamingContext);
}",test order dependency,4
63,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupWithContinuation,"@Test
public void testLookupWithContinuation() throws Exception {
namingStore.bind(new CompositeName(""comp/nested""), ""test"");
final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null);
namingStore.bind(new CompositeName(""test""), reference);
Object result = namingContext.lookup(new CompositeName(""test/nested""));
assertEquals(""test"", result);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""comp/nested"", ""lookup"")), namingContext, ""test/nested"");
assertEquals(""test"", result);
}",test order dependency,4
64,ignite,testFlowNoConflictsWithClients,"@Test
public void testFlowNoConflictsWithClients() throws Exception {
startComputation(0, stopFlag0);
if (!tcpDiscovery())
return;
startComputation(1, stopFlag1);
startComputation(2, stopFlag2);
startComputation(3, stopFlag3);
startComputation(4, stopFlag4);
final Set<Integer> deafClientObservedIds = new ConcurrentHashSet<>();
startListening(5, true, deafClientObservedIds);
final Set<Integer> regClientObservedIds = new ConcurrentHashSet<>();
startListening(6, false, regClientObservedIds);
START_LATCH.countDown();
Thread killer = new Thread(new ServerNodeKiller());
Thread resurrection = new Thread(new ServerNodeResurrection());
killer.setName(""node-killer-thread"");
killer.start();
resurrection.setName(""node-resurrection-thread"");
resurrection.start();
while (!updatesQueue.isEmpty())
Thread.sleep(1000);
killer.interrupt();
resurrection.interrupt();
}",concurrency,1
65,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testInitialFactory,"@Test
public void testInitialFactory() throws Exception {
System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
InitialContext initialContext = new InitialContext();
Context context = (Context) initialContext.lookup("""");
assertTrue(context instanceof NamingContext);
if (!NamingManager.hasInitialContextFactoryBuilder()) {
NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder());
}
initialContext = new InitialContext();
context = (Context) initialContext.lookup("""");
assertTrue(context instanceof NamingContext);
}",test order dependency,4
66,atlasdb,incrementUpperLimitIfOneMinuteElapsedSinceLastUpdate,"@Test
public void incrementUpperLimitIfOneMinuteElapsedSinceLastUpdate() throws InterruptedException {
Clock clock = mock(Clock.class);
when(clock.getTimeMillis()).thenReturn(0L, TWO_MINUTES_IN_MILLIS, 2 * TWO_MINUTES_IN_MILLIS, 3 * TWO_MINUTES_IN_MILLIS);
TimestampBoundStore timestampBoundStore = initialTimestampBoundStore();
PersistentTimestampService persistentTimestampService = PersistentTimestampService.create(timestampBoundStore, clock);
persistentTimestampService.getFreshTimestamp();
Thread.sleep(10);
persistentTimestampService.getFreshTimestamp();
Thread.sleep(10);
verify(timestampBoundStore, atLeast(2)).storeUpperLimit(anyLong());
}",async wait,0
67,spring-data-keyvalue,MapKeyValueAdapterUnitTests.scanShouldIterateOverAvailableEntries,"@Test
void scanShouldIterateOverAvailableEntries() {
adapter.put(""1"", object1, COLLECTION_1);
adapter.put(""2"", object2, COLLECTION_1);
CloseableIterator<Map.Entry<Object, Object>> iterator = adapter.entries(COLLECTION_1);
assertThat(iterator.next()).isEqualTo(new AbstractMap.SimpleEntry<>(""1"", object1));
assertThat(iterator.next()).isEqualTo(new AbstractMap.SimpleEntry<>(""2"", object2));
assertThat(iterator.hasNext()).isFalse();
}",unordered collections,3
68,androidx,testUnsubscribeWithSubscriptionCallbackForMultipleSubscriptions,"@Test
public void testUnsubscribeWithSubscriptionCallbackForMultipleSubscriptions() throws Exception {
connectMediaBrowserService();
final List<StubSubscriptionCallback> subscriptionCallbacks = new ArrayList<>();
final int pageSize = 1;
for (int page = 0; page < 4; page++) {
final StubSubscriptionCallback callback = new StubSubscriptionCallback();
subscriptionCallbacks.add(callback);
Bundle options = new Bundle();
options.putInt(MediaBrowserCompat.EXTRA_PAGE, page);
options.putInt(MediaBrowserCompat.EXTRA_PAGE_SIZE, pageSize);
callback.reset(1);
mMediaBrowser.subscribe(MEDIA_ID_ROOT, options, callback);
callback.await(TIME_OUT_MS);
assertEquals(1, callback.mChildrenLoadedWithOptionCount);
}
final int[] orderOfRemovingCallbacks = {2, 0, 3, 1};
for (int i = 0; i < orderOfRemovingCallbacks.length; i++) {
for (StubSubscriptionCallback callback : subscriptionCallbacks) {
callback.reset(1);
}
mMediaBrowser.unsubscribe(MEDIA_ID_ROOT,
subscriptionCallbacks.get(orderOfRemovingCallbacks[i]));
callMediaBrowserServiceMethod(NOTIFY_CHILDREN_CHANGED, MEDIA_ID_ROOT,
getApplicationContext());
try {
Thread.sleep(SLEEP_MS);
} catch (InterruptedException e) {
fail(""Unexpected InterruptedException occurred."");
}
for (int j = 0; j < 4; j++) {
int childrenLoadedWithOptionsCount = subscriptionCallbacks
.get(orderOfRemovingCallbacks[j]).mChildrenLoadedWithOptionCount;
if (j <= i) {
assertEquals(0, childrenLoadedWithOptionsCount);
} else {
assertEquals(1, childrenLoadedWithOptionsCount);
}
}
}
}",async wait,0
69,samza,TestContainerAllocatorWithHostAffinity.testExpiredRequestAllocationOnAnyHost,"@Test
public void testExpiredRequestAllocationOnAnyHost() throws Exception {
MockClusterResourceManager spyManager = spy(new MockClusterResourceManager(callback, state));
ContainerManager spyContainerManager = spy(new ContainerManager(containerPlacementMetadataStore, state, spyManager, true, false, mock(LocalityManager.class), faultDomainManager, config));
spyAllocator = Mockito.spy(new ContainerAllocator(spyManager, config, state, true, spyContainerManager));
spyAllocator.requestResources(new HashMap<String, String>() {
{
put(""0"", ""hostname-0"");
put(""1"", ""hostname-1"");
}
});
spyAllocatorThread = new Thread(spyAllocator);
spyAllocatorThread.start();
Thread.sleep(1000);
assertTrue(state.preferredHostRequests.get() == 2);
assertTrue(state.expiredPreferredHostRequests.get() == 2);
verify(spyContainerManager, times(1)).handleExpiredRequest(eq(""0""), eq(""hostname-0""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class));
verify(spyContainerManager, times(1)).handleExpiredRequest(eq(""1""), eq(""hostname-1""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class));
ArgumentCaptor<SamzaResourceRequest> cancelledRequestCaptor = ArgumentCaptor.forClass(SamzaResourceRequest.class);
verify(spyManager, atLeast(2)).cancelResourceRequest(cancelledRequestCaptor.capture());
assertTrue(cancelledRequestCaptor.getAllValues().stream().map(( resourceRequest) -> resourceRequest.getPreferredHost()).collect(Collectors.toSet()).size() > 2);
assertTrue(state.matchedResourceRequests.get() == 0);
assertTrue(state.anyHostRequests.get() > 2);
spyAllocator.stop();
}",async wait,0
70,OpenLCB_Java,MemoryConfigurationServiceInterfaceTest.testReadWithTimeoutInterleaved,"@Test
public void testReadWithTimeoutInterleaved() {
int space = 0xfd;
long address = 0x12345678;
int length = 4;
MemoryConfigurationService.McsReadHandler hnd = mock(McsReadHandler.class);
MemoryConfigurationService.McsReadHandler hnd2 = mock(McsReadHandler.class);
iface.getDatagramMeteringBuffer().setTimeout(30);
iface.getMemoryConfigurationService().setTimeoutMillis(30);
{
iface.getMemoryConfigurationService().requestRead(farID, space, address, length, hnd);
expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x78, 4 }));
System.err.println(""Expect 'Never received reply' here -->"");
delay(50);
System.err.println(""<--"");
verify(hnd).handleFailure(0x100);
verifyNoMoreInteractions(hnd);
iface.getMemoryConfigurationService().requestRead(farID, space, address + 1, length, hnd2);
expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 }));
sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
consumeMessages();
sendMessage(new DatagramRejectedMessage(farID, hereID, 0x2020));
consumeMessages();
System.err.println(""Expect 'unexpected response datagram' here -->"");
sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x78, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID));
System.err.println(""<--"");
expectNoMessages();
delay(50);
expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 }));
sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
consumeMessages();
sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
consumeMessages();
sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x79, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID));
verify(hnd2).handleReadData(farID, space, address + 1, new byte[]{ ((byte) (0xaa)) });
verifyNoMoreInteractions(hnd2);
}
System.err.println(""Sending another request..."");
sendAnother(space, address + 5);
}",async wait,0
71,androidx,testOneTimeWorkRequest_backedOff,"@Test
public void testOneTimeWorkRequest_backedOff() {
val now = System.currentTimeMillis() ;
when(mTaskConverter.now()).thenReturn(now) ;
val request = OneTimeWorkRequestBuilder<TestWorker>().setInitialRunAttemptCount(1).build() ;
val workSpec = request.workSpec ;
val expected = workSpec.calculateNextRunTime();
val offset = offset(expected, now) ,
val delta = task.windowEnd - (offset + EXECUTION_WINDOW_SIZE_IN_SECONDS);
val task = mTaskConverter.convert(request.workSpec);
assertEquals(task.serviceName, WorkManagerGcmService::class.java.name);
assertEquals(task.isPersisted, false);
assertEquals(task.isUpdateCurrent, true);
assertEquals(task.requiredNetwork, Task.NETWORK_STATE_ANY);
assertEquals(task.requiresCharging, false);
assertEquals(task.windowStart, offset);
assertEquals(task.windowEnd, offset + EXECUTION_WINDOW_SIZE_IN_SECONDS);
}",time,2
72,elassandra,testTokenExpiry,"@Test
public void testTokenExpiry() throws Exception {
ClockMock clock = ClockMock.frozen();
TokenService tokenService = createTokenService(tokenServiceEnabledSettings, clock);
Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
final UserToken token = tokenFuture.get().v1();
mockGetTokenFromId(token);
mockCheckTokenInvalidationFromId(token);
authentication = token.getAuthentication();
ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
storeTokenHeader(requestContext, tokenService.getUserTokenString(token));
try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
PlainActionFuture<UserToken> future = new PlainActionFuture<>();
tokenService.getAndValidateToken(requestContext, future);
assertAuthenticationEquals(authentication, future.get().getAuthentication());
}
final TimeValue defaultExpiration = TokenService.TOKEN_EXPIRATION.get(Settings.EMPTY);
final int fastForwardAmount = randomIntBetween(1, Math.toIntExact(defaultExpiration.getSeconds()) - 5);
try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
clock.fastForwardSeconds(Math.toIntExact(defaultExpiration.getSeconds()) - fastForwardAmount);
clock.rewind(TimeValue.timeValueNanos(clock.instant().getNano()));
PlainActionFuture<UserToken> future = new PlainActionFuture<>();
tokenService.getAndValidateToken(requestContext, future);
assertAuthenticationEquals(authentication, future.get().getAuthentication());
}
assertSettingDeprecationsAndWarnings(new Setting[] { TokenService.BWC_ENABLED });
}",time,2
73,activemq,InactivityMonitorTest.testClientHang,"@Test
public void testClientHang() throws Exception {
clientTransport = new TcpTransport(new OpenWireFormat(), SocketFactory.getDefault(), new URI(""tcp://localhost:61616""), null) ;
clientTransport.setTransportListener(new TransportListener() {
public void onCommand(Object command) {
clientReceiveCount.incrementAndGet();
if (clientRunOnCommand != null) {
clientRunOnCommand.run();
}
}
clientTransport.start();
WireFormatInfo info = new WireFormatInfo();
info.setMaxInactivityDuration(1000);
clientTransport.oneway(info);
assertEquals(0, serverErrorCount.get());
assertEquals(0, clientErrorCount.get());
Thread.sleep(3000);
assertEquals(0, clientErrorCount.get());
assertTrue(serverErrorCount.get() > 0);
}",async wait,0
74,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBind.2,"@Test
public void testBind() throws Exception {
final Name name = new CompositeName(""test"");
final Object value = new Object();
WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
try {
store.bind(name, value);
} finally {
WritableServiceBasedNamingStore.popOwner();
}
assertEquals(value, store.lookup(name));
}",test order dependency,4
75,hadoop,TestPathData.testUnqualifiedUriContents,"@Test
public void testUnqualifiedUriContents() throws Exception {
dirString = ""d1"";
item = new PathData(dirString, conf);
PathData[] items = item.getDirectoryContents();
assertEquals(sortedString(""d1/f1"", ""d1/f1.1"", ""d1/f2""), sortedString(items));
}",test order dependency,4
76,dex,assertDurationIsInRange,"@Test
public void assertDurationIsInRange(long expectedMillis) {
long minimum = (long) ((double) expectedMillis * 0.90);
long maximum =
Math.max((long) ((double) expectedMillis * 1.10), 10);
long waitMillis = Math.max(expectedMillis * 10, 10);
long duration = getDurationMillis(waitMillis);
if (duration < minimum) {
Assert.fail(""expected duration: "" + expectedMillis +
"" minimum duration: "" + minimum +
"" actual duration too short: "" + duration);
} else if (duration > maximum) {
Assert.fail(""expected duration: "" + expectedMillis +
"" maximum duration: "" + maximum +
"" actual duration too long: "" + duration);
}
}",time,2
77,kylin,CoordinatorTest.testReassignFailOnStopAndSync,"@Test
public void testReassignFailOnStopAndSync() throws IOException {
ReceiverAdminClient receiverAdminClient = mockReceiverClientFailOnStopAndSync();
coordinator = new Coordinator(metadataStore, receiverAdminClient);
Map<Integer, List<Partition>> preAssignMap = metadataStore.getAssignmentsByCube(cubeName).getAssignments();
Map<Integer, List<Partition>> newAssignMap = new HashMap<>();
newAssignMap.put(1, Lists.newArrayList(p1, p2, p3));
newAssignMap.put(2, Lists.newArrayList(p4, p5));
newAssignMap.put(3, Lists.newArrayList(p6));
CubeAssignment preAssigment = new CubeAssignment(cube.getName(), preAssignMap);
CubeAssignment newAssigment = new CubeAssignment(cube.getName(), newAssignMap);
try {
coordinator.doReassign(cube, preAssigment, newAssigment);
} catch (ClusterStateException rune) {
assertSame(ROLLBACK_FAILED, rune.getClusterState());
assertSame(STOP_AND_SNYC, rune.getTransactionStep());
System.out.println(rune.getMessage());
throw rune;
}
}",unordered collections,3
78,pulsar,testTransactionMetaStoreAssignAndFailover,"@Test
public void testTransactionMetaStoreAssignAndFailover() throws IOException, InterruptedException {
int transactionMetaStoreCount = 0;
for (PulsarService pulsarService : pulsarServices) {
transactionMetaStoreCount += pulsarService.getTransactionMetadataStoreService().getStores().size();
}
Assert.assertEquals(transactionMetaStoreCount, 16);
PulsarService crashedMetaStore = null;
for (int i = pulsarServices.length - 1; i >= 0; i--) {
if (pulsarServices[i].getTransactionMetadataStoreService().getStores().size() > 0) {
crashedMetaStore = pulsarServices[i];
break;
}
}
Assert.assertNotNull(crashedMetaStore);
List<PulsarService> services = new ArrayList<>(pulsarServices.length - 1);
for (PulsarService pulsarService : pulsarServices) {
if (pulsarService != crashedMetaStore) {
services.add(pulsarService);
}
}
pulsarServices = new PulsarService[pulsarServices.length - 1];
for (int i = 0; i < services.size(); i++) {
pulsarServices[i] = services.get(i);
}
crashedMetaStore.close();
Thread.sleep(3000);
transactionMetaStoreCount = 0;
for (PulsarService pulsarService : pulsarServices) {
transactionMetaStoreCount += pulsarService.getTransactionMetadataStoreService().getStores().size();
}
Assert.assertEquals(transactionMetaStoreCount, 16);
transactionCoordinatorClient.close();
}",async wait,0
79,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRejectionEAP6,"@Test
public void testRejectionsEAP6() throws Exception {
testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_6_4_0, ModelVersion.create(1, 3),""jboss-as-naming"");
}",test order dependency,4
80,jackson-databind,TestGenerateJsonSchema.testUnwrapping,"@Test
public void testUnwrapping() throws Exception {
JsonSchema jsonSchema = MAPPER.generateJsonSchema(UnwrappingRoot.class);
String json = jsonSchema.toString().replaceAll(""\"""", ""'"");
String EXP = ""{'type':'object',"" + (""'properties':{'age':{'type':'integer'},"" + ""'name.first':{'type':'string'},'name.last':{'type':'string'}}}"");
assertEquals(EXP, json);
}",unordered collections,3
81,dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testEmptyByteArrayForEmptyInput,"@Test
public void testEmptyByteArrayForEmptyInput() throws IOException {
this.fstObjectInput = new FstObjectInput(new ByteArrayInputStream("""".getBytes()));
byte[] bytes = fstObjectInput.readBytes();
assertThat(bytes.length, is(0));
}",test order dependency,4
82,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupLink,"@Test
public void testLookupLink() throws Exception {
final Name name = new CompositeName(""test"");
namingStore.bind(name, ""testValue"", String.class);
final Name linkName = new CompositeName(""link"");
namingStore.bind(linkName, new LinkRef(""./test""));
Object result = namingContext.lookup(linkName);
assertEquals(""testValue"", result);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
assertEquals(""testValue"", result);
System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
namingStore.rebind(linkName, new LinkRef(name));
result = namingContext.lookup(linkName);
assertEquals(""testValue"", result);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
assertEquals(""testValue"", result);
}",test order dependency,4
83,okhttp,CallTest.legalToExecuteTwiceCloning_Async,"@Test
public void legalToExecuteTwiceCloning_Async() throws Exception {
server.enqueue(new MockResponse().setBody(""abc""));
server.enqueue(new MockResponse().setBody(""def""));
Request request = new Request.Builder().url(server.url(""/"")).build();
Call call = client.newCall(request);
call.enqueue(callback);
Call cloned = call.clone();
cloned.enqueue(callback);
callback.await(request.url()).assertBody(""abc"");
callback.await(request.url()).assertBody(""def"");
}",async wait,0
84,marine-api,af0003847db9ba822f67d4f1dceb8de3fe63250a.testSequenceListenerWithIncorrectOrder,"@Test
public void testSequenceListenerWithIncorrectOrder() {
SequenceListener sl = new SequenceListener();
sl.sentenceRead(AIS_05_2);
assertNull(sl.received);
sl.sentenceRead(AIS_05_1);
assertNull(sl.received);
sl.sentenceRead(AIS_05_2);
assertEquals(sl.received.toString(), MSG_05.toString());
}",test order dependency,4
85,hbase,TestSplitTransactionOnCluster.testRSSplitEphemeralsDisappearButDaughtersAreOnlinedAfterShutdownHandling,"@Test
public class Test {
@Test(timeout = 300000)
public void testRSSplitEphemeralsDisappearButDaughtersAreOnlinedAfterShutdownHandling() throws IOException, InterruptedException, NodeExistsException, KeeperException {
final byte[] tableName = Bytes.toBytes(""ephemeral"");
HTable t = TESTING_UTIL.createTable(tableName, CATALOG_FAMILY);
List<HRegion> regions = cluster.getRegions(tableName);
HRegionInfo hri = getAndCheckSingleTableRegion(regions);
int tableRegionIndex = ensureTableRegionNotOnSameServerAsMeta(admin, hri);
this.admin.setBalancerRunning(false, true);
cluster.getMaster().setCatalogJanitorEnabled(false);
try {
TESTING_UTIL.loadTable(t, CATALOG_FAMILY);
HRegionServer server = cluster.getRegionServer(tableRegionIndex);
printOutRegions(server, ""Initial regions: "");
int regionCount = server.getOnlineRegions().size();
SplitRegionHandler.TEST_SKIP = true;
split(hri, server, regionCount);
List<HRegion> daughters = cluster.getRegions(tableName);
assertTrue(daughters.size() >= 2);
String path = ZKAssign.getNodeName(t.getConnection().getZooKeeperWatcher(), hri.getEncodedName());
Stat stats = t.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(path, false);
LOG.info(((""EPHEMERAL NODE BEFORE SERVER ABORT, path="" + path) + "", stats="") + stats);
RegionTransitionData rtd = ZKAssign.getData(t.getConnection().getZooKeeperWatcher(), hri.getEncodedName());
assertTrue(rtd.getEventType().equals(RS_ZK_REGION_SPLIT) || rtd.getEventType().equals(RS_ZK_REGION_SPLITTING));
cluster.abortRegionServer(tableRegionIndex);
waitUntilRegionServerDead();
while (cluster.getRegions(tableName).size() < daughters.size()) {
LOG.info(""Waiting for repair to happen"");
Thread.sleep(1000);
}
regions = cluster.getRegions(tableName);
for (HRegion r : regions) {
assertTrue(daughters.contains(r));
}
stats = t.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(path, false);
LOG.info(((""EPHEMERAL NODE AFTER SERVER ABORT, path="" + path) + "", stats="") + stats);
assertTrue(stats == null);
} finally {
SplitRegionHandler.TEST_SKIP = false;
admin.setBalancerRunning(true, false);
cluster.getMaster().setCatalogJanitorEnabled(true);
}
}
}",async wait,0
86,jackson-datatypes-collections,twin,"@Test
public void twin() throws Exception {
final ObjectMapper mapper = mapperWithModule();
Object sampleOne = randomSample(Object.class);
Object sampleTwo = randomSample(Object.class);
String expectedJson = ""{\""one\"":"" + mapper.writeValueAsString(sampleOne);
Twin<String> twin = Tuples.twin((String) sampleOne, (String) sampleTwo);
Assert.assertEquals(expectedJson, mapper.writeValueAsString(twin));
Assert.assertEquals(twin, mapper.readValue(expectedJson, new TypeReference<Twin<String>>() {}));
}",unordered collections,3
87,httpcomponents,TestConnPool.testLeaseRelease,"@Test
public void testLeaseRelease() throws Exception {
HttpConnection conn1 = Mockito.mock(HttpConnection.class);
HttpConnection conn2 = Mockito.mock(HttpConnection.class);
LocalConnFactory connFactory = Mockito.mock(LocalConnFactory.class);
Mockito.when(connFactory.create(Mockito.eq(""somehost""))).thenReturn(conn1);
Mockito.when(connFactory.create(Mockito.eq(""otherhost""))).thenReturn(conn2);
LocalConnPool pool = new LocalConnPool(connFactory, 2, 10);
Future<LocalPoolEntry> future1 = pool.lease(""somehost"", null);
LocalPoolEntry entry1 = future1.get(1, TimeUnit.SECONDS);
Assert.assertNotNull(entry1);
Future<LocalPoolEntry> future2 = pool.lease(""somehost"", null);
LocalPoolEntry entry2 = future2.get(1, TimeUnit.SECONDS);
Assert.assertNotNull(entry2);
Future<LocalPoolEntry> future3 = pool.lease(""otherhost"", null);
LocalPoolEntry entry3 = future3.get(1, TimeUnit.SECONDS);
Assert.assertNotNull(entry3);
PoolStats totals = pool.getTotalStats();
Assert.assertEquals(0, totals.getAvailable());
Assert.assertEquals(3, totals.getLeased());
LocalPoolEntry entry = future1.get();
Assert.assertSame(entry1, entry);
pool.release(entry1, true);
pool.release(entry2, true);
pool.release(entry3, false);
Mockito.verify(conn1, Mockito.never()).close();
Mockito.verify(conn2, Mockito.times(1)).close();
totals = pool.getTotalStats();
Assert.assertEquals(2, totals.getAvailable());
Assert.assertEquals(0, totals.getLeased());
}",concurrency,1
88,togglz,ZookeeperStateRepositoryTest.testZkNodeChangesUpdateFeatureState,"@Test
public void testZkNodeChangesUpdateFeatureState() throws Exception {
setupTestWithEmptyDatastore();
FeatureState savedFeatureState = new FeatureState(TestFeature.FEATURE);
savedFeatureState.setStrategyId(ID);
savedFeatureState.setParameter(PARAM_USERS, ""user1, user2, user3"");
stateRepository.setFeatureState(savedFeatureState);
FeatureState loadedFeatureState = stateRepository.getFeatureState(TestFeature.FEATURE);
assertThat(reflectionEquals(savedFeatureState, loadedFeatureState), is(true));
FeatureStateStorageWrapper externallySetStateWrapper = new FeatureStateStorageWrapper();
FeatureState externallySetState = new FeatureState(TestFeature.FEATURE);
ObjectMapper objectMapper = new ObjectMapper();
final String json = objectMapper.writeValueAsString(externallySetStateWrapper);
final CountDownLatch latch = new CountDownLatch(1);
new Thread(new Runnable() {
@Override
public void run() {
try {
serverClientPair.client.setData().forPath(TEST_ZNODE + ""/FEATURE"", json.getBytes(""UTF-8""));
latch.countDown();
} catch (Exception e) {
e.printStackTrace();
}
}
}).start();
latch.await(2, TimeUnit.SECONDS);
Thread.sleep(25);
loadedFeatureState = stateRepository.getFeatureState(TestFeature.FEATURE);
assertThat(reflectionEquals(externallySetState, loadedFeatureState), is(true));
}",async wait,0
89,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupReference,"@Test
public void testLookupReference() throws Exception {
final Name name = new CompositeName(""test"");
final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null);
namingStore.bind(name, reference);
Object result = namingContext.lookup(name);
assertEquals(""test"", result);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
assertEquals(""test"", result);
}",test order dependency,4
90,servicemix,CxfBCConsumerAsynTest.multiClientTestBase,"@Test
private void multiClientTestBase() throws Exception {
URL wsdl = getClass().getResource(""/wsdl/calculator.wsdl"");
assertNotNull(wsdl);
CalculatorService service = new CalculatorService(wsdl, new QName(""http://apache.org/cxf/calculator"", ""CalculatorService""));
QName endpoint = new QName(""http://apache.org/cxf/calculator"", ""CalculatorPort"");
service.addPort(endpoint, SOAPBinding.SOAP12HTTP_BINDING, ""http://localhost:19000/CalculatorService/SoapPort"");
CalculatorPortType port = service.getPort(endpoint, CalculatorPortType.class);
ClientProxy.getClient(port).getInInterceptors().add(new LoggingInInterceptor());
ClientProxy.getClient(port).getOutInterceptors().add(new LoggingOutInterceptor());
MultiClientThread[] clients = new MultiClientThread[2];
for (int i = 0; i < clients.length; i++) {
clients[i] = new MultiClientThread(port, i);
}
for (int i = 0; i < clients.length; i++) {
clients[i].start();
Thread.sleep(2000);
}
for (int i = 0; i < clients.length; i++) {
clients[i].join();
assertEquals(clients[i].getResult(), ""20"");
}
}",async wait,0
91,continuum,QueueTest.testQueuePageWithProjectCurrentlyBuilding,"@Test
public void testQueuePageWithProjectCurrentlyBuilding() throws Exception {
String M2_PROJ_GRP_NAME = getProperty(""M2_PROJ_GRP_NAME"");
String M2_PROJ_GRP_ID = getProperty(""M2_PROJ_GRP_ID"");
String M2_PROJ_GRP_DESCRIPTION = getProperty(""M2_PROJ_GRP_DESCRIPTION"");
buildProjectForQueuePageTest(M2_PROJ_GRP_NAME, M2_PROJ_GRP_ID, M2_PROJ_GRP_DESCRIPTION, M2_PROJ_GRP_NAME);
String location = getSelenium().getLocation();
clickAndWait(""link=Queues"");
assertPage(""Continuum - Build Queue"");
assertTextPresent(""Current Build"");
assertTextPresent(""Build Queue"");
assertTextPresent(""Current Checkout"");
assertTextPresent(""Checkout Queue "");
assertTextPresent(""Current Prepare Build"");
assertTextPresent(""Prepare Build Queue"");
assertElementPresent();
assertTextPresent(M2_PROJ_GRP_NAME);
getSelenium().open(location);
waitPage();
waitForElementPresent();
}",async wait,0
92,pulsar,KeySharedSubscriptionTest.testRemoveFirstConsumer,"@Test
public void testRemoveFirstConsumer() throws Exception {
this.conf.setSubscriptionKeySharedEnable(true);
String topic = ""testReadAheadWhenAddingConsumers-"" + UUID.randomUUID();
@Cleanup
Producer<Integer> producer = createProducer(topic, false);
@Cleanup
Consumer<Integer> c1 = pulsarClient.newConsumer(INT32).topic(topic).subscriptionName(""key_shared"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c1"").subscribe();
for (int i = 0; i < 10; i++) {
producer.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(i).send();
}
@Cleanup
Consumer<Integer> c2 = pulsarClient.newConsumer(INT32).topic(topic).subscriptionName(""key_shared"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c2"").subscribe();
for (int i = 10; i < 20; i++) {
producer.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(i).send();
}
assertNull(c2.receive(100, TimeUnit.MILLISECONDS));
c1.close();
for (int i = 0; i < 20; i++) {
Message<Integer> msg = c2.receive();
assertEquals(msg.getValue().intValue(), i);
c2.acknowledge(msg);
}
}",async wait,0
93,spring-data-gemfire,CollectionUtilsUnitTests.iterableOfIterator,"@Test
public void iterableOfIterator() {
Iterator<Object> mockIterator = mock(Iterator.class, ""MockIterator"");
when(mockIterator.hasNext()).thenReturn(true).thenReturn(true).thenReturn(true).thenReturn(false);
when(mockIterator.next()).thenReturn(1).thenReturn(2).thenReturn(3).thenThrow(new NoSuchElementException(""Iterator exhausted""));
Iterable<Object> iterable = CollectionUtils.iterable(mockIterator);
assertThat(iterable).isNotNull();
Set<Object> set = new HashSet<>();
iterable.forEach(set::add);
assertThat(set).hasSize(3);
assertThat(set).containsExactly(1, 2, 3);
verify(mockIterator, times(4)).hasNext();
verify(mockIterator, times(3)).next();
}",unordered collections,3
94,pulsar,PersistentFailoverE2ETest.testSimpleConsumerEventsWithoutPartition,"@Test
public void testSimpleConsumerEventsWithoutPartition() throws Exception {
final String topicName = ""persistent"";
final String subName = ""sub1"";
final int numMsgs = 100;
TestConsumerStateEventListener listener1 = new TestConsumerStateEventListener();
TestConsumerStateEventListener listener2 = new TestConsumerStateEventListener();
ConsumerBuilder<byte[]> consumerBuilder = pulsarClient.newConsumer().topic(topicName).subscriptionName(subName).acknowledgmentGroupTime(0, TimeUnit.SECONDS).subscriptionType(Failover);
ConsumerBuilder<byte[]> consumerBulder1 = consumerBuilder.clone().consumerName(""1"").consumerEventListener(listener1).acknowledgmentGroupTime(0, TimeUnit.SECONDS);
Consumer<byte[]> consumer1 = consumerBulder1.subscribe();
Consumer<byte[]> consumer2 = consumerBuilder.clone().consumerName(""2"").consumerEventListener(listener2).subscribe();
verifyConsumerActive(listener1, -1);
verifyConsumerInactive(listener2, -1);
PersistentTopic topicRef = ((PersistentTopic) (pulsar.getBrokerService().getTopicReference(topicName).get()));
PersistentSubscription subRef = topicRef.getSubscription(subName);
assertNotNull(topicRef);
assertNotNull(subRef);
assertTrue(subRef.getDispatcher().isConsumerConnected());
assertEquals(subRef.getDispatcher().getType(), Failover);
List<CompletableFuture<MessageId>> futures = Lists.newArrayListWithCapacity(numMsgs);
Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName).enableBatching(false).messageRoutingMode(SinglePartition).create();
for (int i = 0; i < numMsgs; i++) {
String message = ""my-message-"" + i;
futures.add(producer.sendAsync(message.getBytes()));
}
FutureUtil.waitForAll(futures).get();
futures.clear();
rolloverPerIntervalStats();
assertEquals(subRef.getNumberOfEntriesInBacklog(), numMsgs);
Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT);
Message<byte[]> msg = null;
Assert.assertNull(consumer2.receive(1, TimeUnit.SECONDS));
for (int i = 0; i < numMsgs; i++) {
msg = consumer1.receive(1, TimeUnit.SECONDS);
Assert.assertNotNull(msg);
Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i);
consumer1.acknowledge(msg);
}
rolloverPerIntervalStats();
Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT);
assertEquals(subRef.getNumberOfEntriesInBacklog(), 0);
for (int i = 0; i < numMsgs; i++) {
String message = ""my-message-"" + i;
futures.add(producer.sendAsync(message.getBytes()));
}
FutureUtil.waitForAll(futures).get();
futures.clear();
for (int i = 0; i < 5; i++) {
msg = consumer1.receive(1, TimeUnit.SECONDS);
Assert.assertNotNull(msg);
Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i);
consumer1.acknowledge(msg);
}
for (int i = 5; i < 10; i++) {
msg = consumer1.receive(1, TimeUnit.SECONDS);
Assert.assertNotNull(msg);
Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i);
}
consumer1.close();
Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME);
verifyConsumerActive(listener2, -1);
verifyConsumerNotReceiveAnyStateChanges(listener1);
for (int i = 5; i < numMsgs; i++) {
msg = consumer2.receive(1, TimeUnit.SECONDS);
Assert.assertNotNull(msg);
Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i);
consumer2.acknowledge(msg);
}
Assert.assertNull(consumer2.receive(1, TimeUnit.SECONDS));
rolloverPerIntervalStats();
Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT);
assertEquals(subRef.getNumberOfEntriesInBacklog(), 0);
for (int i = 0; i < numMsgs; i++) {
String message = ""my-message-"" + i;
futures.add(producer.sendAsync(message.getBytes()));
}
FutureUtil.waitForAll(futures).get();
futures.clear();
for (int i = 0; i < 5; i++) {
msg = consumer2.receive(1, TimeUnit.SECONDS);
Assert.assertNotNull(msg);
Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i);
consumer2.acknowledge(msg);
}
consumer1 = consumerBulder1.subscribe();
Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME);
for (int i = 5; i < numMsgs; i++) {
msg = consumer1.receive(1, TimeUnit.SECONDS);
Assert.assertNotNull(msg);
Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i);
consumer1.acknowledge(msg);
}
Assert.assertNull(consumer1.receive(1, TimeUnit.SECONDS));
rolloverPerIntervalStats();
Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT);
assertEquals(subRef.getNumberOfEntriesInBacklog(), 0);
for (int i = 0; i < numMsgs; i++) {
String message = ""my-message-"" + i;
futures.add(producer.sendAsync(message.getBytes()));
}
FutureUtil.waitForAll(futures).get();
futures.clear();
for (int i = 0; i < 5; i++) {
msg = consumer1.receive(1, TimeUnit.SECONDS);
Assert.assertNotNull(msg);
Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i);
consumer1.acknowledge(msg);
}
TestConsumerStateEventListener listener3 = new TestConsumerStateEventListener();
Consumer<byte[]> consumer3 = consumerBuilder.clone().consumerName(""3"").consumerEventListener(listener3).subscribe();
Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME);
verifyConsumerInactive(listener3, -1);
Assert.assertNull(consumer3.receive(1, TimeUnit.SECONDS));
for (int i = 5; i < numMsgs; i++) {
msg = consumer1.receive(1, TimeUnit.SECONDS);
Assert.assertNotNull(msg);
Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i);
consumer1.acknowledge(msg);
}
rolloverPerIntervalStats();
Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT);
assertEquals(subRef.getNumberOfEntriesInBacklog(), 0);
try {
consumer1.unsubscribe();
fail(""should fail"");
} catch (PulsarClientException e) {
}
consumer1.close();
Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME);
consumer2.close();
Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME);
try {
consumer3.unsubscribe();
} catch (PulsarClientException e) {
fail(""Should not fail"", e);
}
Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT);
subRef = topicRef.getSubscription(subName);
assertNull(subRef);
producer.close();
consumer3.close();
admin.topics().delete(topicName);
}",concurrency,1
95,flume,TestConcurrentDFOMan.doTestLogicalNodesConcurrentDFOMans,"@Test
public void doTestLogicalNodesConcurrentDFOMans(final int threads,
final int events, int timeout) throws IOException, InterruptedException,
FlumeSpecException {
BenchmarkHarness.setupLocalWriteDir();
FlumeMaster master = new FlumeMaster();
FlumeNode node = new FlumeNode(new DirectMasterRPC(master), false, false);
final Reportable[] dfos = new Reportable[threads];
for (int i = 0; i < threads; i++) {
String name = ""test."" + i;
String report = ""report."" + i;
int count = events + i;
String src = ""asciisynth("" + count + "",100)"";
String snk = ""{ diskFailover => counter(\"""" + report + ""\"") } "";
node.getLogicalNodeManager().testingSpawn(name, src, snk);
dfos[i] = node.getLogicalNodeManager().get(name);
}
waitForEmptyDFOs(node, timeout);
boolean success = true;
for (int i = 0; i < threads; i++) {
LOG.info(dfos[i].getReport());
}
for (int i = 0; i < threads; i++) {
CounterSink cnt = (CounterSink) ReportManager.get().getReportable(
""report."" + i);
LOG.info(i + "" expected "" + (events + i) + "" and got "" + cnt.getCount());
success &= ((events + i) == cnt.getCount());
assertEquals(events + i, cnt.getCount());
}
assertTrue(""Counts did not line up"", success);
BenchmarkHarness.cleanupLocalWriteDir();
}",async wait,0
96,hadoop,TestBlockFixer.testGeneratedBlock,"@Test
public void testGeneratedBlock() throws Exception {
LOG.info(""Test testGeneratedBlock started."");
long blockSize = 8192L;
int stripeLength = 3;
mySetup(stripeLength, -1);
Path file1 = new Path(""/user/dhruba/raidtest/file1"");
Path destPath = new Path(""/destraid/user/dhruba/raidtest"");
long crc1 = TestRaidDfs.createTestFile(fileSys, file1, 1, 7, blockSize);
long file1Len = fileSys.getFileStatus(file1).getLen();
LOG.info(""Test testGeneratedBlock created test files"");
Configuration localConf = new Configuration(conf);
localConf.set(RAID_LOCATION_KEY, ""/destraid"");
localConf.setInt(""raid.blockfix.interval"", 1000);
localConf.setLong(""raid.blockfix.filespertask"", 2L);
try {
cnode = RaidNode.createRaidNode(null, localConf);
TestRaidDfs.waitForFileRaided(LOG, fileSys, file1, destPath);
cnode.stop();
cnode.join();
FileStatus srcStat = fileSys.getFileStatus(file1);
DistributedFileSystem dfs = ((DistributedFileSystem) (fileSys));
LocatedBlocks locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen());
String[] corruptFiles = RaidDFSUtil.getCorruptFiles(conf);
assertEquals(corruptFiles.length, 0);
assertEquals(0, cnode.blockFixer.filesFixed());
corruptBlock(locs.get(0).getBlock().getBlockName());
reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize);
corruptFiles = RaidDFSUtil.getCorruptFiles(conf);
assertEquals(corruptFiles.length, 1);
assertEquals(corruptFiles[0], file1.toUri().getPath());
cnode = RaidNode.createRaidNode(null, localConf);
long start = System.currentTimeMillis();
while ((cnode.blockFixer.filesFixed() < 1) && ((System.currentTimeMillis() - start) < 120000)) {
LOG.info(""Test testGeneratedBlock waiting for files to be fixed."");
Thread.sleep(1000);
}
assertEquals(1, cnode.blockFixer.filesFixed());
cnode.stop();
cnode.join();
cnode = null;
dfs = getDFS(conf, dfs);
assertTrue(TestRaidDfs.validateFile(dfs, file1, file1Len, crc1));
locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen());
corruptBlock(locs.get(0).getBlock().getBlockName());
reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize);
try {
Thread.sleep(5 * 1000);
} catch (InterruptedException ignore) {
}
try {
TestRaidDfs.validateFile(dfs, file1, file1Len, crc1);
fail(""Expected exception not thrown"");
} catch (ChecksumException ce) {
} catch (BlockMissingException bme) {
}
} catch (Exception e) {
LOG.info((""Test testGeneratedBlock Exception "" + e) + StringUtils.stringifyException(e));
throw e;
} finally {
myTearDown();
}
LOG.info(""Test testGeneratedBlock completed."");
}",concurrency,1
97,trino,testQueryTimeout,"@Test
public void testQueryTimeout()
throws Exception
{
try (Connection connection = createConnection(""blackhole"", ""blackhole"");
Statement statement = connection.createStatement()) {
statement.executeUpdate(""CREATE TABLE test_query_timeout (key BIGINT) "" +
""WITH ("" +
""   split_count = 1, "" +
""   pages_per_split = 1, "" +
""   rows_per_page = 1, "" +
""   page_processing_delay = '1m'"" +
"")"");
}
CountDownLatch queryFinished = new CountDownLatch(1);
AtomicReference<Throwable> queryFailure = new AtomicReference<>();
executorService.submit(() -> {
try (Connection connection = createConnection(""blackhole"", ""default"");
Statement statement = connection.createStatement()) {
statement.setQueryTimeout(1);
try (ResultSet resultSet = statement.executeQuery(""SELECT * FROM test_query_timeout"")) {
try {
resultSet.next();
}
catch (SQLException t) {
queryFailure.set(t);
}
finally {
queryFinished.countDown();
}
}
}
return null;
});
assertTrue(queryFinished.await(2, SECONDS));
assertNotNull(queryFailure.get());
assertContains(queryFailure.get().getMessage(), ""Query exceeded maximum time limit of 1.00s"");
try (Connection connection = createConnection(""blackhole"", ""blackhole"");
Statement statement = connection.createStatement()) {
statement.executeUpdate(""DROP TABLE test_query_timeout"");
}
}",async wait,0
98,cdap,ProgramLifecycleHttpHandlerTest.testStartProgramWithDisabledRuntimeArgs,"@Test
public void testStartProgramWithDisabledRuntimeArgs() throws Exception {
ProfileId profileId = new NamespaceId(TEST_NAMESPACE1).profile(""MyProfile"");
Profile profile = new Profile(""MyProfile"", Profile.NATIVE.getLabel(), Profile.NATIVE.getDescription(),Profile.NATIVE.getScope(), Profile.NATIVE.getProvisioner());
putProfile(profileId, profile, 200);
disableProfile(profileId, 200);
deploy(AppWithWorkflow.class, 200, Constants.Gateway.API_VERSION_3_TOKEN,TEST_NAMESPACE1);
ProgramId programId = new NamespaceId(TEST_NAMESPACE1).app(APP_WITH_WORKFLOW_APP_ID).workflow(APP_WITH_WORKFLOW_WORKFLOW_NAME);
Assert.assertEquals(STOPPED, getProgramStatus(programId));
startProgram(programId, Collections.singletonMap(SystemArguments.PROFILE_NAME, profileId.getScopedName()), 409);
Assert.assertEquals(STOPPED, getProgramStatus(programId));
startProgram(programId, Collections.singletonMap(SystemArguments.PROFILE_NAME, ProfileId.NATIVE.getScopedName()),200);
waitState(programId, STOPPED);
}",async wait,0
99,CoreNLP,DirectedMultiGraphTest.testConnectedComponents,"@Test
public void testConnectedComponents() {
System.out.println(""graph is "" + graph.toString());
List<Set<Integer>> ccs = graph.getConnectedComponents();
for (Set<Integer> cc : ccs) {
System.out.println(""Connected component: "" + cc);
}
assertEquals(ccs.size(), 4);
assertEquals(CollectionUtils.sorted(ccs.get(0)), Arrays.asList(1, 2, 3, 4));
}",unordered collections,3
100,androidx,playbackRate,"@Test
public void playbackRate() throws Exception {
final int toleranceMs = 1000;
Future<PlayerResult> setSurfaceFuture = mPlayer.setSurface(
mActivity.getSurfaceHolder().getSurface());
Future<PlayerResult> prepareFuture = mPlayer.prepare();
assertFutureSuccess(setSurfaceFuture);
assertFutureSuccess(prepareFuture);
float[] rates = {0.25f, 0.5f, 1.0f, 2.0f};
for (float playbackRate : rates) {
Future<PlayerResult> seekFuture = mPlayer.seekTo(0, MediaPlayer.SEEK_PREVIOUS_SYNC);
Thread.sleep(1000);
int playTime = 4000;
int privState = mPlayer.getPlayerState();
Future<PlayerResult> setParamsFuture = mPlayer.setPlaybackParams(
new PlaybackParams.Builder().setSpeed(playbackRate).build());
assertFutureSuccess(seekFuture);
assertFutureSuccess(setParamsFuture);
assertEquals(""setPlaybackParams() should not change player state. ""
+ mPlayer.getPlayerState(), privState, mPlayer.getPlayerState());
Future<PlayerResult> playFuture = mPlayer.play();
Thread.sleep(playTime);
PlaybackParams pbp = mPlayer.getPlaybackParams();
assertEquals(playbackRate, pbp.getSpeed(), FLOAT_TOLERANCE);
assertEquals(""The player should still be playing"",
MediaPlayer.PLAYER_STATE_PLAYING, mPlayer.getPlayerState());
long playedMediaDurationMs = mPlayer.getCurrentPosition();
long expectedPosition = (long) (playTime * playbackRate);
int diff = (int) Math.abs(playedMediaDurationMs - expectedPosition);
if (diff > toleranceMs) {
fail(""Media player had error in playback rate "" + playbackRate
+ "". expected position after playing "" + playTime
+ "" was "" + expectedPosition + "", but actually "" + playedMediaDurationMs);
}
assertFutureSuccess(playFuture);
assertFutureSuccess(mPlayer.pause());
pbp = mPlayer.getPlaybackParams();
assertEquals(""pause() should not change the playback rate property."",
playbackRate, pbp.getSpeed(), FLOAT_TOLERANCE);
}
mPlayer.reset();
}",async wait,0
101,avro,testRecordWithJsr310LogicalTypes,"@Test
public void testRecordWithJsr310LogicalTypes() throws IOException {
TestRecordWithJsr310LogicalTypes record = new TestRecordWithJsr310LogicalTypes(
true,
34,
35L,
3.14F,
3019.34,
null,
java.time.LocalDate.now(),
java.time.LocalTime.now().truncatedTo(ChronoUnit.MILLIS),
java.time.Instant.now().truncatedTo(ChronoUnit.MILLIS),
new BigDecimal(123.45f).setScale(2, BigDecimal.ROUND_HALF_DOWN)
);
File data = write(TestRecordWithJsr310LogicalTypes.getClassSchema(), record);
List<TestRecordWithJsr310LogicalTypes> actual = read(
TestRecordWithJsr310LogicalTypes.getClassSchema(), data);
Assert.assertEquals(""Should match written record"", record, actual.get(0));
}",time,2
102,hbase,TestHRegion.testWritesWhileGetting,"@Test
public void testWritesWhileGetting() throws IOException, InterruptedException {
byte[] tableName = Bytes.toBytes(""testWritesWhileScanning"");
int testCount = 100;
int numRows = 1;
int numFamilies = 10;
int numQualifiers = 100;
int flushInterval = 10;
int compactInterval = 10 * flushInterval;
byte[][] families = new byte[numFamilies][];
for (int i = 0; i < numFamilies; i++) {
families[i] = Bytes.toBytes(""family"" + i);
}
byte[][] qualifiers = new byte[numQualifiers][];
for (int i = 0; i < numQualifiers; i++) {
qualifiers[i] = Bytes.toBytes(""qual"" + i);
}
String method = ""testWritesWhileScanning"";
initHRegion(tableName, method, families);
PutThread putThread = new PutThread(numRows, families, qualifiers);
putThread.start();
FlushThread flushThread = new FlushThread();
flushThread.start();
Get get = new Get(Bytes.toBytes(""row0""));
Result result = null;
int expectedCount = numFamilies * numQualifiers;
long prevTimestamp = 0L;
for (int i = 0; i < testCount; i++) {
if ((i != 0) && ((i % compactInterval) == 0)) {
region.compactStores(true);
}
if ((i != 0) && ((i % flushInterval) == 0)) {
flushThread.flush();
}
boolean previousEmpty = (result == null) || result.isEmpty();
result = region.get(get, null);
if (((!result.isEmpty()) || (!previousEmpty)) || (i > compactInterval)) {
assertEquals(""i="" + i, expectedCount, result.size());
long timestamp = 0;
for (KeyValue kv : result.sorted()) {
if (Bytes.equals(kv.getFamily(), families[0]) && Bytes.equals(kv.getQualifier(), qualifiers[0])) {
timestamp = kv.getTimestamp();
}
}
assertTrue(timestamp >= prevTimestamp);
prevTimestamp = timestamp;
byte[] gotValue = null;
for (KeyValue kv : result.raw()) {
byte[] thisValue = kv.getValue();
if (gotValue != null) {
assertEquals(gotValue, thisValue);
}
gotValue = thisValue;
}
}
}
putThread.done();
region.flushcache();
putThread.join();
putThread.checkNoError();
flushThread.done();
flushThread.join();
flushThread.checkNoError();
}",async wait,0
103,xmlbeans,XmlLoaderMiscTest.testGetContextTypeLoader,"@Test
public void testGetContextTypeLoader() throws Exception {
SchemaTypeLoader stl = XmlBeans.getContextTypeLoader();
if (stl == null) {
fail(""getContextTypeLoader failed"");
}
Vector vThreads = new Vector();
Set STLset = Collections.synchronizedSortedSet(new TreeSet());
for (int i = 0; i < 10; i++) {
Thread t = new BogusThread(STLset);
vThreads.add(t);
t.start();
}
for (int i = 0; i < 10; i++) {
((BogusThread) (vThreads.elementAt(i))).join();
}
assertEquals(10, STLset.size());
}",concurrency,1
104,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListNameNotFound,"@Test
public void testListNameNotFound() throws Exception {
try {
namingContext.list(new CompositeName(""test""));
fail(""Should have thrown and NameNotFoundException"");
} catch (NameNotFoundException expected) {
}
try {
testActionPermission(JndiPermission.ACTION_LIST, namingContext, ""test"");
fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
} catch (NameNotFoundException expected) {
}
}",test order dependency,4
105,hadoop,TestRPCCompatibility.testVersion2ClientVersion2Server,"@Test
public void testVersion2ClientVersion2Server() throws Exception {
ProtocolSignature.resetCache();
TestImpl2 impl = new TestImpl2();
server = new RPC.Builder(conf).setProtocol(TestProtocol2.class).setInstance(impl).setBindAddress(ADDRESS).setPort(0).setNumHandlers(2).setVerbose(false).build();
server.addProtocol(RPC_WRITABLE, TestProtocol0.class, impl);
server.start();
addr = NetUtils.getConnectAddress(server);
Version2Client client = new Version2Client();
client.ping();
assertEquals(""hello"", client.echo(""hello""));
assertEquals(-3, client.echo(3));
}",test order dependency,4
106,servicemix,QuartzComponentTest.test,"@Test
public void test() throws Exception {
JBIContainer jbi = new JBIContainer();
jbi.setEmbedded(true);
jbi.init();
QuartzComponent quartz = new QuartzComponent();
QuartzEndpoint endpoint = new QuartzEndpoint();
endpoint.setService(new QName(""quartz""));
endpoint.setEndpoint(""endpoint"");
endpoint.setTargetService(new QName(""countDownReceiver""));
SimpleTriggerBean trigger = new SimpleTriggerBean();
trigger.setRepeatInterval(100);
trigger.setName(""trigger"");
trigger.afterPropertiesSet();
endpoint.setTrigger(trigger);
quartz.setEndpoints(new QuartzEndpoint[]{ endpoint });
jbi.activateComponent(quartz, ""servicemix-quartz"");
CountDownReceiverComponent receiver = new CountDownReceiverComponent(new QName(""countDownReceiver""), ""endpoint"", 1, 3000);
jbi.activateComponent(receiver, ""countDownReceiver"");
jbi.start();
assertTrue(receiver.getMessageList().flushMessages().size() > 0);
quartz.stop();
receiver.getMessageList().flushMessages();
Thread.sleep(1000);
assertEquals(0, receiver.getMessageList().flushMessages().size());
quartz.start();
receiver.reset();
assertTrue(receiver.getMessageList().flushMessages().size() > 0);
jbi.shutDown();
}",async wait,0
107,hadoop,TestDelegationTokenForProxyUser.testDelegationTokenWithRealUser,"@Test
public void testDelegationTokenWithRealUser() throws IOException {
UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER);
final UserGroupInformation proxyUgi = UserGroupInformation.createProxyUserForTesting(PROXY_USER, ugi, GROUP_NAMES);
try {
Token<?>[] tokens = proxyUgi.doAs(new PrivilegedExceptionAction<Token<?>[]>() {
@Override
public Token<?>[] run() throws IOException {
return cluster.getFileSystem().addDelegationTokens(""RenewerUser"", null);
}
});
DelegationTokenIdentifier identifier = new DelegationTokenIdentifier();
byte[] tokenId = tokens[0].getIdentifier();
identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
Assert.assertEquals(identifier.getUser().getUserName(), PROXY_USER);
Assert.assertEquals(identifier.getUser().getRealUser().getUserName(), REAL_USER);
} catch (InterruptedException e) {
}
}",test order dependency,4
108,hbase,TestRollingRestart.testBasicRollingRestart,"@Test
public void testBasicRollingRestart() throws Exception {
final int NUM_MASTERS = 2;
final int NUM_RS = 3;
final int NUM_REGIONS_TO_CREATE = 20;
int expectedNumRS = 3;
log(""Starting cluster"");
Configuration conf = HBaseConfiguration.create();
conf.setInt(""hbase.master.assignment.timeoutmonitor.period"", 2000);
conf.setInt(""hbase.master.assignment.timeoutmonitor.timeout"", 5000);
HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility(conf);
TEST_UTIL.startMiniCluster(NUM_MASTERS, NUM_RS);
MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
log(""Waiting for active/ready master"");
cluster.waitForActiveAndReadyMaster();
ZooKeeperWatcher zkw = new ZooKeeperWatcher(conf, ""testRollingRestart"", null);
HMaster master = cluster.getMaster();
byte[] table = Bytes.toBytes(""tableRestart"");
byte[] family = Bytes.toBytes(""family"");
log((""Creating table with "" + NUM_REGIONS_TO_CREATE) + "" regions"");
HTable ht = TEST_UTIL.createTable(table, family);
int numRegions = TEST_UTIL.createMultiRegions(conf, ht, family, NUM_REGIONS_TO_CREATE);
numRegions += 2;
log(""Waiting for no more RIT\n"");
blockUntilNoRIT(zkw, master);
log(""Disabling table\n"");
TEST_UTIL.getHBaseAdmin().disableTable(table);
log(""Waiting for no more RIT\n"");
blockUntilNoRIT(zkw, master);
NavigableSet<String> regions = getAllOnlineRegions(cluster);
log(""Verifying only catalog regions are assigned\n"");
if (regions.size() != 2) {
for (String oregion : regions) {
log(""Region still online: "" + oregion);
}
}
assertEquals(2, regions.size());
log(""Enabling table\n"");
TEST_UTIL.getHBaseAdmin().enableTable(table);
log(""Waiting for no more RIT\n"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster\n"");
regions = getAllOnlineRegions(cluster);
assertRegionsAssigned(cluster, regions);
assertEquals(expectedNumRS, cluster.getRegionServerThreads().size());
log(""Adding a fourth RS"");
RegionServerThread restarted = cluster.startRegionServer();
expectedNumRS++;
restarted.waitForServerOnline();
log(""Additional RS is online"");
log(""Waiting for no more RIT"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster"");
assertRegionsAssigned(cluster, regions);
assertEquals(expectedNumRS, cluster.getRegionServerThreads().size());
List<MasterThread> masterThreads = cluster.getMasterThreads();
MasterThread activeMaster = null;
MasterThread backupMaster = null;
assertEquals(2, masterThreads.size());
if (masterThreads.get(0).getMaster().isActiveMaster()) {
activeMaster = masterThreads.get(0);
backupMaster = masterThreads.get(1);
} else {
activeMaster = masterThreads.get(1);
backupMaster = masterThreads.get(0);
}
log(""Stopping backup master\n\n"");
backupMaster.getMaster().stop(""Stop of backup during rolling restart"");
cluster.hbaseCluster.waitOnMaster(backupMaster);
log(""Stopping primary master\n\n"");
activeMaster.getMaster().stop(""Stop of active during rolling restart"");
cluster.hbaseCluster.waitOnMaster(activeMaster);
log(""Restarting primary master\n\n"");
activeMaster = cluster.startMaster();
cluster.waitForActiveAndReadyMaster();
master = activeMaster.getMaster();
log(""Restarting backup master\n\n"");
backupMaster = cluster.startMaster();
assertEquals(expectedNumRS, cluster.getRegionServerThreads().size());
List<RegionServerThread> regionServers = cluster.getLiveRegionServerThreads();
int num = 1;
int total = regionServers.size();
for (RegionServerThread rst : regionServers) {
ServerName serverName = rst.getRegionServer().getServerName();
log((((((""Stopping region server "" + num) + "" of "") + total) + "" [ "") + serverName) + ""]"");
rst.getRegionServer().stop(""Stopping RS during rolling restart"");
cluster.hbaseCluster.waitOnRegionServer(rst);
log(""Waiting for RS shutdown to be handled by master"");
waitForRSShutdownToStartAndFinish(activeMaster, serverName);
log(""RS shutdown done, waiting for no more RIT"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster"");
assertRegionsAssigned(cluster, regions);
expectedNumRS--;
assertEquals(expectedNumRS, cluster.getRegionServerThreads().size());
log(((""Restarting region server "" + num) + "" of "") + total);
restarted = cluster.startRegionServer();
restarted.waitForServerOnline();
expectedNumRS++;
log((""Region server "" + num) + "" is back online"");
log(""Waiting for no more RIT"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster"");
assertRegionsAssigned(cluster, regions);
assertEquals(expectedNumRS, cluster.getRegionServerThreads().size());
num++;
}
Thread.sleep(2000);
assertRegionsAssigned(cluster, regions);
RegionServerThread rootServer = getServerHostingRoot(cluster);
RegionServerThread metaServer = getServerHostingMeta(cluster);
if (rootServer == metaServer) {
log(""ROOT and META on the same server so killing another random server"");
int i = 0;
while (rootServer == metaServer) {
metaServer = cluster.getRegionServerThreads().get(i);
i++;
}
}
log(""Stopping server hosting ROOT"");
rootServer.getRegionServer().stop(""Stopping ROOT server"");
log(""Stopping server hosting META #1"");
metaServer.getRegionServer().stop(""Stopping META server"");
cluster.hbaseCluster.waitOnRegionServer(rootServer);
log(""Root server down"");
cluster.hbaseCluster.waitOnRegionServer(metaServer);
log(""Meta server down #1"");
expectedNumRS -= 2;
log(""Waiting for meta server #1 RS shutdown to be handled by master"");
waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName());
log(""Waiting for no more RIT"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster"");
assertRegionsAssigned(cluster, regions);
assertEquals(expectedNumRS, cluster.getRegionServerThreads().size());
metaServer = getServerHostingMeta(cluster);
log(""Stopping server hosting META #2"");
metaServer.getRegionServer().stop(""Stopping META server"");
cluster.hbaseCluster.waitOnRegionServer(metaServer);
log(""Meta server down"");
expectedNumRS--;
log(""Waiting for RS shutdown to be handled by master"");
waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName());
log(""RS shutdown done, waiting for no more RIT"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster"");
assertRegionsAssigned(cluster, regions);
assertEquals(expectedNumRS, cluster.getRegionServerThreads().size());
cluster.startRegionServer().waitForServerOnline();
cluster.startRegionServer().waitForServerOnline();
cluster.startRegionServer().waitForServerOnline();
Thread.sleep(1000);
log(""Waiting for no more RIT"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster"");
assertRegionsAssigned(cluster, regions);
metaServer = getServerHostingMeta(cluster);
log(""Stopping server hosting META (1 of 3)"");
metaServer.getRegionServer().stop(""Stopping META server"");
cluster.hbaseCluster.waitOnRegionServer(metaServer);
log(""Meta server down (1 of 3)"");
log(""Waiting for RS shutdown to be handled by master"");
waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName());
log(""RS shutdown done, waiting for no more RIT"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster"");
assertRegionsAssigned(cluster, regions);
metaServer = getServerHostingMeta(cluster);
log(""Stopping server hosting META (2 of 3)"");
metaServer.getRegionServer().stop(""Stopping META server"");
cluster.hbaseCluster.waitOnRegionServer(metaServer);
log(""Meta server down (2 of 3)"");
log(""Waiting for RS shutdown to be handled by master"");
waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName());
log(""RS shutdown done, waiting for no more RIT"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster"");
assertRegionsAssigned(cluster, regions);
metaServer = getServerHostingMeta(cluster);
log(""Stopping server hosting META (3 of 3)"");
metaServer.getRegionServer().stop(""Stopping META server"");
cluster.hbaseCluster.waitOnRegionServer(metaServer);
log(""Meta server down (3 of 3)"");
log(""Waiting for RS shutdown to be handled by master"");
waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName());
log(""RS shutdown done, waiting for no more RIT"");
blockUntilNoRIT(zkw, master);
log((""Verifying there are "" + numRegions) + "" assigned on cluster"");
assertRegionsAssigned(cluster, regions);
if (cluster.getRegionServerThreads().size() != 1) {
log(""Online regionservers:"");
for (RegionServerThread rst : cluster.getRegionServerThreads()) {
log(""RS: "" + rst.getRegionServer().getServerName());
}
}
assertEquals(1, cluster.getRegionServerThreads().size());
TEST_UTIL.shutdownMiniCluster();
}",async wait,0
109,pulsar,ServerCnxTest.testDuplicateConcurrentSubscribeCommand,"@Test
public void testDuplicateConcurrentSubscribeCommand() throws Exception {
resetChannel();
setChannelConnected();
CompletableFuture<Topic> delayFuture = new CompletableFuture<>();
doReturn(delayFuture).when(brokerService).getOrCreateTopic(any(String.class));
ByteBuf clientCommand =
Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0);
channel.writeInbound(clientCommand);
clientCommand =
Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0);
channel.writeInbound(clientCommand);
Object response = getResponse();
assertTrue(response instanceof CommandError, ""Response is not CommandError but "" + response);
CommandError error = ((CommandError) (response));
assertEquals(error.getError(), ServiceNotReady);
channel.finish();
}",concurrency,1
110,aries,JndiUrlIntegrationTest.testBlueprintCompNamespaceWorks,"@Test
public void testBlueprintCompNamespaceWorks() throws Exception {
Bundle bBiz = getInstalledBundle(""org.apache.aries.jndi.url.itest.biz"");
assertNotNull(bBiz);
Bundle bweb = getInstalledBundle(""org.apache.aries.jndi.url.itest.web"");
assertNotNull(bweb);
printBundleStatus(""Before first request"");
try {
getTestServletResponse();
} catch (IOException iox) {
}
try {
Thread.sleep(5000);
} catch (InterruptedException iox) {
}
printBundleStatus(""After workaround, before test proper"");
System.out.println(""In test and trying to get connection...."");
String response = getTestServletResponse();
assertEquals(""ITest servlet response wrong"", ""Mark.2.0.three"", response);
}",async wait,0
111,hadoop,TestPathData.testWithStringAndConfForBuggyPath,"@Test
public void testWithStringAndConfForBuggyPath() throws Exception {
dirString = ""file"" ;
testDir = new Path(dirString);
item = new PathData(dirString, conf);
assertEquals(""file:/tmp"", testDir.toString());
checkPathData();
}",test order dependency,4
112,activemq,JMSDurableTopicRedeliverTest.testRedeliverNewSession,"@Test
public void testRedeliverNewSession() throws Exception {
String text = ""TEST"";
Message sendMessage = session.createTextMessage(text);
if (verbose) {
log.info(((""About to send a message: "" + sendMessage) + "" with text: "") + text);
}
producer.send(producerDestination, sendMessage);
Message unackMessage = consumer.receive(1000);
assertNotNull(unackMessage);
String unackId = unackMessage.getJMSMessageID();
assertEquals(((TextMessage) (unackMessage)).getText(), text);
assertFalse(unackMessage.getJMSRedelivered());
assertEquals(unackMessage.getIntProperty(""JMSXDeliveryCount""), 1);
consumeSession.close();
consumer.close();
consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE);
consumer = createConsumer();
Message ackMessage = consumer.receive(1000);
assertNotNull(ackMessage);
ackMessage.acknowledge();
String ackId = ackMessage.getJMSMessageID();
assertEquals(((TextMessage) (ackMessage)).getText(), text);
assertTrue(ackMessage.getJMSRedelivered());
assertEquals(ackMessage.getIntProperty(""JMSXDeliveryCount""), 2);
assertEquals(unackId, ackId);
consumeSession.close();
consumer.close();
consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE);
consumer = createConsumer();
assertNull(consumer.receiveNoWait());
}",async wait,0
113,typescript-generator,EnumTest.testEnumAsEnum,"@Test
public void testEnumAsEnum() {
final Settings settings = TestUtils.settings();
settings.mapEnum = EnumMapping.asEnum;
final String output = new TypeScriptGenerator(settings).generateTypeScript(Input.from(AClass.class));
final String expected = (""interface AClass {\n"" + ((((((((""    direction: Direction;\n"" + ""}\n"") + ""\n"") + ""declare const enum Direction {\n"") + ""    North = \'North\',\n"") + ""    East = \'East\',\n"") + ""    South = \'South\',\n"") + ""    West = \'West\',\n"") + ""}"")).replace(""'"", ""\"""");
assertEquals(expected.trim(), output.trim());
}",unordered collections,3
114,zeebe,ControlledActorClockEndpointTest.canOffsetMutableClock,"@Test
void canOffsetMutableClock() {
final var offset = Duration.ofMinutes(10);
final var response = endpoint.modify(""add"", null, offset.toMillis());
final var offsetMinimum = Instant.now().plus(offset).truncatedTo(ChronoUnit.MILLIS);
final var offsetMaximum = Instant.now().plus(offset.plus(Duration.ofMinutes(1)));
assertThat(response.getStatus()).isEqualTo(200);
assertThat(response.getBody()).isNotNull().asInstanceOf(instanceOfRecord).satisfies(( body) -> assertThat(body.instant).isBetween(offsetMinimum, offsetMaximum));
}",time,2
115,RxJava,ObservableSwitchTest.outerInnerErrorRace,"@Test
public void outerInnerErrorRace() {
for (int i = 0; i < 500; i++) {
List<Throwable> errors = TestHelper.trackPluginErrors();
try {
final PublishSubject<Integer> ps1 = PublishSubject.create();
final PublishSubject<Integer> ps2 = PublishSubject.create();
ps1.switchMap(new Function<Integer, ObservableSource<Integer>>() {
@Override
public ObservableSource<Integer> apply(Integer v) throws Exception {
if (v == 1) {
return ps2;
}
return Observable.never();
}
})
.test();
final TestException ex1 = new TestException();
Runnable r1 = new Runnable() {
@Override
public void run() {
ps1.onError(ex1);
}
};
final TestException ex2 = new TestException();
Runnable r2 = new Runnable() {
@Override
public void run() {
ps2.onError(ex2);
}
};
TestHelper.race(r1, r2);
for (Throwable e : errors) {
assertTrue(e.toString(), e instanceof TestException);
}
} finally {
RxJavaPlugins.reset();
}
}
}",concurrency,1
116,kylin,CoordinatorTest.testReassignFailOnStartNew,"@Test
public void testReassignFailOnStartNew() throws IOException {
ReceiverAdminClient receiverAdminClient = mockReceiverClientFailOnStartNewComsumer();
coordinator = new Coordinator(metadataStore, receiverAdminClient);
Map<Integer, List<Partition>> preAssignMap = metadataStore.getAssignmentsByCube(cubeName).getAssignments();
Map<Integer, List<Partition>> newAssignMap = new HashMap<>();
newAssignMap.put(1, Lists.newArrayList(p1, p2, p3));
newAssignMap.put(2, Lists.newArrayList(p4, p5));
newAssignMap.put(3, Lists.newArrayList(p6));
CubeAssignment preAssigment = new CubeAssignment(cube.getName(), preAssignMap);
CubeAssignment newAssigment = new CubeAssignment(cube.getName(), newAssignMap);
try {
coordinator.doReassign(cube, preAssigment, newAssigment);
} catch (ClusterStateException rune) {
assertSame(ROLLBACK_FAILED, rune.getClusterState());
assertSame(START_NEW, rune.getTransactionStep());
System.out.println(rune.getMessage());
throw rune;
}
}",unordered collections,3
117,servicemix,WSNComponentTest.testPullWithFilter,"@Test
public void testPullWithFilter() throws Exception {
PullPoint pullPoint1 = wsnCreatePullPoint.createPullPoint();
PullPoint pullPoint2 = wsnCreatePullPoint.createPullPoint();
wsnBroker.subscribe(pullPoint1.getEndpoint(), ""myTopic"", ""@type = 'a'"");
wsnBroker.subscribe(pullPoint2.getEndpoint(), ""myTopic"", ""@type = 'b'"");
wsnBroker.notify(""myTopic"", parse(""<msg type='a'/>""));
Thread.sleep(500);
assertEquals(1, pullPoint1.getMessages(0).size());
assertEquals(0, pullPoint2.getMessages(0).size());
wsnBroker.notify(""myTopic"", parse(""<msg type='b'/>""));
Thread.sleep(500);
assertEquals(0, pullPoint1.getMessages(0).size());
assertEquals(1, pullPoint2.getMessages(0).size());
wsnBroker.notify(""myTopic"", parse(""<msg type='c'/>""));
Thread.sleep(500);
assertEquals(0, pullPoint1.getMessages(0).size());
assertEquals(0, pullPoint2.getMessages(0).size());
}",async wait,0
118,maven,CheckoutMojoTest.testSkipCheckoutWithoutConnectionUrl,"@Test
public void testSkipCheckoutWithoutConnectionUrl() throws Exception {
CheckoutMojo mojo = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWithoutConnectionUrl.xml""))));
try {
mojo.execute();
fail(""mojo execution must fail."");
} catch (MojoExecutionException e) {
assertTrue(true);
}
}",test order dependency,4
119,vertx-mongo-client,MongoClientTest.testWatch,"@Test
public void testWatch() throws Exception {
final JsonArray operationTypes = new JsonArray(Arrays.asList(""insert"", ""update"", ""replace"", ""delete""));
final JsonObject match = new JsonObject().put(""operationType"", new JsonObject().put(""$in"", operationTypes));
final JsonArray pipeline = new JsonArray().add(new JsonObject().put(""$match"", match));
final JsonObject fields = new JsonObject().put(""operationType"", true).put(""namespaceDocument"", true).put(""destinationNamespaceDocument"", true).put(""documentKey"", true).put(""updateDescription"", true).put(""fullDocument"", true);
pipeline.add(new JsonObject().put(""$project"", fields));
final String collection = randomCollection();
final JsonObject doc = createDoc();
final CountDownLatch latch = new CountDownLatch(4);
final AtomicReference<ReadStream<ChangeStreamDocument<JsonObject>>> streamReference = new AtomicReference<>();
mongoClient.createCollection(collection, onSuccess(( res) -> {
ReadStream<ChangeStreamDocument<JsonObject>> stream = mongoClient.watch(collection, pipeline, true, 1).handler(( changeStreamDocument) -> {
OperationType operationType = changeStreamDocument.getOperationType();
assertNotNull(operationType);
JsonObject fullDocument = changeStreamDocument.getFullDocument();
switch (operationType.getValue()) {
case ""insert"" :
assertNotNull(fullDocument);
assertNotNull(fullDocument.getString(MongoClientUpdateResult.ID_FIELD));
assertEquals(""bar"", fullDocument.getString(""foo""));
break;
case ""update"" :
assertNotNull(fullDocument);
assertEquals(""updatedValue"", fullDocument.getString(""fieldToUpdate""));
break;
case ""replace"" :
assertNotNull(fullDocument);
assertEquals(""replacedValue"", fullDocument.getString(""fieldToReplace""));
break;
case ""delete"" :
assertNull(fullDocument);
break;
default :
}
latch.countDown();
if (latch.getCount() == 1) {
mongoClient.removeDocuments(collection, new JsonObject());
}
}).endHandler(( v) -> assertEquals(0, latch.getCount())).exceptionHandler(this::fail).fetch(1);
streamReference.set(stream);
vertx.setTimer(50, ( v) -> {
mongoClient.insert(collection, doc).compose(( idString) -> {
doc.put(MongoClientUpdateResult.ID_FIELD, idString);
doc.put(""fieldToUpdate"", ""updatedValue"");
final JsonObject query = new JsonObject().put(MongoClientUpdateResult.ID_FIELD, idString);
final JsonObject updateField = new JsonObject().put(""fieldToUpdate"", ""updatedValue"");
return CompositeFuture.all(mongoClient.updateCollection(collection, query, new JsonObject().put(""$set"", updateField)), mongoClient.save(collection, doc.put(""fieldToReplace"", ""replacedValue"")));
});
});
}));
awaitLatch(latch);
streamReference.get().handler(null);
}",time,2
120,hadoop,TestModTime.testModTime,"@Test
public void testModTime() throws IOException {
Configuration conf = new Configuration();
MiniDFSCluster cluster = new MiniDFSCluster(conf, numDatanodes, true, null);
cluster.waitActive();
InetSocketAddress addr = new InetSocketAddress(""localhost"", cluster.getNameNodePort());
DFSClient client = new DFSClient(addr, conf);
DatanodeInfo[] info = client.datanodeReport(LIVE);
assertEquals(""Number of Datanodes "", numDatanodes, info.length);
FileSystem fileSys = cluster.getFileSystem();
int replicas = numDatanodes - 1;
assertTrue(fileSys instanceof DistributedFileSystem);
try {
System.out.println(""Creating testdir1 and testdir1/test1.dat."");
Path dir1 = new Path(""testdir1"");
Path file1 = new Path(dir1, ""test1.dat"");
writeFile(fileSys, file1, replicas);
FileStatus stat = fileSys.getFileStatus(file1);
long mtime1 = stat.getModificationTime();
assertTrue(mtime1 != 0);
stat = fileSys.getFileStatus(dir1);
long mdir1 = stat.getModificationTime();
System.out.println(""Creating testdir1/test2.dat."");
Path file2 = new Path(dir1, ""test2.dat"");
writeFile(fileSys, file2, replicas);
stat = fileSys.getFileStatus(file2);
stat = fileSys.getFileStatus(dir1);
assertTrue(stat.getModificationTime() >= mdir1);
mdir1 = stat.getModificationTime();
Path dir2 = new Path(""testdir2/"").makeQualified(fileSys);
System.out.println(""Creating testdir2 "" + dir2);
assertTrue(fileSys.mkdirs(dir2));
stat = fileSys.getFileStatus(dir2);
long mdir2 = stat.getModificationTime();
Path newfile = new Path(dir2, ""testnew.dat"");
System.out.println(((""Moving "" + file1) + "" to "") + newfile);
fileSys.rename(file1, newfile);
stat = fileSys.getFileStatus(newfile);
assertTrue(stat.getModificationTime() == mtime1);
stat = fileSys.getFileStatus(dir1);
assertTrue(stat.getModificationTime() != mdir1);
mdir1 = stat.getModificationTime();
stat = fileSys.getFileStatus(dir2);
assertTrue(stat.getModificationTime() != mdir2);
mdir2 = stat.getModificationTime();
System.out.println(""Deleting testdir2/testnew.dat."");
assertTrue(fileSys.delete(newfile, true));
stat = fileSys.getFileStatus(dir1);
assertTrue(stat.getModificationTime() == mdir1);
stat = fileSys.getFileStatus(dir2);
assertTrue(stat.getModificationTime() != mdir2);
mdir2 = stat.getModificationTime();
cleanupFile(fileSys, file2);
cleanupFile(fileSys, dir1);
cleanupFile(fileSys, dir2);
} catch (IOException e) {
info = client.datanodeReport(ALL);
printDatanodeReport(info);
throw e;
} finally {
fileSys.close();
cluster.shutdown();
}
}",time,2
121,servicemix,WSNComponentTest.testNotifyWithJbiWrapper,"@Test
public void testNotifyWithJbiWrapper() throws Exception {
wsnBroker.setJbiWrapped(true);
ReceiverComponent receiver = new ReceiverComponent();
jbi.activateComponent(receiver, ""receiver"");
W3CEndpointReference consumer = createEPR(SERVICE, ENDPOINT);
wsnBroker.subscribe(consumer, ""myTopic"", null);
wsnBroker.notify(""myTopic"", parse(""<hello>world</hello>""));
Thread.sleep(500);
receiver.getMessageList().assertMessagesReceived(1);
NormalizedMessage msg = ((NormalizedMessage) (receiver.getMessageList().getMessages().get(0)));
Node node = new SourceTransformer().toDOMNode(msg);
assertEquals(""Notify"", node.getLocalName());
Thread.sleep(500);
}",async wait,0
122,jackrabbit,QueryFulltextTest.excerpt,"@Test
public void excerpt() throws Exception {
Session session = getAdminSession();
QueryManager qm = session.getWorkspace().getQueryManager();
Node testRootNode = session.getRootNode().addNode(""testroot"");
Node n1 = testRootNode.addNode(""node1"");
n1.setProperty(""text"", ""hello world"");
n1.setProperty(""desc"", ""description"");
Node n2 = testRootNode.addNode(""node2"");
n2.setProperty(""text"", ""Hello World"");
n2.setProperty(""desc"", ""Description"");
session.save();
Query q;
RowIterator it;
Row row;
String s;
String xpath = """";
q = qm.createQuery(xpath, ""xpath"");
it = q.execute().getRows();
row = it.nextRow();
s = row.getValue(""rep:excerpt(.)"").getString();
assertTrue(s, s.indexOf(""<strong>hello</strong> world"") >= 0);
assertTrue(s, s.indexOf(""description"") >= 0);
row = it.nextRow();
s = row.getValue(""rep:excerpt(.)"").getString();
assertTrue(s, s.indexOf(""Hello World"") >= 0);
assertTrue(s, s.indexOf(""Description"") >= 0);
xpath = """";
q = qm.createQuery(xpath, ""xpath"");
it = q.execute().getRows();
row = it.nextRow();
s = row.getValue(""rep:excerpt(text)"").getString();
assertTrue(s, s.indexOf(""<strong>hello</strong> world"") >= 0);
assertTrue(s, s.indexOf(""description"") < 0);
row = it.nextRow();
s = row.getValue(""rep:excerpt(text)"").getString();
assertTrue(s, s.indexOf(""Hello World"") >= 0);
assertTrue(s, s.indexOf(""Description"") < 0);
}",unordered collections,3
123,mahout,TestClusterDumper.testKmeansSVD,"@Test
public void testKmeansSVD() throws Exception {
DistanceMeasure measure = new EuclideanDistanceMeasure();
Path output = getTestTempDirPath(""output"");
Path tmp = getTestTempDirPath(""tmp"");
DistributedLanczosSolver solver = new DistributedLanczosSolver();
Configuration conf = new Configuration();
solver.setConf(conf);
Path testData = getTestTempDirPath(""testdata"");
int sampleDimension = sampleData.get(0).get().size();
int desiredRank = 15;
solver.run(testData, output, tmp, null, sampleData.size(), sampleDimension, false, desiredRank, 0.5, 0.0, true);
Path cleanEigenvectors = new Path(output, EigenVerificationJob.CLEAN_EIGENVECTORS);
Matrix a = new DenseMatrix(sampleData.size(), sampleDimension);
int i = 0;
for (VectorWritable vw : sampleData) {
a.assignRow(i++, vw.get());
}
Matrix p = new DenseMatrix(39, desiredRank - 1);
FileSystem fs = FileSystem.get(cleanEigenvectors.toUri(), conf);
i = 0;
for (VectorWritable value : new SequenceFileValueIterable<VectorWritable>(cleanEigenvectors, conf)) {
Vector v = value.get();
p.assignColumn(i, v);
i++;
}
Matrix sData = a.times(p);
Path svdData = new Path(output, ""svddata"");
SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, svdData, IntWritable.class, VectorWritable.class);
try {
IntWritable key = new IntWritable();
VectorWritable value = new VectorWritable();
for (int row = 0; row < sData.numRows(); row++) {
key.set(row);
value.set(sData.viewRow(row));
writer.append(key, value);
}
} finally {
Closeables.closeQuietly(writer);
}
CanopyDriver.run(conf, svdData, output, measure, 8, 4, false, 0.0, true);
KMeansDriver.run(svdData, new Path(output, ""clusters-0""), output, measure, 0.001, 10, true, true);
ClusterDumper clusterDumper = new ClusterDumper(finalClusterPath(conf, output, 10), new Path(output, ""clusteredPoints""));
clusterDumper.printClusters(termDictionary);
}",concurrency,1
124,docker-client,DefaultDockerClientTest.testListTaskWithCriteria,"@Test
public void testListTaskWithCriteria() throws Exception {
requireDockerApiVersionAtLeast(""1.24"", ""swarm support"");
final ServiceSpec spec = createServiceSpec(randomName());
assertThat(sut.listTasks().size(), is(0));
sut.createService(spec);
await().until(numberOfTasks(sut), is(greaterThan(0)));
final Task task = sut.listTasks().get(1);
final List<Task> tasksWithId = sut.listTasks(Task.find().taskId(task.id()).build());
assertThat(tasksWithId.size(), is(1));
assertThat(tasksWithId.get(0), equalTo(task));
final List<Task> tasksWithServiceName = sut.listTasks(Task.find().serviceName(spec.name()).build());
assertThat(tasksWithServiceName.size(), is(greaterThanOrEqualTo(1)));
final Set<String> taskIds = Sets.newHashSet(Lists.transform(tasksWithServiceName, new Function<Task, String>()));
assertThat(task.id(), isIn(taskIds));
}",async wait,0
125,openjpa,TestTimestampVersion.testBulkUpdateOnTimestampedVersion,"@Test
public void testBulkUpdateOnTimestampedVersion() {
TimestampedEntity pc = new TimestampedEntity();
pc.setName(""Original"");
EntityManager em = emf.createEntityManager();
em.getTransaction().begin();
em.persist(pc);
em.getTransaction().commit();
em.getTransaction().begin();
Timestamp oldVersion = pc.getVersion();
String jpql = ""UPDATE TimestampedEntity t SET t.name=:newname WHERE t.name=:oldname"";
em.createQuery(jpql).setParameter(""newname"", ""Updated"").setParameter(""oldname"", ""Original"").executeUpdate();
em.getTransaction().commit();
em.getTransaction().begin();
em.refresh(pc);
Timestamp newVersion = pc.getVersion();
assertTrue(newVersion.after(oldVersion));
}",time,2
126,junit-quickcheck,ExhaustingAGivenSetButIncludingAnotherTest.manyParametersWithBooleanAndEnum,"@Test
public void manyParametersWithBooleanAndEnum() throws Exception {
assertThat(testResult(ManyParametersWithBooleanAndEnum.class), isSuccessful());
int expectedCount = ((4 * 4) * 2) * RoundingMode.values().length;
assertEquals(expectedCount, ManyParametersWithBooleanAndEnum.iterations);
for (int i = 0; i < (expectedCount / 4); ++i) {
assertEquals(String.valueOf(i), asList(3, 7), ManyParametersWithBooleanAndEnum.firstTestCases.subList(i * 4, (i * 4) + 2));
}
for (int i = 0; i < (expectedCount / 16); ++i) {
assertEquals(String.valueOf(i), asList('a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'c', 'c', 'c', 'c'), ManyParametersWithBooleanAndEnum.secondTestCases.subList(i * 16, (i * 16) + 12));
}
for (int i = 0; i < (expectedCount / 32); ++i) {
assertEquals(asList(false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false), ManyParametersWithBooleanAndEnum.thirdTestCases.subList(i * 32, (i * 32) + 16));
assertEquals(asList(true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true), ManyParametersWithBooleanAndEnum.thirdTestCases.subList((i * 32) + 16, (i * 32) + 32));
}
}",unordered collections,3
127,maven,CheckoutMojoTest.testExcludeInclude,"@Test
public void testExcludeInclude() throws Exception {
checkoutDir.mkdirs();
CheckoutMojo mojo = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWithExcludesIncludes.xml""))));
mojo.setCheckoutDirectory(checkoutDir);
mojo.execute();
assertTrue(checkoutDir.listFiles().length > 0);
assertTrue(new File(checkoutDir, "".svn"").exists());
assertTrue(new File(checkoutDir, ""pom.xml"").exists());
assertFalse(new File(checkoutDir, ""readme.txt"").exists());
assertFalse(new File(checkoutDir, ""src/test"").exists());
assertTrue(new File(checkoutDir, ""src/main/java"").exists());
assertTrue(new File(checkoutDir, ""src/main/java/.svn"").exists());
assertTrue(new File(checkoutDir, ""src/main/.svn"").exists());
}",test order dependency,4
128,neo4j,createdWorkerThreadsShouldContainConnectorName,"@Test
public void createdWorkerThreadsShouldContainConnectorName() throws Exception
{
AtomicInteger processNextBatchCount = new AtomicInteger();
AtomicReference<Thread> poolThread = new AtomicReference<>();
AtomicReference<String> poolThreadName = new AtomicReference<>();
String id = UUID.randomUUID().toString();
BoltConnection connection = newConnection( id );
when( connection.processNextBatch() ).thenAnswer( inv ->
{
poolThread.set( Thread.currentThread() );
poolThreadName.set( Thread.currentThread().getName() );
processNextBatchCount.incrementAndGet();
return true;
} );
boltScheduler.start();
boltScheduler.created( connection );
boltScheduler.enqueued( connection, Jobs.noop() );
Predicates.await( () -> processNextBatchCount.get() > 0, 1, MINUTES );
assertThat( poolThread.get().getName(), not( equalTo( poolThreadName.get() ) ) );
assertThat( poolThread.get().getName(), containsString( String.format( ""[%s]"", CONNECTOR_KEY ) ) );
assertThat( poolThread.get().getName(), not( containsString( String.format( ""[%s]"", connection.remoteAddress() ) ) ) );
}",concurrency,1
129,hadoop,TestPathData.testWithDirStringAndConf,"@Test
public void testWithDirStringAndConf() throws Exception {
dirString = ""d1"";
item = new PathData(dirString, conf);
checkPathData();
dirString = ""d1/"";
item = new PathData(dirString, conf);
checkPathData();
}",test order dependency,4
130,unirest-java,DefectTest.nullAndObjectValuesInMap,"@Test
void nullAndObjectValuesInMap() {
Map<String, Object> queryParams = new HashMap<>();
queryParams.put(""foo"", null);
queryParams.put(""baz"", ""qux"");
Unirest.get(GET).queryString(queryParams).asObject(RequestCapture.class).getBody().assertParam(""foo"", """").assertParam(""baz"", ""qux"").assertQueryString(""foo&baz=qux"");
}",unordered collections,3
131,beam,testClientConnecting,"@Test
public void testClientConnecting() throws Exception {
PipelineOptions options = PipelineOptionsFactory.create();
Endpoints.ApiServiceDescriptor descriptor = findOpenPort();
BeamFnControlService service =
new BeamFnControlService(
descriptor,
ServerStreamObserverFactory.fromOptions(options)::from,
GrpcContextHeaderAccessorProvider.getHeaderAccessor());
Server server =
ServerFactory.fromOptions(options).create(descriptor, ImmutableList.of(service));
String url = service.getApiServiceDescriptor().getUrl();
BeamFnControlGrpc.BeamFnControlStub clientStub =
BeamFnControlGrpc.newStub(ManagedChannelBuilder.forTarget(url).usePlaintext(true).build());
clientStub.control(requestObserver);
try (FnApiControlClient client = service.get()) {
assertNotNull(client);
}
server.shutdown();
server.awaitTermination(1, TimeUnit.SECONDS);
server.shutdownNow();
verify(requestObserver).onCompleted();
verifyNoMoreInteractions(requestObserver);
}",async wait,0
132,androidx,testInterruption,"@Test
public void testInterruption() throws InterruptedException {
OneTimeWorkRequest work = new OneTimeWorkRequest.Builder(TestWorker.class).build();
insertWork(work);
WorkerWrapper workerWrapper =
createBuilder(work.getStringId())
.withSchedulers(Collections.singletonList(mMockScheduler))
.build();
FutureListener listener = createAndAddFutureListener(workerWrapper);
Executors.newSingleThreadExecutor().submit(workerWrapper);
workerWrapper.interrupt();
Thread.sleep(6000L);
assertThat(listener.mResult, is(true));
}",async wait,0
133,rm-collection-exercise-service,SampleSummaryServiceTest.testActivateSamples,"@Test
public void testActivateSamples() throws Exception {
UUID collectionExerciseId = UUID.randomUUID();
UUID surveyId = UUID.randomUUID();
UUID sampleSummaryId = UUID.randomUUID();
SampleLink sampleLink = new SampleLink();
sampleLink.setSampleSummaryId(sampleSummaryId);
sampleLink.setCollectionExerciseId(collectionExerciseId);
List<SampleLink> sampleLinks = new ArrayList<>();
sampleLinks.add(sampleLink);
CollectionExercise collectionExercise = new CollectionExercise();
collectionExercise.setId(collectionExerciseId);
collectionExercise.setSurveyId(surveyId);
Event event = new Event();
event.setTimestamp(new Timestamp(System.currentTimeMillis()));
when(collectionExerciseRepository.findOneById(collectionExerciseId)).thenReturn(collectionExercise);
when(sampleLinkRepository.findByCollectionExerciseId(collectionExerciseId)).thenReturn(sampleLinks);
when(eventRepository.findOneByCollectionExerciseAndTag(collectionExercise, go_live.name())).thenReturn(event);
sampleSummaryService.activateSamples(collectionExerciseId);
sampleSummaryService.sampleSummaryValidated(true, collectionExerciseId);
sampleSummaryService.sampleSummaryDistributed(true, collectionExerciseId);
verify(collectionExerciseRepository, times(3)).findOneById(collectionExerciseId);
verify(sampleSummaryActivationPublisher, times(1)).sendSampleSummaryActivation(collectionExerciseId, sampleSummaryId, surveyId);
verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, EXECUTE);
verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, VALIDATE);
verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, EXECUTION_COMPLETE);
verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, GO_LIVE);
}",time,2
134,nutz,JsonTest.test_empty_obj_toJson,"@Test
public void test_empty_obj_toJson() {
String j = Json.toJson(new Person(), JsonFormat.compact().setQuoteName(true));
assertEquals(""{\""age\"":0,\""num\"":0}"", j);
}",unordered collections,3
135,hadoop,testPendingAndInvalidate,"@Test
public class Test {
public void testPendingAndInvalidate() throws Exception {
final Configuration CONF = new HdfsConfiguration();
MiniDFSCluster cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(DATANODE_COUNT).build();
cluster.waitActive();
FSNamesystem namesystem = cluster.getNamesystem();
BlockManager bm = namesystem.getBlockManager();
DistributedFileSystem fs = cluster.getFileSystem();
try {
Path filePath = new Path(""/tmp.txt"");
DFSTestUtil.createFile(fs, filePath, 1024, (short) 3, 0L);
for (DataNode dn : cluster.getDataNodes()) {
DataNodeTestUtils.setHeartbeatsDisabledForTests(dn, true);
}
LocatedBlock block = NameNodeAdapter.getBlockLocations(
cluster.getNameNode(), filePath.toString(), 0, 1).get(0);
cluster.getNamesystem().writeLock();
try {
bm.findAndMarkBlockAsCorrupt(block.getBlock(), block.getLocations()[0],
""STORAGE_ID"", ""TEST"");
} finally {
cluster.getNamesystem().writeUnlock();
}
BlockManagerTestUtil.computeAllPendingWork(bm);
BlockManagerTestUtil.updateState(bm);
assertEquals(bm.getPendingReconstructionBlocksCount(), 1L);
BlockInfo storedBlock = bm.getStoredBlock(block.getBlock().getLocalBlock());
assertEquals(bm.pendingReconstruction.getNumReplicas(storedBlock), 2);
fs.delete(filePath, true);
int retries = 10;
long pendingNum = bm.getPendingReconstructionBlocksCount();
while (pendingNum != 0 && retries-- > 0) {
Thread.sleep(1000);
BlockManagerTestUtil.updateState(bm);
pendingNum = bm.getPendingReconstructionBlocksCount();
}
assertEquals(pendingNum, 0L);
} finally {
cluster.shutdown();
}
}
}",concurrency,1
136,graylog2-server,KafkaJournalTest.serverStatusUnthrottledIfJournalUtilizationIsLowerThanThreshold,"@Test
public void serverStatusUnthrottledIfJournalUtilizationIsLowerThanThreshold() throws Exception {
serverStatus.throttle();
final Size segmentSize = Size.kilobytes(1L);
final KafkaJournal journal = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus);
journal.flushDirtyLogs();
journal.cleanupLogs();
assertThat(serverStatus.getLifecycle()).isEqualTo(RUNNING);
}",concurrency,1
137,jackson-datatypes-collections,DeserializerTest.primitivePairs,"@Test
public void primitivePairs() throws Exception {
List<Class<?>> types = Arrays.asList(Object.class, boolean.class, byte.class, short.class, char.class, int.class, float.class, long.class, double.class);
for (Class<?> oneType : types) {
for (Class<?> twoType : types) {
Class<?> pairClass;
Method factory;
if ((oneType == Object.class) && (twoType == Object.class)) {
pairClass = Pair.class;
factory = Tuples.class.getMethod(""pair"", Object.class, Object.class);
} else {
pairClass = Class.forName(((""org.eclipse.collections.api.tuple.primitive."" + capitalize(oneType.getSimpleName())) + capitalize(twoType.getSimpleName())) + ""Pair"");
factory = PrimitiveTuples.class.getMethod(""pair"", oneType, twoType);
}
Object sampleOne = randomSample(oneType);
Object sampleTwo = randomSample(twoType);
JavaType pairType;
if (oneType == Object.class) {
if (twoType == Object.class) {
pairType = mapperWithModule().getTypeFactory().constructParametricType(pairClass, sampleOne.getClass(), sampleTwo.getClass());
} else {
pairType = mapperWithModule().getTypeFactory().constructParametricType(pairClass, sampleOne.getClass());
}
} else if (twoType == Object.class) {
pairType = mapperWithModule().getTypeFactory().constructParametricType(pairClass, sampleTwo.getClass());
} else {
pairType = mapperWithModule().constructType(pairClass);
}
String expectedJson = (((""{\""one\"":"" + mapperWithModule().writeValueAsString(sampleOne)) + "",\""two\"":"") + mapperWithModule().writeValueAsString(sampleTwo)) + ""}"";
Object samplePair = factory.invoke(null, sampleOne, sampleTwo);
Assert.assertEquals(expectedJson, mapperWithModule().writeValueAsString(samplePair));
Assert.assertEquals(samplePair, mapperWithModule().readValue(expectedJson, pairType));
}
}
}",unordered collections,3
138,qpid,TransactedTest.testCommit,"@Test
public void testCommit() throws Exception {
producer2.send(session.createTextMessage(""X""));
producer2.send(session.createTextMessage(""Y""));
producer2.send(session.createTextMessage(""Z""));
expect(""A"", consumer1.receive(1000));
expect(""B"", consumer1.receive(1000));
expect(""C"", consumer1.receive(1000));
session.commit();
expect(""X"", testConsumer2.receive(1000));
expect(""Y"", testConsumer2.receive(1000));
expect(""Z"", testConsumer2.receive(1000));
assertTrue(null == testConsumer1.receive(1000));
assertTrue(null == testConsumer2.receive(1000));
}",async wait,0
139,cdap,WorkflowClientTestRun.testWorkflowClient,"@Test
public void testWorkflowClient() throws Exception {
String outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
Map<String, String> runtimeArgs = ImmutableMap.of(""inputPath"", createInput(""input""),
""outputPath"", outputPath);
Id.Workflow workflowId = Id.Workflow.from(appId, AppWithWorkflow.SampleWorkflow.NAME);
programClient.start(workflowId, false, runtimeArgs);
programClient.waitForStatus(workflowId, ""STOPPED"", 60, TimeUnit.SECONDS);
List<RunRecord> workflowRuns = programClient.getProgramRuns(workflowId, ProgramRunStatus.COMPLETED.name(), 0,
Long.MAX_VALUE, 10);
Assert.assertEquals(1, workflowRuns.size());
Id.Run workflowRunId = new Id.Run(workflowId, workflowRuns.get(0).getPid());
try {
workflowClient.getWorkflowToken(new Id.Run(Id.Workflow.from(appId, ""random""), workflowRunId.getId()));
Assert.fail(""Should not find a workflow token for a non-existing workflow"");
} catch (NotFoundException expected) {
}
try {
workflowClient.getWorkflowToken(new Id.Run(workflowId, RunIds.generate().getId()));
Assert.fail(""Should not find a workflow token for a random run id"");
} catch (NotFoundException expected) {
}
WorkflowTokenDetail workflowToken = workflowClient.getWorkflowToken(workflowRunId);
Assert.assertEquals(3, workflowToken.getTokenData().size());
workflowToken = workflowClient.getWorkflowToken(workflowRunId, WorkflowToken.Scope.SYSTEM);
Assert.assertTrue(workflowToken.getTokenData().size() > 0);
workflowToken = workflowClient.getWorkflowToken(workflowRunId, ""start_time"");
Map<String, List<WorkflowTokenDetail.NodeValueDetail>> tokenData = workflowToken.getTokenData();
Assert.assertEquals(AppWithWorkflow.WordCountMapReduce.NAME, tokenData.get(""start_time"").get(0).getNode());
Assert.assertTrue(Long.parseLong(tokenData.get(""start_time"").get(0).getValue()) < System.currentTimeMillis());
workflowToken = workflowClient.getWorkflowToken(workflowRunId, WorkflowToken.Scope.USER, ""action_type"");
tokenData = workflowToken.getTokenData();
Assert.assertEquals(AppWithWorkflow.WordCountMapReduce.NAME, tokenData.get(""action_type"").get(0).getNode());
Assert.assertEquals(""MapReduce"", tokenData.get(""action_type"").get(0).getValue());
String nodeName = AppWithWorkflow.SampleWorkflow.firstActionName;
WorkflowTokenNodeDetail workflowTokenAtNode =
workflowClient.getWorkflowTokenAtNode(workflowRunId, nodeName);
Assert.assertEquals(AppWithWorkflow.DummyAction.TOKEN_VALUE,
workflowTokenAtNode.getTokenDataAtNode().get(AppWithWorkflow.DummyAction.TOKEN_KEY));
workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, nodeName, WorkflowToken.Scope.SYSTEM);
Assert.assertEquals(0, workflowTokenAtNode.getTokenDataAtNode().size());
workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, nodeName,
AppWithWorkflow.DummyAction.TOKEN_KEY);
Assert.assertEquals(AppWithWorkflow.DummyAction.TOKEN_VALUE,
workflowTokenAtNode.getTokenDataAtNode().get(AppWithWorkflow.DummyAction.TOKEN_KEY));
String reduceOutputRecordsCounter = ""org.apache.hadoop.mapreduce.TaskCounter.REDUCE_OUTPUT_RECORDS"";
workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, AppWithWorkflow.WordCountMapReduce.NAME,
WorkflowToken.Scope.SYSTEM, reduceOutputRecordsCounter);
Assert.assertEquals(6, Integer.parseInt(workflowTokenAtNode.getTokenDataAtNode().get(reduceOutputRecordsCounter)));
}",async wait,0
140,voltdb,testPrematureTimeout,"@Test
public void testPrematureTimeout() throws Exception {
final AtomicBoolean failed = new AtomicBoolean(false);
MockVolt volt = new MockVolt(20000);
volt.start();
Distributer dist = new Distributer(false,
ClientConfig.DEFAULT_PROCEDURE_TIMOUT_NANOS,
2000,
false, null);
dist.addClientStatusListener(new TimeoutMonitorCSL());
dist.createConnection(""localhost"", """", """", 20000);
assertTrue(volt.handler != null);
long start = System.currentTimeMillis();
while ((System.currentTimeMillis() - start) < 3000) {
Thread.yield();
}
volt.handler.sendResponses.set(false);
start = System.currentTimeMillis();
while (!failed.get()) {
if ((System.currentTimeMillis() - start) > 2000) {
break;
} else {
Thread.yield();
}
}
if ((System.currentTimeMillis() - start) < 2000) {
fail(""Premature timeout occurred""); }
dist.shutdown();
volt.shutdown();
}",time,2
141,activemq,BrokerTest.testConsumerClose,"@Test
public void testConsumerClose() throws Exception {
StubConnection connection1 = createConnection();
ConnectionInfo connectionInfo1 = createConnectionInfo();
SessionInfo sessionInfo1 = createSessionInfo(connectionInfo1);
ProducerInfo producerInfo1 = createProducerInfo(sessionInfo1);
connection1.send(connectionInfo1);
connection1.send(sessionInfo1);
connection1.send(producerInfo1);
ConsumerInfo consumerInfo1 = createConsumerInfo(sessionInfo1, destination);
consumerInfo1.setPrefetchSize(100);
consumerInfo1.setNoLocal(true);
connection1.request(consumerInfo1);
StubConnection connection2 = createConnection();
ConnectionInfo connectionInfo2 = createConnectionInfo();
SessionInfo sessionInfo2 = createSessionInfo(connectionInfo2);
ProducerInfo producerInfo2 = createProducerInfo(sessionInfo2);
connection2.send(connectionInfo2);
connection2.send(sessionInfo2);
connection2.send(producerInfo2);
connection2.send(createMessage(producerInfo2, destination, deliveryMode));
connection2.send(createMessage(producerInfo2, destination, deliveryMode));
connection2.send(createMessage(producerInfo2, destination, deliveryMode));
connection2.send(createMessage(producerInfo2, destination, deliveryMode));
for (int i = 0; i < 4; i++) {
Message m1 = receiveMessage(connection1);
assertNotNull(m1);
connection1.send(createAck(consumerInfo1, m1, 1, STANDARD_ACK_TYPE));
}
connection1.request(closeConsumerInfo(consumerInfo1));
connection2.request(createMessage(producerInfo2, destination, deliveryMode));
assertNull(connection1.getDispatchQueue().poll(MAX_NULL_WAIT, TimeUnit.MILLISECONDS));
}",async wait,0
142,hbase,TestHRegion.testWritesWhileScanning,"@Test
public void testWritesWhileScanning() throws IOException, InterruptedException {
byte[] tableName = Bytes.toBytes(""testWritesWhileScanning"");
int testCount = 100;
int numRows = 1;
int numFamilies = 10;
int numQualifiers = 100;
int flushInterval = 7;
int compactInterval = 5 * flushInterval;
byte[][] families = new byte[numFamilies][];
for (int i = 0; i < numFamilies; i++) {
families[i] = Bytes.toBytes(""family"" + i);
}
byte[][] qualifiers = new byte[numQualifiers][];
for (int i = 0; i < numQualifiers; i++) {
qualifiers[i] = Bytes.toBytes(""qual"" + i);
}
String method = ""testWritesWhileScanning"";
initHRegion(tableName, method, families);
PutThread putThread = new PutThread(numRows, families, qualifiers);
putThread.start();
FlushThread flushThread = new FlushThread();
flushThread.start();
Scan scan = new Scan(Bytes.toBytes(""row0""), Bytes.toBytes(""row1""));
int expectedCount = numFamilies * numQualifiers;
List<KeyValue> res = new ArrayList<KeyValue>();
long prevTimestamp = 0L;
for (int i = 0; i < testCount; i++) {
if ((i != 0) && ((i % compactInterval) == 0)) {
region.compactStores(true);
}
if ((i != 0) && ((i % flushInterval) == 0)) {
flushThread.flush();
}
boolean previousEmpty = res.isEmpty();
res.clear();
InternalScanner scanner = region.getScanner(scan);
while (scanner.next(res));
if (((!res.isEmpty()) || (!previousEmpty)) || (i > compactInterval)) {
assertEquals(""i="" + i, expectedCount, res.size());
long timestamp = res.get(0).getTimestamp();
assertTrue(((""Timestamps were broke: "" + timestamp) + "" prev: "") + prevTimestamp, timestamp >= prevTimestamp);
prevTimestamp = timestamp;
}
}
putThread.done();
region.flushcache();
putThread.join();
putThread.checkNoError();
flushThread.done();
flushThread.join();
flushThread.checkNoError();
}",async wait,0
143,cassandra,ColumnFamilyStoreTest.testRemoveSuperColumn,"@Test
public void testRemoveSuperColumn() throws IOException, ExecutionException, InterruptedException {
Table table = Table.open(""Table1"");
ColumnFamilyStore store = table.getColumnFamilyStore(""Super1"");
RowMutation rm;
rm = new RowMutation(""Table1"", ""key1"");
rm.add(""Super1:SC1:Column1"", ""asdf"".getBytes(), 0);
rm.apply();
store.forceBlockingFlush();
rm = new RowMutation(""Table1"", ""key1"");
rm.delete(""Super1:SC1"", 1);
rm.apply();
List<ColumnFamily> families = store.getColumnFamilies(""key1"", ""Super1"", new IdentityFilter());
assert families.get(0).getAllColumns().first().getMarkedForDeleteAt() == 1;
assert !families.get(1).getAllColumns().first().isMarkedForDelete();
ColumnFamily resolved = ColumnFamily.resolve(families);
assert resolved.getAllColumns().first().getMarkedForDeleteAt() == 1;
Collection<IColumn> subColumns = resolved.getAllColumns().first().getSubColumns();
assert subColumns.size() == 1;
assert subColumns.iterator().next().timestamp() == 0;
assertNull(ColumnFamilyStore.removeDeleted(resolved, Integer.MAX_VALUE));
}",async wait,0
144,spring-cloud-config,GiteePropertyPathNotificationExtractorTests.giteeSample,"@Test
public void giteeSample() throws Exception {
Map<String, Object> value = new ObjectMapper().readValue(new ClassPathResource(""pathsamples/gitee.json"").getInputStream(), new TypeReference<Map<String, Object>>() {});
this.headers.set(""x-git-oschina-event"", ""Push Hook"");
PropertyPathNotification extracted = this.extractor.extract(this.headers, value);
assertThat(extracted).isNotNull();
assertThat(extracted.getPaths()[0]).isEqualTo(""d.txt"");
}",unordered collections,3
145,pinot,SegmentGenerationWithTimeColumnTest.testMinAllowedValue,"@Test
public void testMinAllowedValue() {
long millis = _validMinTime;
DateTime dateTime = new DateTime(millis, DateTimeZone.UTC);
LocalDateTime localDateTime = dateTime.toLocalDateTime();
int year = localDateTime.getYear();
int month = localDateTime.getMonthOfYear();
int day = localDateTime.getDayOfMonth();
Assert.assertEquals(year, 1971);
Assert.assertEquals(month, 1);
Assert.assertEquals(day, 1);
}",time,2
146,alluxio,FileSystemMasterIntegrationTest.lastModificationTimeAddCheckpointTest,"@Test
public void lastModificationTimeAddCheckpointTest() throws Exception {
long fileId = mFsMaster.create(new TachyonURI(""/testFile""), CreateOptions.defaults());
long opTimeMs = System.currentTimeMillis();
mFsMaster.persistFileInternal(fileId, 1, opTimeMs);
FileInfo fileInfo = mFsMaster.getFileInfo(fileId);
Assert.assertEquals(opTimeMs, fileInfo.lastModificationTimeMs);
}",time,2
147,junit-quickcheck,ExhaustingAGivenSetTest.manyParameters,"@Test
public void manyParameters() throws Exception {
assertThat(testResult(ManyParameters.class), isSuccessful());
assertEquals(6, ManyParameters.iterations);
assertEquals(asList(-1, -2, -4, -1, -2, -4), ManyParameters.firstTestCases);
assertEquals(asList('r', 'r', 'r', 'y', 'y', 'y'), ManyParameters.secondTestCases);
}",unordered collections,3
148,Wikidata-Toolkit,20de6f7f12319f54eb962ff6e8357b3f5695d54d.createDefaultDirectoryManagerPath,"@Test
public void createDefaultDirectoryManagerPath() throws IOException {
Path path = Paths.get(System.getProperty(""user.dir""));
DirectoryManager dm = DirectoryManagerFactory.createDirectoryManager(
path, true);
assertTrue(dm instanceof DirectoryManagerImpl);
DirectoryManagerImpl dmi = (DirectoryManagerImpl) dm;
assertTrue(dmi.readOnly);
assertEquals(path, dmi.directory);
}",test order dependency,4
149,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testCompositeBindingUpdate,"@Test
public void testCompositeBindingUpdate() throws Exception {
final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/a"");
final ModelNode compositeOp = Operations.CompositeOperationBuilder.create()
.addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.BINDING_TYPE, NamingSubsystemModel.LOOKUP))
.addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/b""))
.build().getOperation();
ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
}",test order dependency,4
150,killbill,TestOverdueIntegration.testOverdueStateIfNoPaymentMethod,"@Test
public void testOverdueStateIfNoPaymentMethod() throws Exception {
clock.setTime(new DateTime(2012, 5, 1, 0, 3, 42, 0));
setupAccount();
accountInternalApi.removePaymentMethod(account.getId(), internalCallContext);
final DefaultEntitlement baseEntitlement = createBaseEntitlementAndCheckForCompletion(account.getId(), ""externalKey"", productName, BASE, term, CREATE, BLOCK, INVOICE);
bundle = subscriptionApi.getSubscriptionBundle(baseEntitlement.getBundleId(), callContext);
invoiceChecker.checkInvoice(account.getId(), 1, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 1), null, InvoiceItemType.FIXED, new BigDecimal(""0"")));
invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 5, 1), callContext);
addDaysAndCheckForCompletion(30, PHASE, INVOICE, INVOICE_PAYMENT_ERROR);
invoiceChecker.checkInvoice(account.getId(), 2, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 31), new LocalDate(2012, 6, 30), InvoiceItemType.RECURRING, new BigDecimal(""249.95"")));
invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 6, 30), callContext);
checkODState(CLEAR_STATE_NAME);
addDaysAndCheckForCompletion(15);
checkODState(CLEAR_STATE_NAME);
addDaysAndCheckForCompletion(20, BLOCK, INVOICE, INVOICE_PAYMENT_ERROR);
invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95"")));
invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 7, 31), callContext);
checkODState(""OD1"");
checkChangePlanWithOverdueState(baseEntitlement, true, true);
addDaysAndCheckForCompletion(2);
checkODState(""OD1"");
checkChangePlanWithOverdueState(baseEntitlement, true, true);
addDaysAndCheckForCompletion(8, BLOCK, TAG);
checkODState(""OD2"");
checkChangePlanWithOverdueState(baseEntitlement, true, true);
addDaysAndCheckForCompletion(10, BLOCK);
checkODState(""OD3"");
checkChangePlanWithOverdueState(baseEntitlement, true, true);
paymentApi.addPaymentMethod(account, UUID.randomUUID().toString(), NON_OSGI_PLUGIN_NAME, true, paymentMethodPlugin, PLUGIN_PROPERTIES, callContext);
allowPaymentsAndResetOverdueToClearByPayingAllUnpaidInvoices(false);
invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95"")));
invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63"")));
invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 7, 31), callContext);
checkChangePlanWithOverdueState(baseEntitlement, false, false);
invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63"")));
invoiceChecker.checkInvoice(account.getId(), 5, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""116.12"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-48.38"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""-67.74"")));
invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 7, 31), callContext);
assertEquals(invoiceUserApi.getAccountBalance(account.getId(), callContext).compareTo(new BigDecimal(""-12.89"")), 0);
}",time,2
151,ambari,TestHeartbeatMonitor.testHeartbeatExpiry,"@Test
public void testHeartbeatExpiry() throws Exception {
Clusters fsm = mock(Clusters.class);
ActionQueue aq = new ActionQueue();
ActionManager am = mock(ActionManager.class);
HostState hs = HostState.WAITING_FOR_HOST_STATUS_UPDATES;
List<Host> allHosts = new ArrayList<Host>();
Host hostObj = mock(Host.class);
allHosts.add(hostObj);
when(fsm.getHosts()).thenReturn(allHosts);
when(fsm.getHost(""host1"")).thenReturn(hostObj);
when(hostObj.getState()).thenReturn(hs);
when(hostObj.getHostName()).thenReturn(""host1"");
aq.enqueue(""host1"", new ExecutionCommand());
HeartbeatMonitor hm = new HeartbeatMonitor(fsm, aq, am, 100);
hm.start();
Thread.sleep(120);
assertEquals(0, aq.dequeueAll(""host1"").size());
verify(am, times(1)).handleLostHost(""host1"");
verify(hostObj, times(1)).handleEvent(any(HostEvent.class));
verify(hostObj, times(1)).setState(INIT);
hm.shutdown();
}",async wait,0
152,dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testListAllPort,"@Test
public void testListAllPort() throws RemotingException {
String result = port.telnet(null, """");
assertEquals(""20887"", result);
}",test order dependency,4
153,androidx,testOneTimeRequest_noInitialDelay_withConstraintNetworkConnected,"@Test
public void testOneTimeRequest_noInitialDelay_withConstraintNetworkConnected() {
val now = System.currentTimeMillis() ;
when(mTaskConverter.now()).thenReturn(now) ;
val constraints = Constraints.Builder().setRequiredNetworkType(NetworkType.METERED).setRequiresCharging(true).build() ;
val request = OneTimeWorkRequestBuilder<TestWorker>()
.setConstraints(constraints)
.build() ;
val task = mTaskConverter.convert(request.workSpec) ;
val expected = request.workSpec.calculateNextRunTime() ;
val offset = offset(expected, now) ;
assertEquals(task.serviceName, WorkManagerGcmService::class.java.name) ;
assertEquals(task.isPersisted, false) ;
assertEquals(task.isUpdateCurrent, true) ;
assertEquals(task.requiredNetwork, Task.NETWORK_STATE_CONNECTED) ;
assertEquals(task.requiresCharging, true) ;
assertEquals(task.windowStart, offset) ;
assertEquals(task.windowEnd, offset + EXECUTION_WINDOW_SIZE_IN_SECONDS) ;
}",time,2
154,cdap,TestFrameworkTestRun.testWorkerInstances,"@Test
public void testWorkerInstances() throws Exception {
ApplicationManager applicationManager = deployApplication(testSpace, AppUsingGetServiceURL.class);
WorkerManager workerManager = applicationManager.getWorkerManager(PINGING_WORKER).start();
workerManager.waitForStatus(true);
workerInstancesCheck(workerManager, 5);
workerManager.setInstances(10);
workerInstancesCheck(workerManager, 10);
workerManager.setInstances(2);
workerInstancesCheck(workerManager, 2);
workerManager.setInstances(2);
workerInstancesCheck(workerManager, 2);
WorkerManager lifecycleWorkerManager = applicationManager.getWorkerManager(LIFECYCLE_WORKER).start();
lifecycleWorkerManager.waitForStatus(true);
lifecycleWorkerManager.setInstances(5);
workerInstancesCheck(lifecycleWorkerManager, 5);
for (int i = 0; i < 5; i++) {
kvTableKeyCheck(testSpace, WORKER_INSTANCES_DATASET, Bytes.toBytes(String.format(""init.%d"", i)));
}
lifecycleWorkerManager.stop();
lifecycleWorkerManager.waitForStatus(false);
if (workerManager.isRunning()) {
workerManager.stop();
}
workerManager.waitForStatus(false);
workerInstancesCheck(lifecycleWorkerManager, 5);
workerInstancesCheck(workerManager, 2);
assertWorkerDatasetWrites(Bytes.toBytes(""init""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init.2"")), 3, 3);
assertWorkerDatasetWrites(Bytes.toBytes(""init.3""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init"")), 2, 5);
byte[] startRow = Bytes.toBytes(""stop"");
assertWorkerDatasetWrites(startRow, Bytes.stopKeyForPrefix(startRow), 5, 5);
}",async wait,0
155,tapestry,FormTests.regexp_validator,"@Test
public void regexp_validator() {
clickThru(""Regexp Demo"");
String update = SUBMIT;
type(""zipCode"", ""abc"");
click(update);
assertTextPresent(""A zip code consists of five or nine digits"");
type(""zipCode"", ""12345"");
clickAndWait(update);
assertTextPresent(""Zip code: [12345]"");
type(""zipCode"", ""12345-9876"");
clickAndWait(update);
assertTextPresent(""Zip code: [12345-9876]"");
}",async wait,0
156,astraea,MetricsTest.testBytes,"@Test
void testBytes() throws InterruptedException {
final CountDownLatch countDownLatch = new CountDownLatch(1);
final Metrics metrics = new Metrics();
final LongAdder longAdder = new LongAdder();
final long input = 100;
final int loopCount = 10000;
Thread adder = new Thread(() -> {
try {
countDownLatch.await();
} catch (InterruptedException ignore) {
}
for (int i = 0; i < loopCount; ++i) {
metrics.addBytes(input);
}
});
Thread getter = new Thread(() -> {
try {
countDownLatch.await();
} catch (InterruptedException ignore) {
}
for (int i = 0; i < loopCount; ++i) {
longAdder.add(metrics.bytesThenReset());
}
});
adder.start();
getter.start();
countDownLatch.countDown();
adder.join();
longAdder.add(metrics.bytesThenReset());
Assertions.assertEquals(loopCount * input, longAdder.sum());
}",concurrency,1
157,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testStoredContext,"@Test
public void testStoredContext() throws Exception {
final ServiceName bindingName = ServiceName.JBOSS.append(""foo-stored"").append(""again"");
bindObject(bindingName, new Context() {
@Override
public Object lookup(Name name) throws NamingException {
if (""blah/blah2"".equals(name.toString())) {
return new Integer(5);
}
return null;
}
@Override
public Object lookup(String name) throws NamingException {
return lookup(new CompositeName(name));
}
@Override
public void bind(Name name, Object obj) throws NamingException {
}
@Override
public void bind(String name, Object obj) throws NamingException {
}
@Override
public void rebind(Name name, Object obj) throws NamingException {
}
@Override
public void rebind(String name, Object obj) throws NamingException {
}
@Override
public void unbind(Name name) throws NamingException {
}
@Override
public void unbind(String name) throws NamingException {
}
@Override
public void rename(Name oldName, Name newName) throws NamingException {
}
@Override
public void rename(String oldName, String newName) throws NamingException {
}
@Override
public NamingEnumeration<NameClassPair> list(Name name) throws NamingException {
return null;
}
@Override
public NamingEnumeration<NameClassPair> list(String name) throws NamingException {
return null;
}
@Override
public NamingEnumeration<Binding> listBindings(Name name) throws NamingException {
if (!""hi/there"".equals(name.toString()))
throw new IllegalArgumentException(""Expected hi/there"");
return null;
}
@Override
public NamingEnumeration<Binding> listBindings(String name) throws NamingException {
return null;
}
@Override
public void destroySubcontext(Name name) throws NamingException {
}
@Override
public void destroySubcontext(String name) throws NamingException {
}
@Override
public Context createSubcontext(Name name) throws NamingException {
return null;
}
@Override
public Context createSubcontext(String name) throws NamingException {
return null;
}
@Override
public Object lookupLink(Name name) throws NamingException {
return null;
}
@Override
public Object lookupLink(String name) throws NamingException {
return null;
}
@Override
public NameParser getNameParser(Name name) throws NamingException {
return null;
}
@Override
public NameParser getNameParser(String name) throws NamingException {
return null;
}
@Override
public Name composeName(Name name, Name prefix) throws NamingException {
return null;
}
@Override
public String composeName(String name, String prefix) throws NamingException {
return null;
}
@Override
public Object addToEnvironment(String propName, Object propVal) throws NamingException {
return null;
}
@Override
public Object removeFromEnvironment(String propName) throws NamingException {
return null;
}
@Override
public Hashtable<?, ?> getEnvironment() throws NamingException {
return null;
}
@Override
public void close() throws NamingException {
}
@Override
public String getNameInNamespace() throws NamingException {
return null;
}
});
final NamingContext ctx = new NamingContext(new CompositeName(), store, null);
final Object obj = ctx.lookup(new CompositeName(""foo-stored/again/blah/blah2""));
ctx.listBindings(""foo-stored/again/hi/there"");
assertNotNull(obj);
assertEquals(new Integer(5), obj);
}",test order dependency,4
158,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindAndRetrieveObjectFactoryFromInitialContext,"@Test
public void testBindAndRetrieveObjectFactoryFromInitialContext() throws Exception {
final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
namingStore.bind(new CompositeName(""test""), reference);
final InitialContext initialContext = new InitialContext();
final Object result = initialContext.lookup(""test"");
assertTrue(result instanceof String);
assertEquals(""Test ParsedResult"", result);
}",test order dependency,4
159,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireOneLevelEvent,"@Test
public void testFireOneLevelEvent() throws Exception {
final NamingEventCoordinator coordinator = new NamingEventCoordinator();
final CollectingListener objectListener = new CollectingListener(0);
coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
final CollectingListener subtreeListener = new CollectingListener(0);
coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
final CollectingListener oneLevelListener = new CollectingListener(1);
coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.ONELEVEL_SCOPE);
oneLevelListener.latch.await(1, TimeUnit.SECONDS);
assertTrue(objectListener.capturedEvents.isEmpty());
assertTrue(subtreeListener.capturedEvents.isEmpty());
assertEquals(1, oneLevelListener.capturedEvents.size());
}",test order dependency,4
160,hbase,TestSplitLogManager.testVanishingTaskZNode,"@Test
public void testVanishingTaskZNode() throws Exception {
LOG.info(""testVanishingTaskZNode"");
conf.setInt(""hbase.splitlog.manager.unassigned.timeout"", 0);
slm = new SplitLogManager(zkw, conf, stopper, ""dummy-master"", null);
slm.finishInitialization();
FileSystem fs = TEST_UTIL.getTestFileSystem();
final Path logDir = new Path(fs.getWorkingDirectory(), UUID.randomUUID().toString());
fs.mkdirs(logDir);
Thread thread = null;
try {
Path logFile = new Path(logDir, UUID.randomUUID().toString());
fs.createNewFile(logFile);
thread = new Thread() {
public void run() {
try {
slm.splitLogDistributed(logDir);
} catch (Exception e) {
LOG.warn(""splitLogDistributed failed"", e);
}
}
};
thread.start();
waitForCounter(tot_mgr_node_create_result, 0, 1, 10000);
String znode = ZKSplitLog.getEncodedNodeName(zkw, logFile.toString());
ZKUtil.deleteNode(zkw, znode);
waitForCounter(tot_mgr_get_data_nonode, 0, 1, 30000);
waitForCounter(tot_mgr_log_split_batch_success, 0, 1, 1000);
assertTrue(fs.exists(logFile));
} finally {
if (thread != null) {
thread.interrupt();
}
fs.delete(logDir, true);
}
}",concurrency,1
161,zeebe,AtomixTransportTest.shouldOnlyHandleRequestsOfSubscribedTypes,"@Test
public void shouldOnlyHandleRequestsOfSubscribedTypes() {
serverTransport.subscribe(0, COMMAND, new DirectlyResponder());
serverTransport.subscribe(0, UNKNOWN, new FailingResponder());
final var requestFuture = clientTransport.sendRequest(() -> AtomixTransportTest.serverAddress, new Request(""messageABC""), REQUEST_TIMEOUT);
final var response = requestFuture.join();
assertThat(response.byteArray()).isEqualTo(""messageABC"".getBytes());
}",async wait,0
162,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupWitResolveResult,"@Test
public void testLookupWitResolveResult() throws Exception {
namingStore.bind(new CompositeName(""test/nested""), ""test"");
final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null);
namingStore.bind(new CompositeName(""comp""), reference);
Object result = namingContext.lookup(new CompositeName(""comp/nested""));
assertEquals(""test"", result);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test/nested"", ""lookup"")), namingContext, ""comp/nested"");
assertEquals(""test"", result);
}",test order dependency,4
163,storio,NotifyAboutChangesTest.notifyAboutChangesConcurrently,"@Test
public void notifyAboutChangesConcurrently() {
final int numberOfThreads = 100;
final TestSubscriber<Changes> testSubscriber = new TestSubscriber<Changes>();
final Set<String> tables = new HashSet<String>();
final List<Changes> expectedChanges = new ArrayList<Changes>();
for (int i = 0; i < numberOfThreads; i++) {
final String table = ""test_table"" + i;
tables.add(table);
expectedChanges.add(Changes.newInstance(table));
}
storIOSQLite.observeChanges(LATEST).subscribe(testSubscriber);
final CountDownLatch startAllThreadsLock = new CountDownLatch(1);
for (int i = 0; i < numberOfThreads; i++) {
final int finalI = i;
new Thread(new Runnable() {
@Override
public void run() {
try {
startAllThreadsLock.await();
} catch (InterruptedException e) {
throw new RuntimeException(e);
}
storIOSQLite.lowLevel().notifyAboutChanges(Changes.newInstance(""test_table"" + finalI));
}
}).start();
}
startAllThreadsLock.countDown();
final long startTime = SystemClock.elapsedRealtime();
while ((testSubscriber.valueCount() != tables.size()) && ((SystemClock.elapsedRealtime() - startTime) < 20000)) {
Thread.yield();
}
testSubscriber.assertNoErrors();
testSubscriber.assertValueCount(expectedChanges.size());
assertThat(expectedChanges.containsAll(testSubscriber.values())).isTrue();
}",concurrency,1
164,ignite,GridCacheRebalancingWithAsyncClearingTest.testCorrectRebalancingCurrentlyRentingPartitions,"@Test
public void testCorrectRebalancingCurrentlyRentingPartitions() throws Exception {
IgniteEx ignite = ((IgniteEx) (startGrids(3)));
ignite.cluster().active(true);
final int keysCnt = SF.applyLB(300000, 10000);
try (final IgniteDataStreamer<Integer, Integer> ds = ignite.dataStreamer(CACHE_NAME)) {
log.info(""Writing initial data..."");
ds.allowOverwrite(true);
for (int k = 1; k <= keysCnt; k++) {
ds.addData(k, k);
if ((k % 10000) == 0) {
log.info((""Written "" + k) + "" entities."");
}
}
log.info(""Writing initial data finished."");
}
startGrid(3);
resetBaselineTopology();
stopGrid(3);
resetBaselineTopology();
stopGrid(1);
startGrid(1);
awaitPartitionMapExchange();
for (int k = 1; k <= keysCnt; k++) {
Integer val = ((Integer) (ignite.cache(CACHE_NAME).get(k)));
Assert.assertNotNull((""Value for "" + k) + "" is null"", val);
Assert.assertEquals(((""Check failed for "" + k) + "" = "") + val, k, ((int) (val)));
}
}",concurrency,1
165,continuum,BuildAgentsTest.testAddAnExistingBuildAgent,"@Test
public void testAddAnExistingBuildAgent() {
String BUILD_AGENT_NAME = getProperty(""BUILD_AGENT_NAME"");
String BUILD_AGENT_DESCRIPTION = getProperty(""BUILD_AGENT_DESCRIPTION"");
enableDistributedBuilds();
goToAddBuildAgent();
addBuildAgent(BUILD_AGENT_NAME, BUILD_AGENT_DESCRIPTION, false, false);
assertTextPresent(""Build agent already exists"");
disableDistributedBuilds();
}",async wait,0
166,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRejectionEAP7,"@Test
public void testRejectionsEAP7() throws Exception {
testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_7_0_0, ModelVersion.create(2, 0), ""wildfly-naming"");
}",test order dependency,4
167,neo4j,RaftMessageProcessingMetricTest.shouldBeAbleToUpdateAllMessageTypes,"@Test
public void shouldBeAbleToUpdateAllMessageTypes() throws Throwable
{
int durationNanos = 5;
for ( RaftMessages.Type type : RaftMessages.Type.values() )
{
metric.updateTimer( type, Duration.ofNanos( durationNanos ) );
assertEquals( 1, metric.timer( type ).getCount() );
assertEquals( durationNanos, metric.timer( type ).getSnapshot().getMean(), 0 );
}
assertEquals( RaftMessages.Type.values().length, metric.timer().getCount() );
assertEquals( 0, metric.timer().getSnapshot().getMean(), durationNanos );
}",time,2
168,shardingsphere-elasticjob,b022898ef1b8c984e17efb2a422ee45f6b13e46e.assertPersistEphemeralSequential,"@Test
public void assertPersistEphemeralSequential() throws Exception {
zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential"");
zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential"");
CuratorFramework client = CuratorFrameworkFactory.newClient(EmbedTestingServer.getConnectionString(), new RetryOneTime(2000));
client.start();
client.blockUntilConnected();
List<String> actual = client.getChildren().forPath(""/"" + ZookeeperRegistryCenterModifyTest.class.getName() + ""/sequential"");
assertThat(actual.size(), is(2));
for (String each : actual) {
assertThat(each, startsWith(""test_ephemeral_sequential""));
}
zkRegCenter.close();
actual = client.getChildren().forPath(""/"" + ZookeeperRegistryCenterModifyTest.class.getName() + ""/sequential"");
assertTrue(actual.isEmpty());
zkRegCenter.init();
}",test order dependency,4
169,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindNested,"@Test
public void testBindNested() throws Exception {
final Name name = new CompositeName(""nested/test"");
final Object value = new Object();
WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
try {
store.bind(name, value);
} finally {
WritableServiceBasedNamingStore.popOwner();
}
assertEquals(value, store.lookup(name));
}",test order dependency,4
170,pulsar,AntiAffinityNamespaceGroupTest.testBrokerSelectionForAntiAffinityGroup,"@Test
public void testBrokerSelectionForAntiAffinityGroup() throws Exception {
final String broker1 = primaryHost;
final String broker2 = secondaryHost;
final String cluster = pulsar1.getConfiguration().getClusterName();
final String tenant = ""tenant-"" + UUID.randomUUID().toString();
final String namespace1 = ((tenant + ""/"") + cluster) + ""/ns1"";
final String namespace2 = ((tenant + ""/"") + cluster) + ""/ns2"";
final String namespaceAntiAffinityGroup = ""group"";
FailureDomain domain1 = new FailureDomain();
domain1.brokers = Sets.newHashSet(broker1);
admin1.clusters().createFailureDomain(cluster, ""domain1"", domain1);
FailureDomain domain2 = new FailureDomain();
domain2.brokers = Sets.newHashSet(broker2);
admin1.clusters().createFailureDomain(cluster, ""domain2"", domain2);
admin1.tenants().createTenant(tenant, new TenantInfo(null, Sets.newHashSet(cluster)));
admin1.namespaces().createNamespace(namespace1);
admin1.namespaces().createNamespace(namespace2);
admin1.namespaces().setNamespaceAntiAffinityGroup(namespace1, namespaceAntiAffinityGroup);
admin1.namespaces().setNamespaceAntiAffinityGroup(namespace2, namespaceAntiAffinityGroup);
for (int i = 0; i < 5; i++) {
if ((!isLoadManagerUpdatedDomainCache(primaryLoadManager)) || (!isLoadManagerUpdatedDomainCache(secondaryLoadManager))) {
Thread.sleep(200);
} else {
break;
}
}
assertTrue(isLoadManagerUpdatedDomainCache(primaryLoadManager));
assertTrue(isLoadManagerUpdatedDomainCache(secondaryLoadManager));
ServiceUnitId serviceUnit1 = makeBundle(tenant, cluster, ""ns1"");
String selectedBroker1 = primaryLoadManager.selectBrokerForAssignment(serviceUnit1).get();
ServiceUnitId serviceUnit2 = makeBundle(tenant, cluster, ""ns2"");
String selectedBroker2 = primaryLoadManager.selectBrokerForAssignment(serviceUnit2).get();
assertNotEquals(selectedBroker1, selectedBroker2);
}",concurrency,1
171,aismessages,7b0c4c708b6bb9a6da3d5737bcad1857ade8a931.canHandleFragmentedMessageReceived,"@Test
public void canHandleFragmentedMessageReceived() {
NMEAMessage fragmentedNMEAMessage1 = NMEAMessage.fromString(""!AIVDM,2,1,3,B,55DA><02=6wpPuID000qTf059@DlU<00000000171lMDD4q20LmDp3hB,0*27"");
NMEAMessage fragmentedNMEAMessage2 = NMEAMessage.fromString(""!AIVDM,2,2,3,B,p=Mh00000000000,2*4C"");
final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>();
context.checking(new Expectations() {{
oneOf(aisMessageHandler).accept(with(aisMessage.getMatcher()));
}});
aisMessageReceiver.accept(fragmentedNMEAMessage1);
aisMessageReceiver.accept(fragmentedNMEAMessage2);
assertEquals(AISMessageType.ShipAndVoyageRelatedData, aisMessage.getCapturedObject().getMessageType());
}",test order dependency,4
172,servicemix,WSNComponentTest.testPauseResume,"@Test
public void testPauseResume() throws Exception {
PullPoint pullPoint = wsnCreatePullPoint.createPullPoint();
Subscription subscription = wsnBroker.subscribe(pullPoint.getEndpoint(), ""myTopic"", null);
wsnBroker.notify(""myTopic"", new Notify());
Thread.sleep(500);
assertEquals(1, pullPoint.getMessages(0).size());
subscription.pause();
wsnBroker.notify(""myTopic"", new Notify());
Thread.sleep(500);
assertEquals(0, pullPoint.getMessages(0).size());
subscription.resume();
wsnBroker.notify(""myTopic"", new Notify());
Thread.sleep(500);
assertEquals(1, pullPoint.getMessages(0).size());
Thread.sleep(500);
}",async wait,0
173,hadoop,TestPathData.testQualifiedUriContents,"@Test
public void testQualifiedUriContents() throws Exception {
dirString = fs.makeQualified(new Path(""d1"")).toString();
item = new PathData(dirString, conf);
PathData[] items = item.getDirectoryContents();
assertEquals(sortedString(dirString + ""/f1"", dirString + ""/f1.1"", dirString + ""/f2""), sortedString(items));
}",test order dependency,4
174,ormlite-core,DatabaseFieldConfigTest.testFromDbField,"@Test
public void testFromDbField() throws Exception {
Field[] fields = Foo.class.getDeclaredFields();
assertTrue(fields.length >= 1);
DatabaseFieldConfig config = DatabaseFieldConfig.fromField(databaseType, ""foo"", fields[0]);
assertNotNull(config);
assertTrue(config.isCanBeNull());
assertEquals(fields[0].getName(), config.getFieldName());
}",unordered collections,3
175,beam,testRateLimitingMax,"@Test
public void testRateLimitingMax() {
int n = 10;
double rate = 10.0;
long duration = runWithRate(n, rate, new IdentityFn<Integer>());
long perElementPause = (long) (1000L / rate);
long minDuration = (n - 1) * perElementPause;
Assert.assertThat(duration, greaterThan(minDuration));
}",time,2
176,avro,TestTraceCollection.testRecursingTrace,"@Test
public void testRecursingTrace() throws Exception {
TracePluginConfiguration conf = new TracePluginConfiguration();
conf.traceProb = 1.0;
conf.port = 51010;
conf.clientPort = 12346;
TracePlugin aPlugin = new TracePlugin(conf);
conf.port = 51011;
conf.clientPort = 12347;
TracePlugin bPlugin = new TracePlugin(conf);
conf.port = 51012;
conf.clientPort = 12348;
TracePlugin cPlugin = new TracePlugin(conf);
conf.port = 51013;
conf.clientPort = 12349;
TracePlugin dPlugin = new TracePlugin(conf);
Responder bRes = new RecursingResponder(TestBasicTracing.advancedProtocol, bPlugin);
bRes.addRPCPlugin(bPlugin);
HttpServer server1 = new HttpServer(bRes, 21005);
server1.start();
Responder cRes = new EndpointResponder(TestBasicTracing.advancedProtocol);
cRes.addRPCPlugin(cPlugin);
HttpServer server2 = new HttpServer(cRes, 21006);
server2.start();
Responder dRes = new EndpointResponder(TestBasicTracing.advancedProtocol);
dRes.addRPCPlugin(dPlugin);
HttpServer server3 = new HttpServer(dRes, 21007);
server3.start();
HttpTransceiver trans = new HttpTransceiver(new URL(""http:www.example.com""));
GenericRequestor r = new GenericRequestor(TestBasicTracing.advancedProtocol, trans);
r.addRPCPlugin(aPlugin);
GenericRecord params = new GenericData.Record(advancedProtocol.getMessages().get(""w"").getRequest());
params.put(""req"", 1);
for (int i = 0; i < 40; i++) {
r.request(""w"", params);
}
List<Span> allSpans = new ArrayList<Span>();
allSpans.addAll(aPlugin.storage.getAllSpans());
allSpans.addAll(bPlugin.storage.getAllSpans());
allSpans.addAll(cPlugin.storage.getAllSpans());
allSpans.addAll(dPlugin.storage.getAllSpans());
SpanAggregationResults results = SpanAggregator.getFullSpans(allSpans);
assertEquals(0, results.incompleteSpans.size());
List<Span> merged = results.completeSpans;
List<Trace> traces = SpanAggregator.getTraces(merged).traces;
assertEquals(40, traces.size());
TraceCollection collection = new TraceCollection(traces.get(0));
for (Trace t : traces) {
collection.addTrace(t);
}
server1.close();
server2.close();
server3.close();
aPlugin.httpServer.close();
aPlugin.clientFacingServer.stop();
bPlugin.httpServer.close();
bPlugin.clientFacingServer.stop();
cPlugin.httpServer.close();
cPlugin.clientFacingServer.stop();
dPlugin.httpServer.close();
dPlugin.clientFacingServer.stop();
}",async wait,0
177,pulsar,NamespacesTest.testSubscribeRate,"@Test
public void testSubscribeRate() throws Exception {
SubscribeRate subscribeRate = new SubscribeRate(1, 5);
String namespace = ""my-tenants/my-namespace"";
admin.tenants().createTenant(""my-tenants"", new TenantInfoImpl(Sets.newHashSet(), Sets.newHashSet(testLocalCluster)));
admin.namespaces().createNamespace(namespace, Sets.newHashSet(testLocalCluster));
admin.namespaces().setSubscribeRate(namespace, subscribeRate);
assertEquals(subscribeRate, admin.namespaces().getSubscribeRate(namespace));
String topicName = ((""persistent""));
admin.topics().createPartitionedTopic(topicName, 2);
pulsar.getConfiguration().setAuthorizationEnabled(false);
Consumer<?> consumer = pulsarClient.newConsumer().topic(topicName).subscriptionType(Shared).subscriptionName(""subscribe-rate"").subscribe();
assertTrue(consumer.isConnected());
pulsarClient.updateServiceUrl(lookupUrl.toString());
Awaitility.await().untilAsserted(() -> assertFalse(consumer.isConnected()));
Thread.sleep(6000L);
pulsarClient.updateServiceUrl(lookupUrl.toString());
assertTrue(consumer.isConnected());
subscribeRate = new SubscribeRate(0, 10);
admin.namespaces().setSubscribeRate(namespace, subscribeRate);
pulsarClient.updateServiceUrl(lookupUrl.toString());
Awaitility.await().untilAsserted(() -> assertTrue(consumer.isConnected()));
pulsar.getConfiguration().setAuthorizationEnabled(true);
admin.topics().deletePartitionedTopic(topicName, true);
admin.namespaces().deleteNamespace(namespace);
admin.tenants().deleteTenant(""my-tenants"");
}",async wait,0
178,reactive-grpc,ChainedCallIntegrationTest.servicesCanCallOtherServices,"@Test
public void servicesCanCallOtherServices() throws InterruptedException {
ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
Mono<String> chain =
Mono.just(request(""X"")).compose(stub::sayHello).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).as(stub::sayHelloRespStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).compose(stub::sayHelloBothStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).as(stub::sayHelloReqStream).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).compose(stub::sayHello).map(HelloResponse::getMessage).doOnSuccess(System.out::println);
StepVerifier.create(chain).expectNext(""[<{[X]}> :: </[X]/> :: <\\[X]\\> :: <([X])>]"").expectComplete().verify(Duration.ofSeconds(2));
}",concurrency,1
179,crate,SniffConnectionStrategyTests.testSniffStrategyWillConnectToAndDiscoverNodes,"@Test
public void testSniffStrategyWillConnectToAndDiscoverNodes() {
List<DiscoveryNode> knownNodes = new CopyOnWriteArrayList<>();
try (MockTransportService seedTransport = startTransport(""seed_node"", knownNodes, Version.CURRENT);
MockTransportService discoverableTransport = startTransport(""discoverable_node"", knownNodes, Version.CURRENT)) {
DiscoveryNode seedNode = seedTransport.getLocalNode();
DiscoveryNode discoverableNode = discoverableTransport.getLocalNode();
knownNodes.add(seedNode);
knownNodes.add(discoverableNode);
Collections.shuffle(knownNodes, random());
try (MockTransportService localService = MockTransportService.createNewService(Settings.EMPTY, Version.CURRENT, threadPool)) {
localService.start();
localService.acceptIncomingRequests();
ClusterConnectionManager connectionManager = new ClusterConnectionManager(profile, localService.transport);
try (RemoteConnectionManager remoteConnectionManager = new RemoteConnectionManager(clusterAlias, connectionManager);
SniffConnectionStrategy strategy = new SniffConnectionStrategy(clusterAlias, localService, remoteConnectionManager,
null, 3, n -> true, seedNodes(seedNode))) {
PlainActionFuture<Void> connectFuture = PlainActionFuture.newFuture();
strategy.connect(connectFuture);
connectFuture.actionGet();
assertTrue(connectionManager.nodeConnected(seedNode));
assertTrue(connectionManager.nodeConnected(discoverableNode));
assertTrue(strategy.assertNoRunningConnections());
}
}
}
}",async wait,0
180,symphony-wdk,SendMessageIntegrationTest.sendMessageOnMessage,"@Test
void sendMessageOnMessage() throws Exception {
final Workflow workflow = SwadlParser.fromYaml(getClass().getResourceAsStream(""/message/send-message-on-message.swadl.yaml""));
final V4Message message = message(""Hello!"");
engine.deploy(workflow);
engine.onEvent(messageReceived(""/message""));
when(messageService.send(anyString(), any(Message.class))).thenReturn(message);
verify(messageService, timeout(5000)).send(anyString(), any(Message.class));
assertThat(workflow).isExecuted().hasOutput(String.format(OUTPUTS_MSG_KEY, ""sendMessage1""), message).hasOutput(String.format(OUTPUTS_MSG_ID_KEY, ""sendMessage1""), message.getMessageId());
}",async wait,0
181,spring-data-couchbase,MappingCouchbaseConverterTests.writesAndReadsCustomFieldsConvertedClass,"@Test
void writesAndReadsCustomFieldsConvertedClass() {
List<Object> converters = new ArrayList<>();
converters.add(BigDecimalToStringConverter.INSTANCE);
converters.add(StringToBigDecimalConverter.INSTANCE);
CustomConversions customConversions = new CouchbaseCustomConversions(converters);
converter.setCustomConversions(customConversions);
converter.afterPropertiesSet();
((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(customConversions.getSimpleTypeHolder());
CouchbaseDocument converted = new CouchbaseDocument();
final String valueStr = ""12.345"";
final BigDecimal value = new BigDecimal(valueStr);
final String value2Str = ""0.6789"";
final BigDecimal value2 = new BigDecimal(value2Str);
List<BigDecimal> listOfValues = new ArrayList<>();
listOfValues.add(value);
listOfValues.add(value2);
Map<String, BigDecimal> mapOfValues = new HashMap<>();
mapOfValues.put(""val1"", value);
mapOfValues.put(""val2"", value2);
CustomFieldsEntity entity = new CustomFieldsEntity(value, listOfValues, mapOfValues);
converter.write(entity, converted);
CouchbaseDocument source = new CouchbaseDocument();
source.put(""_class"", CustomFieldsEntity.class.getName());
source.put(""decimalValue"", valueStr);
CouchbaseList listOfValuesDoc = new CouchbaseList();
listOfValuesDoc.put(valueStr);
listOfValuesDoc.put(value2Str);
source.put(""listOfDecimalValues"", listOfValuesDoc);
CouchbaseDocument mapOfValuesDoc = new CouchbaseDocument();
mapOfValuesDoc.put(""val1"", valueStr);
mapOfValuesDoc.put(""val2"", value2Str);
source.put(""mapOfDecimalValues"", mapOfValuesDoc);
assertThat(valueStr).isEqualTo(((CouchbaseList) (converted.getContent().get(""listOfDecimalValues""))).get(0));
assertThat(value2Str).isEqualTo(((CouchbaseList) (converted.getContent().get(""listOfDecimalValues""))).get(1));
assertThat(converted.export().toString()).isEqualTo(source.export().toString());
CustomFieldsEntity readConverted = converter.read(CustomFieldsEntity.class, source);
assertThat(readConverted.value).isEqualTo(value);
assertThat(readConverted.listOfValues.get(0)).isEqualTo(listOfValues.get(0));
assertThat(readConverted.listOfValues.get(1)).isEqualTo(listOfValues.get(1));
assertThat(readConverted.mapOfValues.get(""val1"")).isEqualTo(mapOfValues.get(""val1""));
assertThat(readConverted.mapOfValues.get(""val2"")).isEqualTo(mapOfValues.get(""val2""));
}",unordered collections,3
182,shardingsphere-elasticjob,b022898ef1b8c984e17efb2a422ee45f6b13e46e.assertGetLocalFailoverItemsIfShutdown,"@Test
public void assertGetLocalFailoverItemsIfShutdown() {
assertThat(failoverService.getLocalFailoverItems(), is(Collections.<Integer>emptyList()));
verify(jobNodeStorage, times(0)).getJobNodeChildrenKeys(""sharding"");
}",test order dependency,4
183,servicemix,WSNComponentTest.testPull,"@Test
public void testPull() throws Exception {
PullPoint pullPoint = wsnCreatePullPoint.createPullPoint();
wsnBroker.subscribe(pullPoint.getEndpoint(), ""myTopic"", null);
wsnBroker.notify(""myTopic"", new Notify());
Thread.sleep(500);
List<NotificationMessageHolderType> msgs = pullPoint.getMessages(0);
assertNotNull(msgs);
assertEquals(1, msgs.size());
Thread.sleep(500);
}",async wait,0
184,InactiveTopicDeleteTest ,testTopicLevelInactivePolicyUpdateAndClean,"@Test
public void testTopicLevelInactivePolicyUpdateAndClean() throws Exception {
super.resetConfig();
conf.setSystemTopicEnabled(true);
conf.setTopicLevelPoliciesEnabled(true);
conf.setBrokerDeleteInactiveTopicsEnabled(true);
conf.setBrokerDeleteInactiveTopicsMaxInactiveDurationSeconds(1000);
conf.setBrokerDeleteInactiveTopicsMode(delete_when_no_subscriptions);
InactiveTopicPolicies defaultPolicy = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1000, true);
super.baseSetup();
Thread.sleep(2000);
final String namespace = ""prop/ns-abc"";
final String topic = ""persistent"";
final String topic2 = ""persistent"";
final String topic3 = ""persistent"";
List<String> topics = Arrays.asList(topic, topic2, topic3);
for (String tp : topics) {
admin.topics().createNonPartitionedTopic(tp);
}
InactiveTopicPolicies inactiveTopicPolicies = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1, true);
admin.topics().setInactiveTopicPolicies(topic, inactiveTopicPolicies);
inactiveTopicPolicies.setInactiveTopicDeleteMode(delete_when_subscriptions_caught_up);
admin.topics().setInactiveTopicPolicies(topic2, inactiveTopicPolicies);
inactiveTopicPolicies.setInactiveTopicDeleteMode(delete_when_no_subscriptions);
admin.topics().setInactiveTopicPolicies(topic3, inactiveTopicPolicies);
for (int i = 0; i < 50; i++) {
if (admin.topics().getInactiveTopicPolicies(topic) != null) {
break;
}
Thread.sleep(100);
}
InactiveTopicPolicies policies = ((PersistentTopic) (pulsar.getBrokerService().getTopic(topic, false).get().get())).inactiveTopicPolicies;
Assert.assertTrue(policies.isDeleteWhileInactive());
assertEquals(policies.getInactiveTopicDeleteMode(), delete_when_no_subscriptions);
assertEquals(policies.getMaxInactiveDurationSeconds(), 1);
assertEquals(policies, admin.topics().getInactiveTopicPolicies(topic));
admin.topics().removeInactiveTopicPolicies(topic);
for (int i = 0; i < 50; i++) {
if (admin.topics().getInactiveTopicPolicies(topic) == null) {
break;
}
Thread.sleep(100);
}
assertEquals(((PersistentTopic) (pulsar.getBrokerService().getTopic(topic, false).get().get())).inactiveTopicPolicies, defaultPolicy);
policies = ((PersistentTopic) (pulsar.getBrokerService().getTopic(topic2, false).get().get())).inactiveTopicPolicies;
Assert.assertTrue(policies.isDeleteWhileInactive());
assertEquals(policies.getInactiveTopicDeleteMode(), delete_when_subscriptions_caught_up);
assertEquals(policies.getMaxInactiveDurationSeconds(), 1);
assertEquals(policies, admin.topics().getInactiveTopicPolicies(topic2));
inactiveTopicPolicies.setMaxInactiveDurationSeconds(999);
admin.namespaces().setInactiveTopicPolicies(namespace, inactiveTopicPolicies);
Thread.sleep(1000);
admin.topics().removeInactiveTopicPolicies(topic2);
for (int i = 0; i < 50; i++) {
if (admin.topics().getInactiveTopicPolicies(topic2) == null) {
break;
}
Thread.sleep(100);
}
InactiveTopicPolicies nsPolicies = ((PersistentTopic) (pulsar.getBrokerService().getTopic(topic2, false).get().get())).inactiveTopicPolicies;
assertEquals(nsPolicies.getMaxInactiveDurationSeconds(), 999);
super.internalCleanup();
}",async wait,0
185,struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testProcessAction_ok.2,"@Test
public void testProcessAction_ok() {
final Mock mockResponse = mock(ActionResponse.class);
PortletMode mode = PortletMode.VIEW;
Map<String, String> initParams = new HashMap<String, String>();
initParams.put(""viewNamespace"", ""/view"");
Map<String, String[]> requestParams = new HashMap<String, String[]>();
requestParams.put(ACTION_PARAM, new String[] { ""/view/testAction"" });
requestParams.put(MODE_PARAM, new String[] { mode.toString() });
initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE,
""true"");
initPortletConfig(initParams, new HashMap<String, Object>());
initRequest(requestParams, new HashMap<String, Object>(),
new HashMap<String, Object>(), PortletMode.VIEW,
WindowState.NORMAL, true, null);
setupActionFactory(""/view"", ""testAction"", ""success"",
EasyMock.createNiceMock(ValueStack.class));
try {
dispatcher
.setActionProxyFactory((ActionProxyFactory) mockActionFactory
.proxy());
dispatcher.init((PortletConfig) mockConfig.proxy());
dispatcher.processAction((ActionRequest) mockRequest.proxy(),
(ActionResponse) mockResponse.proxy());
} catch (Exception e) {
e.printStackTrace();
fail(""Error occured"");
}
}",test order dependency,4
186,struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testRender_ok,"@Test
public void testRender_ok() {
final Mock mockResponse = mock(RenderResponse.class);
mockResponse.stubs().method(ANYTHING);
PortletMode mode = PortletMode.VIEW;
Map<String, String[]> requestParams = new HashMap<String, String[]>();
requestParams.put(ACTION_PARAM, new String[]{""/view/testAction""});
requestParams.put(EVENT_ACTION, new String[]{""true""});
requestParams.put(MODE_PARAM, new String[]{mode.toString()});
Map<String, Object> sessionMap = new HashMap<String, Object>();
Map<String, String> initParams = new HashMap<String, String>();
initParams.put(""viewNamespace"", ""/view"");
initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true"");
initPortletConfig(initParams, new HashMap<String, Object>());
initRequest(requestParams, new HashMap<String, Object>(), sessionMap, PortletMode.VIEW, WindowState.NORMAL, false, null);
setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));
mockInvocation.expects(once()).method(""getStack"").will(
returnValue(null));
try {
dispatcher
.setActionProxyFactory((ActionProxyFactory) mockActionFactory
.proxy());
dispatcher.init((PortletConfig) mockConfig.proxy());
dispatcher.render((RenderRequest) mockRequest.proxy(),
(RenderResponse) mockResponse.proxy());
} catch (Exception e) {
e.printStackTrace();
fail(""Error occured"");
}
}",test order dependency,4
187,pulsar,ManagedLedgerTest.testMaximumRolloverTime,"@Test
public void testMaximumRolloverTime() throws Exception {
ManagedLedgerConfig conf = new ManagedLedgerConfig();
conf.setMaxEntriesPerLedger(5);
conf.setMinimumRolloverTime(1, SECONDS);
conf.setMaximumRolloverTime(1, SECONDS);
ManagedLedgerImpl ledger = ((ManagedLedgerImpl) (factory.open(""my_test_maxtime_ledger"", conf)));
ledger.openCursor(""c1"");
ledger.addEntry(""data"".getBytes());
ledger.addEntry(""data"".getBytes());
assertEquals(ledger.getLedgersInfoAsList().size(), 1);
Thread.sleep(2000);
ledger.addEntry(""data"".getBytes());
ledger.addEntry(""data"".getBytes());
assertEquals(ledger.getLedgersInfoAsList().size(), 2);
}",async wait,0
188,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupBindingUsingNestedContext,"@Test
public void testLookupBindingUsingNestedContext() throws Exception {
final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean"");
final Object value = new Object();
bindObject(bindingName, value);
Object context = store.lookup(new CompositeName(""foo""));
assertNotNull(context);
assertTrue(context instanceof Context);
Object obj = Context.class.cast(context).lookup(new CompositeName(""bar/baz/TestBean""));
assertNotNull(obj);
assertEquals(value, obj);
context = Context.class.cast(context).lookup(new CompositeName(""bar""));
obj = Context.class.cast(context).lookup(new CompositeName(""baz/TestBean""));
assertNotNull(obj);
assertEquals(value, obj);
context = Context.class.cast(context).lookup(new CompositeName(""baz""));
obj = Context.class.cast(context).lookup(new CompositeName(""TestBean""));
assertNotNull(obj);
assertEquals(value, obj);
}",test order dependency,4
189,jaeger-client-java,testUpdatePerOperationSamplerUpdatesExistingPerOperationSampler,"@Test
public void testUpdatePerOperationSamplerUpdatesExistingPerOperationSampler() throws Exception {
PerOperationSampler perOperationSampler = mock(PerOperationSampler.class);
OperationSamplingParameters parameters = mock(OperationSamplingParameters.class);
when(samplingManager.getSamplingStrategy(SERVICE_NAME)).thenReturn(
new SamplingStrategyResponse(null, null, parameters));
undertest = new RemoteControlledSampler(SERVICE_NAME, samplingManager, perOperationSampler, metrics);
undertest.updateSampler();
Thread.sleep(20);
verify(perOperationSampler, times(2)).update(parameters);
}",concurrency,1
190,dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testChangeServiceNotExport,"@Test
public void testChangeServiceNotExport() throws RemotingException {
String result = change.telnet(mockChannel, ""demo"");
assertEquals(""No such service demo"", result);
}",test order dependency,4
191,pulsar,DiscoveryServiceTest.testBrokerDiscoveryRoundRobin,"@Test
public void testBrokerDiscoveryRoundRobin() throws Exception {
addBrokerToZk(5);
String prevUrl = null;
for (int i = 0; i < 10; i++) {
String current = service.getDiscoveryProvider().nextBroker().getPulsarServiceUrl();
assertNotEquals(prevUrl, current);
prevUrl = current;
}
}",async wait,0
192,aws-sdk-java-v2,S3TransferManagerListenerTest.upload_success_shouldInvokeListener,"@Test
public void upload_success_shouldInvokeListener() throws Exception {
TransferListener listener = mock(TransferListener.class);
Path path = newTempFile();
Files.write(path, randomBytes(contentLength));
UploadRequest uploadRequest = UploadRequest.builder().putObjectRequest(( r) -> r.bucket(""bucket"").key(""key"")).source(path).overrideConfiguration(( b) -> b.addListener(listener)).build();
Upload upload = tm.upload(uploadRequest);
upload.completionFuture().join();
ArgumentCaptor<TransferListener.Context.TransferInitiated> captor1 = ArgumentCaptor.forClass(TransferInitiated.class);
verify(listener, times(1)).transferInitiated(captor1.capture());
TransferListener.Context.TransferInitiated ctx1 = captor1.getValue();
assertThat(ctx1.request()).isSameAs(uploadRequest);
assertThat(ctx1.progressSnapshot().transferSizeInBytes()).hasValue(contentLength);
assertThat(ctx1.progressSnapshot().bytesTransferred()).isZero();
ArgumentCaptor<TransferListener.Context.BytesTransferred> captor2 = ArgumentCaptor.forClass(BytesTransferred.class);
verify(listener, times(1)).bytesTransferred(captor2.capture());
TransferListener.Context.BytesTransferred ctx2 = captor2.getValue();
assertThat(ctx2.request()).isSameAs(uploadRequest);
assertThat(ctx2.progressSnapshot().transferSizeInBytes()).hasValue(contentLength);
assertThat(ctx2.progressSnapshot().bytesTransferred()).isPositive();
ArgumentCaptor<TransferListener.Context.TransferComplete> captor3 = ArgumentCaptor.forClass(TransferComplete.class);
verify(listener, times(1)).transferComplete(captor3.capture());
TransferListener.Context.TransferComplete ctx3 = captor3.getValue();
assertThat(ctx3.request()).isSameAs(uploadRequest);
assertThat(ctx3.progressSnapshot().transferSizeInBytes()).hasValue(contentLength);
assertThat(ctx3.progressSnapshot().bytesTransferred()).isEqualTo(contentLength);
assertThat(ctx3.completedTransfer()).isSameAs(upload.completionFuture().get());
verifyNoMoreInteractions(listener);
}",async wait,0
193,activemq,JmsTempDestinationTest.testPublishFailsForClosedConnection,"@Test
public void testPublishFailsForClosedConnection() throws JMSException {
Connection tempConnection = factory.createConnection();
Session tempSession = tempConnection.createSession(false, AUTO_ACKNOWLEDGE);
TemporaryQueue queue = tempSession.createTemporaryQueue();
Session session = connection.createSession(false, AUTO_ACKNOWLEDGE);
connection.start();
MessageProducer producer = session.createProducer(queue);
producer.setDeliveryMode(NON_PERSISTENT);
TextMessage message = session.createTextMessage(""First"");
producer.send(message);
tempConnection.close();
try {
message = session.createTextMessage(""Hello"");
producer.send(message);
fail(""Send should fail since temp destination should not exist anymore."");
} catch (JMSException e) {
assertTrue(""failed to throw an exception"", true);
}
}",async wait,0
194,netty,testAutomaticStartStop,"@Test
public void testAutomaticStartStop() throws Exception {
final TestRunnable task = new TestRunnable(500);
e.execute(task);
Thread thread = e.thread;
assertThat(thread, is(not(nullValue())));
assertThat(thread.isAlive(), is(true));
Thread.sleep(1500);
assertThat(thread.isAlive(), is(false));
assertThat(task.ran.get(), is(true));
task.ran.set(false);
e.execute(task);
assertThat(e.thread, not(sameInstance(thread)));
thread = e.thread;
Thread.sleep(1500);
assertThat(thread.isAlive(), is(false));
assertThat(task.ran.get(), is(true));
}",async wait,0
195,Wikidata-Toolkit,20de6f7f12319f54eb962ff6e8357b3f5695d54d.createDirectoryManagerIoException,"@Test
public void createDirectoryManagerIoException() throws IOException {
DirectoryManagerFactory.createDirectoryManager(
""/nonexisting-directory/123456789/hopefully"", true);
}",test order dependency,4
196,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBind,"@Test
public void testBind() throws Exception {
Name name = new CompositeName(""test"");
final Object value = new Object();
namingContext.bind(name, value);
assertEquals(value, namingStore.lookup(name));
name = new CompositeName(""securitytest"");
testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", value);
assertEquals(value, namingStore.lookup(name));
}",test order dependency,4
197,pulsar,PrometheusMetricsTest.testPerTopicStats,"@Test
public void testPerTopicStats() throws Exception {
String randSeed = randomName(16);
System.out.println(""The randSeed of testPerTopicStats() is: "" + randSeed);
Producer<byte[]> p1 = pulsarClient.newProducer().topic(""persistent://my-property/use/"" + randSeed + ""/my-topic1"").create();
Producer<byte[]> p2 = pulsarClient.newProducer().topic(""persistent://my-property/use/"" + randSeed + ""/my-topic2"").create();
for (int i = 0; i < 10; i++) {
String message = ""my-message-"" + i;
p1.send(message.getBytes());
p2.send(message.getBytes());
}
ByteArrayOutputStream statsOut = new ByteArrayOutputStream();
PrometheusMetricsGenerator.generate(pulsar, true, false, statsOut);
String metricsStr = new String(statsOut.toByteArray());
Multimap<String, Metric> metrics = parseMetrics(metricsStr);
metrics.entries().forEach(e -> {
System.out.println(e.getKey() + "": "" + e.getValue());
});
List<Metric> cm = (List<Metric>) metrics.get(""pulsar_storage_write_latency_le_1"");
List<Metric> matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
int positionOfTopic1;
int positionOfTopic2;
if(cm.get(0).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) {
positionOfTopic1 = 0;
positionOfTopic2 = 1;
} else {
positionOfTopic2 = 0;
positionOfTopic1 = 1;
}
matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
if(matchingMetrics.size() > 2){
System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). First check. Debug entries: "");
matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
}
assertEquals(matchingMetrics.size(), 2);
assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2"");
assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed);
assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1"");
assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);
cm = (List<Metric>) metrics.get(""pulsar_producers_count"");
if(cm.get(1).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) {
positionOfTopic1 = 1;
positionOfTopic2 = 2;
} else {
positionOfTopic2 = 1;
positionOfTopic1 = 2;
}
matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
if(matchingMetrics.size() > 2){
System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Second check. Debug entries: "");
matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
}
assertEquals(matchingMetrics.size(), 2);
assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2"");
assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed);
assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1"");
assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);
cm = (List<Metric>) metrics.get(""topic_load_times_count"");
if(cm.size() > 1){
System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Third check. Debug entries: "");
cm.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
}
assertEquals(cm.size(), 1);
assertEquals(cm.get(0).tags.get(""cluster""), ""test"");
cm = (List<Metric>) metrics.get(""pulsar_in_bytes_total"");
if(cm.get(0).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) {
positionOfTopic1 = 0;
positionOfTopic2 = 1;
} else {
positionOfTopic2 = 0;
positionOfTopic1 = 1;
}
matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
if(matchingMetrics.size() > 2){
System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fourth check. Debug entries: "");
matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
}
assertEquals(matchingMetrics.size(), 2);
assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2"");
assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed);
assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1"");
assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);
cm = (List<Metric>) metrics.get(""pulsar_in_messages_total"");
if(cm.get(0).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) {
positionOfTopic1 = 0;
positionOfTopic2 = 1;
} else {
positionOfTopic2 = 0;
positionOfTopic1 = 1;
}
matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
if(matchingMetrics.size() > 2){
System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fifth check. Debug entries: "");
matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
}
assertEquals(matchingMetrics.size(), 2);
assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2"");
assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed);
assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1"");
assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);
p1.close();
p2.close();
}",concurrency,1
198,hadoop,TestPathData.testCwdContents,"@Test
public void testCwdContents() throws Exception {
dirString = Path.CUR_DIR;
item = new PathData(dirString, conf);
PathData[] items = item.getDirectoryContents();
assertEquals(sortedString(""d1"", ""d2""), sortedString(items));
}",test order dependency,4
199,shardingsphere-elasticjob,b022898ef1b8c984e17efb2a422ee45f6b13e46e.assertGetCurrentShardingTotalCountIfNull,"@Test
public void assertGetCurrentShardingTotalCountIfNull() {
assertThat(JobRegistry.getInstance().getCurrentShardingTotalCount(""exist_job_instance""), is(0));
}",test order dependency,4
200,ambari,TestActionQueue.testConcurrentOperations,"@Test
public void testConcurrentOperations() throws InterruptedException {
ActionQueue aq = new ActionQueue();
String[] hosts = new String[]{ ""h0"", ""h1"", ""h2"", ""h3"", ""h4"", ""h5"", ""h6"", ""h7"", ""h8"", ""h9"" };
ActionQueueOperation[] enqueOperators = new ActionQueueOperation[threadCount];
ActionQueueOperation[] dequeOperators = new ActionQueueOperation[threadCount];
ActionQueueOperation[] dequeAllOperators = new ActionQueueOperation[threadCount];
for (int i = 0; i < threadCount; i++) {
dequeOperators[i] = new ActionQueueOperation(aq, hosts, ActionQueueOperation.OpType.DEQUEUE);
Thread t = new Thread(dequeOperators[i]);
t.start();
}
for (int i = 0; i < threadCount; i++) {
enqueOperators[i] = new ActionQueueOperation(aq, hosts, ActionQueueOperation.OpType.ENQUEUE);
Thread t = new Thread(enqueOperators[i]);
t.start();
}
for (int i = 0; i < threadCount; i++) {
dequeAllOperators[i] = new ActionQueueOperation(aq, hosts, ActionQueueOperation.OpType.DEQUEUEALL);
Thread t = new Thread(dequeAllOperators[i]);
t.start();
}
Thread.sleep(100);
for (int i = 0; i < threadCount; i++) {
enqueOperators[i].stop();
}
boolean allDequeued = false;
while (!allDequeued) {
Thread.sleep(10);
allDequeued = true;
for (String host : hosts) {
if (aq.size(host) > 0) {
allDequeued = false;
break;
}
}
}
for (int i = 0; i < threadCount; i++) {
dequeOperators[i].stop();
dequeAllOperators[i].stop();
}
for (int h = 0; h < hosts.length; h++) {
long opsEnqueued = 0;
long opsDequeued = 0;
for (int i = 0; i < threadCount; i++) {
opsEnqueued += enqueOperators[i].getOpCounts()[h];
opsDequeued += dequeOperators[i].getOpCounts()[h];
opsDequeued += dequeAllOperators[i].getOpCounts()[h];
}
assertTrue(opsEnqueued != 0);
assertEquals(0, aq.size(hosts[h]));
LOG.info(((((""Host: "" + hosts[h]) + "", opsEnqueued: "") + opsEnqueued) + "", opsDequeued: "") + opsDequeued);
assertEquals(opsDequeued, opsEnqueued);
}
}",async wait,0
201,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupBinding.2.,"@Test
public void testLookupBinding() throws Exception {
final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"");
final Object value = new Object();
bindObject(bindingName, value);
final Object obj = store.lookup(new CompositeName(""foo/bar""));
assertNotNull(obj);
assertEquals(value, obj);
}",test order dependency,4
202,cdap,ProvisioningServiceTest.testCancelDeprovision,"@Test
public void testCancelDeprovision() throws Exception {
ProvisionerInfo provisionerInfo = new MockProvisioner.PropertyBuilder().waitDelete(1, TimeUnit.MINUTES).build();
TaskFields taskFields = testProvision(ProvisioningOp.Status.CREATED, provisionerInfo);
Runnable task = Transactionals.execute(transactional, dsContext -> {
return provisioningService.deprovision(taskFields.programRunId, dsContext);
});
task.run();
Assert.assertTrue(provisioningService.cancelDeprovisionTask(taskFields.programRunId).isPresent());
ProvisioningTaskKey taskKey = new ProvisioningTaskKey(taskFields.programRunId, ProvisioningOp.Type.DEPROVISION);
waitForExpectedProvisioningState(taskKey, ProvisioningOp.Status.CANCELLED);
}",test order dependency,4
203,cassandra,testTimeWindows,"@Test
public void testTimeWindows()
{
Long tstamp1 = 1451001601000L;
Long tstamp2 = 1451088001000L;
Long lowHour = 1451001600000L;
assertTrue(getWindowBoundsInMillis(TimeUnit.HOURS, 1, tstamp1).left.compareTo(lowHour) == 0);
assertTrue(getWindowBoundsInMillis(TimeUnit.MINUTES, 1, tstamp1).left.compareTo(lowHour) == 0);
assertTrue(getWindowBoundsInMillis(TimeUnit.DAYS, 1, tstamp1).left.compareTo(lowHour) == 0 );
assertTrue(getWindowBoundsInMillis(TimeUnit.DAYS, 2, tstamp2).left.compareTo(lowHour) == 0);
return;
}",time,2
204,marine-api,af0003847db9ba822f67d4f1dceb8de3fe63250a.testCreateWithTwo,"@Test
public void testCreateWithTwo() {
AISMessage msg = amf.create(split1, split2);
assertTrue(msg instanceof AISMessage05);
assertEquals(5, msg.getMessageType());
}",test order dependency,4
205,httpcomponents,TestConnPool.testMaxLimits,"@Test
public void testMaxLimits() throws Exception {
LocalConnFactory connFactory = Mockito.mock(LocalConnFactory.class);
HttpConnection conn1 = Mockito.mock(HttpConnection.class);
Mockito.when(connFactory.create(Mockito.eq(""somehost""))).thenReturn(conn1);
HttpConnection conn2 = Mockito.mock(HttpConnection.class);
Mockito.when(connFactory.create(Mockito.eq(""otherhost""))).thenReturn(conn2);
LocalConnPool pool = new LocalConnPool(connFactory, 2, 10);
pool.setMaxPerRoute(""somehost"", 2);
pool.setMaxPerRoute(""otherhost"", 1);
pool.setMaxTotal(3);
Future<LocalPoolEntry> future1 = pool.lease(""somehost"", null);
GetPoolEntryThread t1 = new GetPoolEntryThread(future1);
t1.start();
Future<LocalPoolEntry> future2 = pool.lease(""somehost"", null);
GetPoolEntryThread t2 = new GetPoolEntryThread(future2);
t2.start();
Future<LocalPoolEntry> future3 = pool.lease(""otherhost"", null);
GetPoolEntryThread t3 = new GetPoolEntryThread(future3);
t3.start();
t1.join(GRACE_PERIOD);
Assert.assertTrue(future1.isDone());
LocalPoolEntry entry1 = t1.getEntry();
Assert.assertNotNull(entry1);
t2.join(GRACE_PERIOD);
Assert.assertTrue(future2.isDone());
LocalPoolEntry entry2 = t2.getEntry();
Assert.assertNotNull(entry2);
t3.join(GRACE_PERIOD);
Assert.assertTrue(future3.isDone());
LocalPoolEntry entry3 = t3.getEntry();
Assert.assertNotNull(entry3);
pool.release(entry1, true);
pool.release(entry2, true);
pool.release(entry3, true);
PoolStats totals = pool.getTotalStats();
Assert.assertEquals(3, totals.getAvailable());
Assert.assertEquals(0, totals.getLeased());
Future<LocalPoolEntry> future4 = pool.lease(""somehost"", null);
GetPoolEntryThread t4 = new GetPoolEntryThread(future4);
t4.start();
Future<LocalPoolEntry> future5 = pool.lease(""somehost"", null);
GetPoolEntryThread t5 = new GetPoolEntryThread(future5);
t5.start();
Future<LocalPoolEntry> future6 = pool.lease(""otherhost"", null);
GetPoolEntryThread t6 = new GetPoolEntryThread(future6);
t6.start();
t4.join(GRACE_PERIOD);
Assert.assertTrue(future4.isDone());
LocalPoolEntry entry4 = t4.getEntry();
Assert.assertNotNull(entry4);
t5.join(GRACE_PERIOD);
Assert.assertTrue(future5.isDone());
LocalPoolEntry entry5 = t5.getEntry();
Assert.assertNotNull(entry5);
t6.join(GRACE_PERIOD);
Assert.assertTrue(future6.isDone());
LocalPoolEntry entry6 = t6.getEntry();
Assert.assertNotNull(entry6);
Future<LocalPoolEntry> future7 = pool.lease(""somehost"", null);
GetPoolEntryThread t7 = new GetPoolEntryThread(future7);
t7.start();
Future<LocalPoolEntry> future8 = pool.lease(""somehost"", null);
GetPoolEntryThread t8 = new GetPoolEntryThread(future8);
t8.start();
Future<LocalPoolEntry> future9 = pool.lease(""otherhost"", null);
GetPoolEntryThread t9 = new GetPoolEntryThread(future9);
t9.start();
Assert.assertFalse(t7.isDone());
Assert.assertFalse(t8.isDone());
Assert.assertFalse(t9.isDone());
Mockito.verify(connFactory, Mockito.times(3)).create(Mockito.any(String.class));
pool.release(entry4, true);
pool.release(entry5, false);
pool.release(entry6, true);
t7.join();
Assert.assertTrue(future7.isDone());
t8.join();
Assert.assertTrue(future8.isDone());
t9.join();
Assert.assertTrue(future9.isDone());
Mockito.verify(connFactory, Mockito.times(4)).create(Mockito.any(String.class));
}",concurrency,1
206,kafka,testGracefulClose,"@Test
public void testGracefulClose() throws Exception {
int maxReceiveCountAfterClose = 0;
for (int i = 6; i <= 100 && maxReceiveCountAfterClose < 5; i++) {
int receiveCount = 0;
KafkaChannel channel = createConnectionWithPendingReceives(i);
selector.poll(1000);
assertEquals(1, selector.completedReceives().size());
server.closeConnections();
while (selector.disconnected().isEmpty()) {
selector.poll(1);
receiveCount += selector.completedReceives().size();
assertTrue(""Too many completed receives in one poll"", selector.completedReceives().size() <= 1);
}
assertEquals(channel.id(), selector.disconnected().keySet().iterator().next());
maxReceiveCountAfterClose = Math.max(maxReceiveCountAfterClose, receiveCount);
}
assertTrue(""Too few receives after close: "" + maxReceiveCountAfterClose, maxReceiveCountAfterClose >= 5);
}",async wait,0
207,pulsar,testAsyncFunction,"@Test
public void testAsyncFunction() throws Exception {
InstanceConfig instanceConfig = new InstanceConfig();
Function<String, CompletableFuture<String>> function = (input, context) -> {
log.info(""input string: {}"", input);
CompletableFuture<String> result  = new CompletableFuture<>();
Executors.newCachedThreadPool().submit(() -> {
try {
Thread.sleep(500);
result.complete(String.format(""%s-lambda"", input));
} catch (Exception e) {
result.completeExceptionally(e);
}
});
return result;
};
JavaInstance instance = new JavaInstance(
mock(ContextImpl.class),
function,
instanceConfig);
String testString = ""ABC123"";
CompletableFuture<JavaExecutionResult> result = instance.handleMessage(mock(Record.class), testString);
assertNotNull(result.get().getResult());
assertEquals(new String(testString + ""-lambda""), result.get().getResult());
instance.close();
}",concurrency,1
208,vespa,testNodeMetricsDb,"@Test
public void testNodeMetricsDb() {
ManualClock clock = new ManualClock();
NodeMetricsDb db = new NodeMetricsDb();
List<NodeMetrics.MetricValue> values = new ArrayList<>();
for (int i = 0; i < 40; i++) {
values.add(new NodeMetrics.MetricValue(""host0"", ""cpu.util"", clock.instant().getEpochSecond(), 0.9f));
clock.advance(Duration.ofHours(1));
}
db.add(values);
assertEquals(29, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.cpu,    List.of(""host0"")).measurementCount());
assertEquals( 0, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.memory, List.of(""host0"")).measurementCount());
db.gc(clock);
assertEquals(23, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.cpu,    List.of(""host0"")).measurementCount());
assertEquals( 0, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.memory, List.of(""host0"")).measurementCount());
}",time,2
209,hadoop,TestHftpFileSystem.testHftpCustomDefaultPorts,"@Test
public void testHftpCustomDefaultPorts() throws IOException {
resetFileSystem();
Configuration conf = new Configuration();
conf.setInt(""dfs.http.port"", 123);
conf.setInt(""dfs.https.port"", 456);
URI uri = URI.create();
HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
assertEquals(123, fs.getDefaultPort());
assertEquals(456, fs.getDefaultSecurePort());
assertEquals(uri, fs.getUri());
assertEquals(""127.0.0.1:456"", fs.getCanonicalServiceName());
}",test order dependency,4
210,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindReferenceable,"@Test
public void testBindReferenceable() throws Exception {
Name name = new CompositeName(""test"");
final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
namingContext.bind(name, referenceable);
Object result = namingContext.lookup(name);
assertEquals(referenceable.addr, result);
name = new CompositeName(""securitytest"");
testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", referenceable);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""securitytest"");
assertEquals(referenceable.addr, result);
}",test order dependency,4
211,pulsar,testLedgerReachMaximumRolloverTime,"@Test
public void testLedgerReachMaximumRolloverTime() throws Exception {
ManagedLedgerConfig config = new ManagedLedgerConfig();
config.setMinimumRolloverTime(1, TimeUnit.MILLISECONDS);
config.setMaximumRolloverTime(1, TimeUnit.SECONDS);
ManagedLedger ml = factory.open(""ledger-reach-maximum-rollover-time"", config);
long firstLedgerId = ml.addEntry(""test"".getBytes()).getLedgerId();
Awaitility.await()
.atMost(1100, TimeUnit.MILLISECONDS)
.pollInterval(100, TimeUnit.MILLISECONDS)
.until(() -> firstLedgerId != ml.addEntry(""test"".getBytes()).getLedgerId());
}",async wait,0
212,okhttp,HttpOverHttp2Test.recoverFromCancelReusesConnection,"@Test
public void recoverFromCancelReusesConnection() throws Exception {
CountDownLatch responseDequeuedLatch = new CountDownLatch(1);
CountDownLatch requestCanceledLatch = new CountDownLatch(1);
QueueDispatcher dispatcher = new QueueDispatcher() {
@Override
public MockResponse dispatch(RecordedRequest request) throws InterruptedException {
MockResponse response = super.dispatch(request);
responseDequeuedLatch.countDown();
requestCanceledLatch.await();
return response;
}
};
server.setDispatcher(dispatcher);
dispatcher.enqueueResponse(new MockResponse().setBodyDelay(10, TimeUnit.SECONDS).setBody(""abc""));
dispatcher.enqueueResponse(new MockResponse().setBody(""def""));
client = client.newBuilder().dns(new DoubleInetAddressDns()).build();
callAndCancel(0, responseDequeuedLatch, requestCanceledLatch);
Call call = client.newCall(new Request.Builder().url(server.url(""/"")).build());
Response response = call.execute();
assertThat(response.body().string()).isEqualTo(""def"");
assertThat(server.takeRequest().getSequenceNumber()).isEqualTo(1);
}",async wait,0
213,maven,CheckoutMojoTest.testSkipCheckoutWhenCheckoutDirectoryExistsAndSkip,"@Test
public void testSkipCheckoutWhenCheckoutDirectoryExistsAndSkip() throws Exception {
checkoutDir.mkdirs();
CheckoutMojo mojo = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWhenCheckoutDirectoryExistsAndSkip.xml""))));
mojo.setCheckoutDirectory(checkoutDir);
mojo.execute();
assertEquals(0, checkoutDir.listFiles().length);
}",test order dependency,4
214,cdap,MetadataSubscriberServiceTest.testSubscriber,"@Test
public void testSubscriber() throws InterruptedException, ExecutionException, TimeoutException {
LineageWriter lineageWriter = getInjector().getInstance(MessagingLineageWriter.class);
ProgramRunId run1 = service1.run(RunIds.generate());
lineageWriter.addAccess(run1, dataset1, AccessType.READ);
lineageWriter.addAccess(run1, dataset2, AccessType.WRITE);
LineageStoreReader lineageReader = getInjector().getInstance(LineageStoreReader.class);
ProgramRunId run1 = service1.run(RunIds.generate());
Set<NamespacedEntityId> entities = lineageReader.getEntitiesForRun(run1);
Assert.assertTrue(entities.isEmpty());
LineageWriter lineageWriter = getInjector().getInstance(MessagingLineageWriter.class);
lineageWriter.addAccess(run1, dataset1, AccessType.READ);
lineageWriter.addAccess(run1, dataset2, AccessType.WRITE);
FieldLineageWriter fieldLineageWriter = getInjector().getInstance(MessagingLineageWriter.class);
ProgramRunId spark1Run1 = spark1.run(RunIds.generate(100));
ReadOperation read = new ReadOperation(""read"", ""some read"", EndPoint.of(""ns"", ""endpoint1""), ""offset"", ""body"");
TransformOperation parse = new TransformOperation(""parse"", ""parse body"",
Collections.singletonList(InputField.of(""read"", ""body"")),
""name"", ""address"");
WriteOperation write = new WriteOperation(""write"", ""write data"", EndPoint.of(""ns"", ""endpoint2""),
Arrays.asList(InputField.of(""read"", ""offset""),
InputField.of(""parse"", ""name""),
InputField.of(""parse"", ""address"")));
List<Operation> operations = new ArrayList<>();
operations.add(read);
operations.add(write);
operations.add(parse);
FieldLineageInfo info1 = new FieldLineageInfo(operations);
fieldLineageWriter.write(spark1Run1, info1);
ProgramRunId spark1Run2 = spark1.run(RunIds.generate(200));
fieldLineageWriter.write(spark1Run2, info1);
List<Operation> operations2 = new ArrayList<>();
operations2.add(read);
operations2.add(parse);
TransformOperation normalize = new TransformOperation(""normalize"", ""normalize address"",
Collections.singletonList(InputField.of(""parse"", ""address"")),
""address"");
operations2.add(normalize);
WriteOperation anotherWrite = new WriteOperation(""anotherwrite"", ""write data"", EndPoint.of(""ns"", ""endpoint2""),
Arrays.asList(InputField.of(""read"", ""offset""),
InputField.of(""parse"", ""name""),
InputField.of(""normalize"", ""address"")));
operations2.add(anotherWrite);
FieldLineageInfo info2 = new FieldLineageInfo(operations2);
ProgramRunId spark1Run3 = spark1.run(RunIds.generate(300));
fieldLineageWriter.write(spark1Run3, info2);
UsageWriter usageWriter = getInjector().getInstance(MessagingUsageWriter.class);
usageWriter.register(spark1, dataset1);
usageWriter.registerAll(Collections.singleton(spark1), dataset3);
Set<NamespacedEntityId> expectedLineage = new HashSet<>(Arrays.asList(run1.getParent(), dataset1, dataset2));
Tasks.waitFor(true, () -> expectedLineage.equals(lineageReader.getEntitiesForRun(run1)),
10, TimeUnit.SECONDS, 100, TimeUnit.MILLISECONDS);
Assert.assertTrue(lineageReader.getRelations(spark1, 0L, Long.MAX_VALUE, x -> true).isEmpty());
FieldLineageReader fieldLineageReader = getInjector().getInstance(FieldLineageReader.class);
Set<Operation> expectedOperations = new HashSet<>();
expectedOperations.add(read);
expectedOperations.add(anotherWrite);
List<ProgramRunOperations> expected = new ArrayList<>();
expected.add(new ProgramRunOperations(Collections.singleton(spark1Run3), expectedOperations));
expectedOperations = new HashSet<>();
expectedOperations.add(read);
expectedOperations.add(write);
expected.add(new ProgramRunOperations(new HashSet<>(Arrays.asList(spark1Run1, spark1Run2)),
expectedOperations));
EndPointField endPointField = new EndPointField(EndPoint.of(""ns"", ""endpoint2""), ""offset"");
Tasks.waitFor(expected, () -> fieldLineageReader.getIncomingOperations(endPointField, 1L, Long.MAX_VALUE - 1),
10, TimeUnit.SECONDS, 100, TimeUnit.MILLISECONDS);
Set<EntityId> expectedUsage = new HashSet<>(Arrays.asList(dataset1, dataset3));
UsageRegistry usageRegistry = getInjector().getInstance(UsageRegistry.class);
Tasks.waitFor(true, () -> expectedUsage.equals(usageRegistry.getDatasets(spark1)),
10, TimeUnit.SECONDS, 100, TimeUnit.MILLISECONDS);
}",async wait,0
215,neo4j,shouldPickANewServerToWriteToOnLeaderSwitch,"@Test
public void shouldPickANewServerToWriteToOnLeaderSwitch() throws Throwable
{
cluster = clusterRule.withNumberOfEdgeMembers( 0 ).startCluster();
CoreClusterMember leader = cluster.awaitLeader();
CountDownLatch startTheLeaderSwitching = new CountDownLatch( 1 );
Thread thread = new Thread( () ->
{
try
{
startTheLeaderSwitching.await();
CoreClusterMember theLeader = cluster.awaitLeader();
switchLeader( theLeader );
}
catch ( TimeoutException | InterruptedException e )
{
}
} );
thread.start();
Config config = Config.build().withLogging( new JULogging( Level.OFF ) ).toConfig();
try ( Driver driver = GraphDatabase
.driver( leader.routingURI(), AuthTokens.basic( ""neo4j"", ""neo4j"" ), config ) )
{
boolean success = false;
Set<BoltServerAddress> seenAddresses = new HashSet<>();
long deadline = System.currentTimeMillis() + (30 * 1000);
while ( !success )
{
if ( System.currentTimeMillis() > deadline )
{
fail( ""Failed to write to the new leader in time"" );
}
try ( Session session = driver.session( AccessMode.WRITE ) )
{
startTheLeaderSwitching.countDown();
BoltServerAddress boltServerAddress = ((RoutingNetworkSession) session).address();
seenAddresses.add( boltServerAddress );
session.run( ""CREATE (p:Person)"" );
success = seenAddresses.size() >= 2;
}
catch ( Exception e )
{
Thread.sleep( 100 );
}
}
}
finally
{
thread.join();
}
}",concurrency,1
216,dpnt-coverage,CoverageDatapointAcceptanceTest.create_repo_and_uploads_commits,"@Test
public void create_repo_and_uploads_commits() throws Exception {
String challengeId = ""TCH"";
String participantId = generateId();
String s3destination = String.format(""%s/%s/file.srcs"", challengeId, participantId);
TestSrcsFile srcsForTestChallenge = new TestSrcsFile(""HmmmLang_R1Cov33_R2Cov44.srcs"");
S3Event s3Event = localS3Bucket.putObject(srcsForTestChallenge.asFile(), s3destination);
coverageUploadHandler.handleRequest(convertToMap(wrapAsSNSEvent(s3Event)),NO_CONTEXT);
waitForQueueToReceiveEvents();
assertThat(languageDetectedEvents.size(), equalTo(1));
System.out.println(""Received language detected events: ""+languageDetectedEvents);
ProgrammingLanguageDetectedEvent languageEvent = languageDetectedEvents.get(0);
assertThat(languageEvent.getParticipant(), equalTo(participantId));
assertThat(languageEvent.getChallengeId(), equalTo(challengeId));
assertThat(languageEvent.getProgrammingLanguage(), equalTo(""HmmmLang""));
assertThat(coverageComputedEvents.size(), equalTo(2));
System.out.println(""Received coverage events: ""+coverageComputedEvents);
coverageComputedEvents.sort(Comparator.comparing(CoverageComputedEvent::getRoundId));
CoverageComputedEvent coverageRound1 = coverageComputedEvents.get(0);
assertThat(coverageRound1.getParticipant(), equalTo(participantId));
assertThat(coverageRound1.getRoundId(), equalTo(challengeId+""_R1""));
assertThat(coverageRound1.getCoverage(), equalTo(33));
CoverageComputedEvent coverageRound2 = coverageComputedEvents.get(1);
assertThat(coverageRound2.getParticipant(), equalTo(participantId));
assertThat(coverageRound2.getRoundId(), equalTo(challengeId+""_R2""));
assertThat(coverageRound2.getCoverage(), equalTo(44));
}",async wait,0
217,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireAllEvent,"@Test
public void testFireAllEvent() throws Exception {
final NamingEventCoordinator coordinator = new NamingEventCoordinator();
final CollectingListener objectListener = new CollectingListener(1);
coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
final CollectingListener subtreeListener = new CollectingListener(1);
coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
final CollectingListener oneLevelListener = new CollectingListener(1);
coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);
objectListener.latch.await(1, TimeUnit.SECONDS);
oneLevelListener.latch.await(1, TimeUnit.SECONDS);
subtreeListener.latch.await(1, TimeUnit.SECONDS);
assertEquals(1, objectListener.capturedEvents.size());
assertEquals(1, subtreeListener.capturedEvents.size());
assertEquals(1, oneLevelListener.capturedEvents.size());
}",test order dependency,4
218,fastjson,JSONObjectTest_readObject.test_6,"@Test
public void test_6() throws Exception {
JSONObject jsonObject = new JSONObject();
jsonObject.put(""val"", new Character[]{  });
jsonObject.put(""cls"", Number.class);
jsonObject.put(""nums"", new Number[]{  });
ByteArrayOutputStream bytesOut = new ByteArrayOutputStream();
ObjectOutputStream objOut = new ObjectOutputStream(bytesOut);
objOut.writeObject(jsonObject);
objOut.flush();
byte[] bytes = bytesOut.toByteArray();
ByteArrayInputStream bytesIn = new ByteArrayInputStream(bytes);
ObjectInputStream objIn = new ObjectInputStream(bytesIn);
Object obj = objIn.readObject();
assertEquals(JSONObject.class, obj.getClass());
assertEquals(jsonObject.toJSONString(), JSON.toJSONString(obj));
}",unordered collections,3
219,graylog2-server,KafkaJournalTest.serverStatusThrottledIfJournalUtilizationIsHigherThanThreshold,"@Test
public void serverStatusThrottledIfJournalUtilizationIsHigherThanThreshold() throws Exception {
serverStatus.running();
final Size segmentSize = Size.kilobytes(1L);
final KafkaJournal journal = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus);
createBulkChunks(journal, segmentSize, 4);
journal.flushDirtyLogs();
journal.cleanupLogs();
assertThat(serverStatus.getLifecycle()).isEqualTo(THROTTLED);
}",concurrency,1
220,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRebind,"@Test
public void testRebind() throws Exception {
final Name name = new CompositeName(""test"");
final Object value = new Object();
namingStore.bind(name, value);
Object newValue = new Object();
namingContext.rebind(name, newValue);
assertEquals(newValue, namingStore.lookup(name));
newValue = new Object();
testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newValue);
assertEquals(newValue, namingStore.lookup(name));
}",test order dependency,4
221,commercetools-project-sync,InventoryEntrySyncerTest.syncWithError_ShouldCallErrorCallback,"@Test
void syncWithError_ShouldCallErrorCallback() {
final TestLogger syncerTestLogger = TestLoggerFactory.getTestLogger(InventoryEntrySyncer.class);
final SphereClient sourceClient = mock(SphereClient.class);
final SphereClient targetClient = mock(SphereClient.class);
when(sourceClient.getConfig()).thenReturn(SphereApiConfig.of(""source-project""));
when(targetClient.getConfig()).thenReturn(SphereApiConfig.of(""target-project""));
final List<InventoryEntry> inventoryEntries = Collections.singletonList(readObjectFromResource(""inventory-no-sku.json"", InventoryEntry.class));
final PagedQueryResult<InventoryEntry> pagedQueryResult = mock(PagedQueryResult.class);
when(pagedQueryResult.getResults()).thenReturn(inventoryEntries);
when(sourceClient.execute(any(InventoryEntryQuery.class))).thenReturn(CompletableFuture.completedFuture(pagedQueryResult));
final InventoryEntrySyncer inventoryEntrySyncer = InventoryEntrySyncer.of(sourceClient, targetClient, mock(Clock.class));
inventoryEntrySyncer.sync(null, true).toCompletableFuture().join();
final LoggingEvent errorLog = syncerTestLogger.getAllLoggingEvents().get(1);
assertThat(errorLog.getMessage()).isEqualTo(""Error when trying to sync inventory entry. Existing key: <<not present>>. Update actions: []"");
assertThat(errorLog.getThrowable().get().getMessage()).isEqualTo(""InventoryEntryDraft doesn't have a SKU. Please make sure all inventory entry drafts have SKUs."");
}",test order dependency,4
222,struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testProcessAction_ok,"@Test
public void testProcessAction_ok() {
final Mock mockResponse = mock(ActionResponse.class);
PortletMode mode = PortletMode.VIEW;
Map<String, String> initParams = new HashMap<String, String>();
initParams.put(""viewNamespace"", ""/view"");
Map<String, String[]> requestParams = new HashMap<String, String[]>();
requestParams.put(ACTION_PARAM, new String[]{""/view/testAction""});
requestParams.put(MODE_PARAM, new String[]{mode.toString()});
initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true"");
initPortletConfig(initParams, new HashMap<String, Object>());
initRequest(requestParams, new HashMap<String, Object>(), new HashMap<String, Object>(), PortletMode.VIEW, WindowState.NORMAL, true, null);
setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));
try {
dispatcher
.setActionProxyFactory((ActionProxyFactory) mockActionFactory
.proxy());
dispatcher.init((PortletConfig) mockConfig.proxy());
dispatcher.processAction((ActionRequest) mockRequest.proxy(),
(ActionResponse) mockResponse.proxy());
} catch (Exception e) {
e.printStackTrace();
fail(""Error occured"");
}
}",test order dependency,4
223,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testList,"@Test
public void testList() throws Exception {
bindList();
NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName());
checkListResults(results);
results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, namingContext, null);
checkListResults(results);
}",test order dependency,4
224,hbase,TaskMonitor.testDoNotPurgeRPCTask,"@Test
public void testDoNotPurgeRPCTask() throws Exception {
int RPCTaskNums = 10;
TaskMonitor tm = TaskMonitor.get();
for(int i = 0; i < RPCTaskNums; i++) {
tm.createRPCStatus(""PRCTask"" + i);
}
for(int i = 0; i < TaskMonitor.DEFAULT_MAX_TASKS; i++) {
tm.createStatus(""otherTask"" + i);
}
int remainRPCTask = 0;
for(MonitoredTask task: tm.getTasks()) {
if(task instanceof MonitoredRPCHandler) {
remainRPCTask++;
}
}
assertEquals(""RPC Tasks have been purged!"", RPCTaskNums, remainRPCTask);
tm.shutdown();
}",test order dependency,4
225,alluxio,BlockMasterJournalIntegrationTest.journalBlockDeletion,"@Test
public void journalBlockDeletion() throws Exception {
FileSystem fs = mCluster.getClient();
BlockMaster blockMaster = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class);
AlluxioURI file = new AlluxioURI(""/test"");
FileSystemTestUtils.createByteFile(fs, file, MUST_CACHE, 10);
URIStatus status = fs.getStatus(file);
Long blockId = status.getBlockIds().get(0);
assertNotNull(blockMaster.getBlockInfo(blockId));
fs.delete(file);
WorkerNetAddress workerAddress = mCluster.getWorkerAddress();
try {
blockMaster.getBlockInfo(blockId);
fail(""Expected the block to be deleted"");
} catch (BlockInfoException e) {
}
mCluster.stopMasters();
mCluster.startMasters();
AlluxioMasterProcess masterProcess = mCluster.getLocalAlluxioMaster().getMasterProcess();
try {
masterProcess.getMaster(BlockMaster.class).getBlockInfo(blockId);
fail(""Expected the block to be deleted after restart"");
} catch (BlockInfoException e) {
}
}",async wait,0
226,portals,TestInternalPasswordCredentialHistoryHandlingInterceptor.testPasswordHistory,"@Test
public void testPasswordHistory() throws Exception {
assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password""));
Thread.sleep(10);
ums.setPassword(""testcred"", ""password"", ""password1"");
Thread.sleep(10);
ums.setPassword(""testcred"", ""password1"", ""password2"");
assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password2""));
try {
Thread.sleep(10);
ums.setPassword(""testcred"", ""password2"", ""password"");
fail(""Should not be allowed to reuse a password from password history"");
} catch (SecurityException sex) {
assertTrue(SecurityException.PASSWORD_ALREADY_USED.equals(sex.getKeyedMessage()));
}
Thread.sleep(10);
ums.setPassword(""testcred"", ""password2"", ""password3"");
Thread.sleep(10);
ums.setPassword(""testcred"", ""password3"", ""password4"");
Thread.sleep(10);
ums.setPassword(""testcred"", ""password4"", ""password"");
assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password""));
}",async wait,0
227,jenkins-rest,JobsApiLiveTest.testGetJobListFromRoot,"@Test
@Test(dependsOnMethods = ""testCreateJob"")
public void testGetJobListFromRoot() {
JobList output = api().jobList("""");
assertNotNull(output);
assertFalse(output.jobs().isEmpty());
assertEquals(output.jobs().size(), 2);
}",test order dependency,4
228,weblogic-kubernetes-operator,ItKubernetesEvents.testK8SEventsMultiClusterEvents,"@Test
void testK8SEventsMultiClusterEvents() {
createNewCluster();
OffsetDateTime timestamp = now();
scaleClusterWithRestApi(domainUid, cluster2Name, 1, externalRestHttpsPort, opNamespace, opServiceAccount);
logger.info(""verify the Domain_Available event is generated"");
checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_AVAILABLE, ""Normal"", timestamp);
logger.info(""verify the DomainCompleted event is generated"");
checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_COMPLETED, ""Normal"", timestamp);
logger.info(""verify the only 1 DomainCompleted event is generated"");
assertEquals(1, getEventCount(domainNamespace1, domainUid, DOMAIN_COMPLETED, timestamp));
}",time,2
229,pulsar,AvroSchemaTest.testNotAllowNullSchema,"@Test
public void testNotAllowNullSchema() {
AvroSchema<Foo> avroSchema = AvroSchema.of(SchemaDefinition.<Foo>builder().withPojo(Foo.class).withAlwaysAllowNull(false).build());
assertEquals(avroSchema.getSchemaInfo().getType(), AVRO);
Schema.Parser parser = new Schema.Parser();
String schemaJson = new String(avroSchema.getSchemaInfo().getSchema());
assertEquals(schemaJson, SCHEMA_AVRO_NOT_ALLOW_NULL);
Schema schema = parser.parse(schemaJson);
for (String fieldName : FOO_FIELDS) {
Schema.Field field = schema.getField(fieldName);
Assert.assertNotNull(field);
if (field.name().equals(""field4"")) {
Assert.assertNotNull(field.schema().getTypes().get(1).getField(""field1""));
}
if (field.name().equals(""fieldUnableNull"")) {
Assert.assertNotNull(field.schema().getType());
}
}
}",unordered collections,3
230,fastjson,Issue1492.test_for_issue,"@Test
public void test_for_issue() throws Exception {
DubboResponse resp = new DubboResponse();
JSONObject obj = new JSONObject();
obj.put(""key1"", ""value1"");
obj.put(""key2"", ""value2"");
resp.setData(obj);
String str = JSON.toJSONString(resp);
System.out.println(str);
DubboResponse resp1 = JSON.parseObject(str, DubboResponse.class);
assertEquals(str, JSON.toJSONString(resp1));
JSONArray arr = new JSONArray();
arr.add(""key1"");
arr.add(""key2"");
resp.setData(arr);
String str2 = JSON.toJSONString(resp);
System.out.println(str2);
DubboResponse resp2 = JSON.parseObject(str2, DubboResponse.class);
assertEquals(str2, JSON.toJSONString(resp2));
}",unordered collections,3
231,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindings,"@Test
public void testListBindings() throws Exception {
bindList();
NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName());
checkListResults(results);
results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, null);
checkListResults(results);
}",test order dependency,4
232,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListWithContinuation,"@Test
public void testListWithContinuation() throws Exception {
bindListWithContinuations();
NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName(""comp""));
checkListWithContinuationsResults(results);
results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, Arrays.asList(
new JndiPermission(""test"", ""list"")), namingContext, ""comp"");
checkListWithContinuationsResults(results);
}",test order dependency,4
233,flume,TestChokeDecos.runCollectiveChokeTest,"@Test
public void runCollectiveChokeTest() throws InterruptedException, IOException {
int numChokes = 5;
for (int i = 0; i < numChokes; i++) {
chokeMap.put(Integer.toString(i),
rateFloor + rand.nextInt(rateCeil - rateFloor));
}
testChokeMan.updateChokeLimitMap(chokeMap);
TestChoke[] tchokeArray = new TestChoke[numChokes];
for (int i = 0; i < numChokes; i++) {
tchokeArray[i] = new TestChoke<EventSink>(null, Integer.toString(i));
}
Set<TestChoke<EventSink>> chokesUsed = new HashSet<TestChoke<EventSink>>();
DirectDriver[] directDriverArray = new DirectDriver[numDrivers];
int randChokeIndex = 0;
for (int i = 0; i < numDrivers; i++) {
randChokeIndex = rand.nextInt(numChokes);
directDriverArray[i] = new DirectDriver(new SynthSourceRndSize(0,minMsgSize, maxMsgSize), tchokeArray[randChokeIndex]);
chokesUsed.add(tchokeArray[randChokeIndex]);
}
LOG.info(""Running the Collective Test Now!"");
for (TestChoke<EventSink> t : chokesUsed) {
if (!testChokeMan.isChokeId(t.getChokeId())) {
LOG.error(""ChokeID "" + t.getChokeId() + ""not present"");
fail();
}
}
testChokeMan.start();
for (DirectDriver f : directDriverArray) {
f.start();
}
Thread.sleep(testTime);
for (DirectDriver f : directDriverArray) {
f.stop();
}
testChokeMan.halt();
for (TestChoke<EventSink> t : chokesUsed) {
double maxRate = chokeMap.get(t.getChokeId());
errorRatio = ((double) (chokeMap.get(t.getChokeId()) * testTime)) / (double) (t.getReport().getLongMetric(""number of bytes""));
assertFalse((errorRatio > this.highErrorLimit || errorRatio < this.lowErrorLimit));
}
}",concurrency,1
234,jackrabbit,AbstractLockTest.testLockExpiration,"@Test
public synchronized void testLockExpiration() throws RepositoryException, NotExecutableException {
lockedNode.unlock();
long hint = 1;
lock = lockMgr.lock(lockedNode.getPath(), isDeep(), isSessionScoped(), hint, null);
long remaining = lock.getSecondsRemaining();
if (remaining <= hint) {
try {
wait(remaining * 2000);
} catch (InterruptedException ignore) {
}
long secs = lock.getSecondsRemaining();
assertTrue(""A released lock must return a negative number of seconds, was: "" + secs, secs < 0);
String message = ""If the timeout hint is respected the lock"" + "" must be automatically released."";
assertFalse(message, lock.isLive());
assertFalse(message, lockedNode.isLocked());
assertFalse(message, lockMgr.isLocked(lockedNode.getPath()));
assertFalse(message, lockedNode.hasProperty(JCR_LOCK_IS_DEEP));
assertFalse(message, lockedNode.hasProperty(JCR_LOCK_OWNER));
} else {
throw new NotExecutableException(""timeout hint was ignored."");
}
}",async wait,0
235,CorfuDB,StreamingIT.testStreamingPrevValue,"@Test
public void testStreamingPrevValue() throws Exception {
Process corfuServer = runSinglePersistentServer(corfuSingleNodeHost, corfuStringNodePort);
runtime = createRuntime(singleNodeEndpoint);
CorfuStore store = new CorfuStore(runtime);
String ns = ""test_namespace"";
String tn = ""tableA"";
Table<Uuid, SampleTableAMsg, Uuid> table = store.openTable(ns, tn, Uuid.class, SampleTableAMsg.class, Uuid.class, TableOptions.builder().build());
PrevValueStreamer listenerCommon = new PrevValueStreamer<Uuid, SampleTableAMsg, Uuid>(store, ns, tn);
store.subscribeListener(listenerCommon, ns, ""sample_streamer_1"", Collections.singletonList(tn));
final int numRecords = PARAMETERS.NUM_ITERATIONS_LOW;
for (int i = 0; i < numRecords; i++) {
try (final TxnContext tx = store.txn(namespace)) {
Uuid key = Uuid.newBuilder().setLsb(0).setMsb(0).build();
SampleTableAMsg val = SampleTableAMsg.newBuilder().setPayload(""val"" + i).build();
tx.putRecord(table, key, val, key);
tx.commit();
}
}
TimeUnit.MILLISECONDS.sleep(sleepTime);
assertThat(listenerCommon.getRecordCount()).isEqualTo(numRecords);
assertThat(shutdownCorfuServer(corfuServer)).isTrue();
}",async wait,0
236,Digital,CircuitBuilderTest.testBus,"@Test
public void testBus() throws Exception {
final ToBreakRunner runner = new ToBreakRunner(""dig/circuitBuilder/busTest.dig"", false);
TruthTable tt = new ModelAnalyser(runner.getModel()).analyse();
assertEquals(8, tt.getVars().size());
assertEquals(8, tt.getResultCount());
ExpressionListenerStore expr = new ExpressionListenerStore(null);
new ExpressionCreator(tt).create(expr);
CircuitBuilder circuitBuilder = new CircuitBuilder(runner.getLibrary().getShapeFactory(), tt.getVars()).setModelAnalyzerInfo(tt.getModelAnalyzerInfo());
new BuilderExpressionCreator(circuitBuilder).create(expr);
Circuit circuit = circuitBuilder.createCircuit();
List<VisualElement> in = circuit.getElements(( v) -> v.equalsDescription(In.DESCRIPTION));
assertEquals(2, in.size());
checkPin(in.get(0), ""A"", ""1,2,3,4"");
checkPin(in.get(1), ""B"", ""5,6,7,8"");
List<VisualElement> out = circuit.getElements(( v) -> v.equalsDescription(Out.DESCRIPTION));
assertEquals(2, out.size());
checkPin(out.get(0), ""S"", ""9,10,11,12"");
checkPin(out.get(1), ""U"", ""13,14,15,16"");
}",unordered collections,3
237,undertow,d0efffad5d2034bb07525cac9b299dac72c3045d.testCloseReason,"@Test
public void testCloseReason() throws Exception {
MessageEndpoint.reset();
Session session = deployment.connectToServer(AnnotatedClientEndpoint.class, new URI(""ws://"" + DefaultServer.getHostAddress(""default"") + "":"" + DefaultServer.getHostPort(""default"") + ""/ws/chat/Bob""));
Assert.assertEquals(""hi Bob (protocol=foo)"", AnnotatedClientEndpoint.message());
session.close(new CloseReason(CloseReason.CloseCodes.VIOLATED_POLICY, ""Foo!""));
Assert.assertEquals(""CLOSED"", AnnotatedClientEndpoint.message());
CloseReason cr = MessageEndpoint.getReason();
Assert.assertEquals(CloseReason.CloseCodes.VIOLATED_POLICY.getCode(), cr.getCloseCode().getCode());
Assert.assertEquals(""Foo!"", cr.getReasonPhrase());
}",test order dependency,4
238,pulsar,ReplicatorTest.testReplicatorProducerName,"@Test
public void testReplicatorProducerName() throws Exception {
log.info(""--- Starting ReplicatorTest::testReplicatorProducerName ---"");
final String topicName = BrokerTestUtil.newUniqueName(""persistent"");
final TopicName dest = TopicName.get(topicName);
@Cleanup
MessageProducer producer1 = new MessageProducer(url1, dest);
Awaitility.await().untilAsserted(() -> {
assertTrue(pulsar2.getBrokerService().getTopicReference(topicName).isPresent());
});
Optional<Topic> topic = pulsar2.getBrokerService().getTopicReference(topicName);
assertTrue(topic.isPresent());
Set<String> remoteClusters = topic.get().getProducers().values().stream().map(Producer::getRemoteCluster).collect(Collectors.toSet());
assertTrue(remoteClusters.contains(""r1""));
}",async wait,0
239,Hystrix,HealthCountsStreamTest.testShortCircuited,"@Test
public void testShortCircuited() {
HystrixCommandKey key = Factory.asKey(""CMD-Health-G"");
stream = HealthCountsStream.getInstance(key, 10, 100);
final CountDownLatch latch = new CountDownLatch(1);
stream.observe().take(10).subscribe(getSubscriber(latch));
CommandStreamTest.Command failure1 = Command.from(groupKey, key, FAILURE, 20);
CommandStreamTest.Command failure2 = Command.from(groupKey, key, FAILURE, 20);
CommandStreamTest.Command failure3 = Command.from(groupKey, key, FAILURE, 20);
CommandStreamTest.Command shortCircuit1 = Command.from(groupKey, key, SUCCESS);
CommandStreamTest.Command shortCircuit2 = Command.from(groupKey, key, SUCCESS);
failure1.observe();
failure2.observe();
failure3.observe();
try {
Thread.sleep(100);
} catch (InterruptedException ie) {
fail(ie.getMessage());
}
shortCircuit1.observe();
shortCircuit2.observe();
try {
assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
} catch (InterruptedException ex) {
fail(""Interrupted ex"");
}
assertTrue(shortCircuit1.isResponseShortCircuited());
assertTrue(shortCircuit2.isResponseShortCircuited());
System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
assertEquals(3L, stream.getLatest().getErrorCount());
assertEquals(3L, stream.getLatest().getTotalRequests());
}",async wait,0
240,nutz,JsonTest.test_enum,"@Test
public void test_enum() {
assertEquals(""\""K\"""", Json.toJson(K.K));
String expected = ""{\n"" + ((""   \""name\"": \""t\"",\n"" + ""   \""index\"": 1\n"") + ""}"");
assertEquals(expected, Json.toJson(TT.T));
assertEquals(""\""T\"""", Json.toJson(TT.T, JsonFormat.full().ignoreJsonShape()));
}",unordered collections,3
241,servicemix,WSNComponentTest.testUnsubscribe,"@Test
public void testUnsubscribe() throws Exception {
PullPoint pullPoint = wsnCreatePullPoint.createPullPoint();
Subscription subscription = wsnBroker.subscribe(pullPoint.getEndpoint(), ""myTopic"", null);
wsnBroker.notify(""myTopic"", new Notify());
Thread.sleep(500);
assertEquals(1, pullPoint.getMessages(0).size());
subscription.unsubscribe();
wsnBroker.notify(""myTopic"", new Notify());
Thread.sleep(500);
assertEquals(0, pullPoint.getMessages(0).size());
Thread.sleep(500);
}",async wait,0
242,xtext-eclipse,XtextGrammarRefactoringIntegrationTest.testRefactorXtextGrammarWithoutGeneratedClassifier,"@Test
public void testRefactorXtextGrammarWithoutGeneratedClassifier() throws Exception {
waitForBuild();
final XtextEditor editor = openEditor(grammarFile);
doRefactoring(editor);
waitForReconciler(editor);
waitForDisplay();
waitForBuild();
checkConsistenceOfGrammar(editor);
}",async wait,0
243,fastjson,test_date,"@Test
public void test_date() throws Exception {
Date date1 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12\""}"", VO.class).getGmtCreate();
assertNotNull(date1);
Date date2 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19+00:00\""}"", VO.class).getGmtCreate();
Date date3 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate();
Date date4 = JSON.parseObject(""{\""gmtCreate\"":\""20180912T151019Z\""}"", VO.class).getGmtCreate();
Date date5 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate();
Date date6 = JSON.parseObject(""{\""gmtCreate\"":\""20180912\""}"", VO.class).getGmtCreate();
long delta_2_1 = date2.getTime() - date1.getTime();
assertEquals(83419000, delta_2_1);
long delta_3_1 = date3.getTime() - date1.getTime();
assertEquals(83419000, delta_3_1);
long delta_4_3 = date4.getTime() - date3.getTime();
assertEquals(0, delta_4_3);
long delta_5_4 = date5.getTime() - date4.getTime();
assertEquals(0, delta_5_4);
long delta_6_1 = date6.getTime() - date1.getTime();
assertEquals(0, delta_6_1);
}",time,2
244,dropwizard-service-utilities,SystemExecutionerTest.shouldExitBeforeGivenWaitTime_WhenWaitingThreadInterrupted,"@Test
void shouldExitBeforeGivenWaitTime_WhenWaitingThreadInterrupted() {
var executorService = Executors.newFixedThreadPool(2);
var executionStrategy = new ExecutionStrategies.ExitFlaggingExecutionStrategy();
var executioner = new SystemExecutioner(executionStrategy);
var startTime = new AtomicLong();
var executionFuture = executorService.submit(() -> {
LOG.info(""Calling executioner with 5 second wait"");
startTime.set(System.nanoTime());
executioner.exit(5, TimeUnit.SECONDS);
});
var killerSleepTimeMillis = 100;
var killerFuture = executorService.submit(() -> {
LOG.info(""Sleeping for {} milliseconds..."", killerSleepTimeMillis);
new DefaultEnvironment().sleepQuietly(killerSleepTimeMillis, TimeUnit.MILLISECONDS);
LOG.info(""I'm awake and will now interrupt executionThread"");
var canceled = executionFuture.cancel(true);
LOG.info(""executionFuture was canceled? {}"", canceled);
});
await().atMost(ONE_SECOND).until(() -> executionFuture.isDone() && killerFuture.isDone());
long elapsedNanos = System.nanoTime() - startTime.get();
assertThat(executionStrategy.didExit()).describedAs(""Execution strategy exit() should have been called"").isTrue();
assertThat(TimeUnit.NANOSECONDS.toMillis(elapsedNanos)).describedAs(""Elapsed millis must be greater than %d"", killerSleepTimeMillis).isGreaterThan(killerSleepTimeMillis);
executorService.shutdown();
await().atMost(ONE_SECOND).until(executorService::isShutdown);
}",time,2
245,Achilles,TestEntityWithStaticAnnotations.should_insert_using_static_strategy_an_consistency_level,"@Test
public void should_insert_using_static_strategy_an_consistency_level() throws Exception {
final long id = RandomUtils.nextLong(0L, Long.MAX_VALUE);
scriptExecutor.executeScriptTemplate(""EntityWithStaticAnnotations/insert_single_row.cql"", ImmutableMap.of(""id"", id));
final EntityWithStaticAnnotations entity = new EntityWithStaticAnnotations(id, ""new_val"", null);
final CassandraLogAsserter logAsserter = new CassandraLogAsserter();
logAsserter.prepareLogLevelForDriverConnection();
manager.crud().insert(entity).usingTimeToLive(1000).execute();
Row actual = session.execute(""SELECT * FROM entity_static_annotations WHERE partition_key = "" + id).one();
assertThat(actual).isNotNull();
assertThat(actual.getString(""value"")).isEqualTo(""new_val"");
assertThat(actual.getString(""\""overRiden\"""")).isEqualTo(""overriden_val"");
logAsserter.assertConsistencyLevels(LOCAL_ONE);
}",async wait,0
246,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupNameNotFound,"@Test
public void testLookupNameNotFound() throws Exception {
try {
namingContext.lookup(new CompositeName(""test""));
fail(""Should have thrown and NameNotFoundException"");
} catch (NameNotFoundException expected) {
}
try {
testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
} catch (NameNotFoundException expected) {
}
}",test order dependency,4
247,hadoop,TestSecurityUtil.testBuildDTServiceName,"@Test
public void testBuildDTServiceName() {
assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
}",test order dependency,4
248,ignite,SystemCacheNotConfiguredTest.test,"@Test
public void test() throws Exception {
captureErr();
new Thread(this::startServer).start();
Ignite client = startGrid(getConfiguration(""client"").setClientMode(true));
IgniteServices services = client.services();
SimpleService srvc = services.serviceProxy(""service"", SimpleService.class, false);
Thread.sleep(1000);
srvc.isWorking();
assertFalse(getErr().contains(""Cache is not configured:""));
}",async wait,0
249,spring-framework,validUsage,"@Test
void validUsage() throws Exception {
assertThat(stopWatch.isRunning()).isFalse();
stopWatch.start(name1);
Thread.sleep(duration1);
assertThat(stopWatch.isRunning()).isTrue();
assertThat(stopWatch.currentTaskName()).isEqualTo(name1);
stopWatch.stop();
assertThat(stopWatch.isRunning()).isFalse();
assertThat(stopWatch.getLastTaskTimeNanos())
.as(""last task time in nanoseconds for task #2"")
.isGreaterThanOrEqualTo(millisToNanos(duration2))
.isLessThanOrEqualTo(millisToNanos(duration2 + fudgeFactor));
assertThat(stopWatch.getTotalTimeMillis())
.as(""total time in milliseconds for tasks #1 and #2"")
.isGreaterThanOrEqualTo(duration1 + duration2 - fudgeFactor)
.isLessThanOrEqualTo(duration1 + duration2 + fudgeFactor);
assertThat(stopWatch.getTotalTimeSeconds())
.as(""total time in seconds for task #2"")
.isGreaterThanOrEqualTo((duration1 + duration2 - fudgeFactor) / 1000.0)
.isLessThanOrEqualTo((duration1 + duration2 + fudgeFactor) / 1000.0);
assertThat(stopWatch.getTaskCount()).isEqualTo(2);
assertThat(stopWatch.prettyPrint()).contains(name1, name2);
assertThat(stopWatch.getTaskInfo()).extracting(TaskInfo::getTaskName).containsExactly(name1, name2);
assertThat(stopWatch.toString()).contains(ID, name1, name2);
assertThat(stopWatch.getId()).isEqualTo(ID);
}",time,2
250,maven,CheckoutMojoTest.testUseExport,"@Test
public void testUseExport() throws Exception {
checkoutDir.mkdirs();
CheckoutMojo mojo = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutUsingExport.xml""))));
mojo.setCheckoutDirectory(checkoutDir);
mojo.execute();
assertTrue(checkoutDir.listFiles().length > 0);
assertFalse(new File(checkoutDir, "".svn"").exists());
}",test order dependency,4
251,hadoop,TestUnderReplicatedBlocks.testSetrepIncWithUnderReplicatedBlocks,"@Test
public void testSetrepIncWithUnderReplicatedBlocks() throws Exception {
Configuration conf = new HdfsConfiguration();
final short REPLICATION_FACTOR = 2;
final String FILE_NAME = ""/testFile"";
final Path FILE_PATH = new Path(FILE_NAME);
MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION_FACTOR + 1).build();
try {
final FileSystem fs = cluster.getFileSystem();
DFSTestUtil.createFile(fs, FILE_PATH, 1L, REPLICATION_FACTOR, 1L);
DFSTestUtil.waitReplication(fs, FILE_PATH, REPLICATION_FACTOR);
final BlockManager bm = cluster.getNamesystem().getBlockManager();
ExtendedBlock b = DFSTestUtil.getFirstBlock(fs, FILE_PATH);
DatanodeDescriptor dn = bm.blocksMap.nodeIterator(b.getLocalBlock()).next();
bm.addToInvalidates(b.getLocalBlock(), dn);
bm.blocksMap.removeNode(b.getLocalBlock(), dn);
FsShell shell = new FsShell(conf);
assertEquals(0, shell.run(new String[]{ ""-setrep"", ""-w"", Integer.toString(1 + REPLICATION_FACTOR), FILE_NAME }));
} finally {
cluster.shutdown();
}
}",async wait,0
252,ninja,MessagesImplTest.testiParameterized18nWithSpeciali18nPlaceholder,"@Test
public void testiParameterized18nWithSpeciali18nPlaceholder() {
when(ninjaProperties.getStringArray(applicationLanguages)).thenReturn(new String[]{ ""en"", ""de"", ""fr-FR"" });
Lang lang = new LangImpl(ninjaProperties);
Messages messages = new MessagesImpl(ninjaProperties, lang);
Optional<String> language = Optional.absent();
Optional<String> result = messages.get(""message_with_placeholder_date"", language, new Date(0));
assertEquals(""that's a date: Jan 1, 1970"", result.get());
language = Optional.of(""de"");
result = messages.get(""message_with_placeholder_date"", language, new Date(0));
assertEquals(""das ist ein datum: 01.01.1970"", result.get());
language = Optional.of(""fr-FR"");
result = messages.get(""message_with_placeholder_date"", language, new Date(0));
assertEquals(""c`est la date: 1 janv. 1970"", result.get());
language = Optional.of(""en"");
result = messages.get(""message_with_placeholder_date"", language, new Date(0));
assertEquals(""that's a date: Jan 1, 1970"", result.get());
}",time,2
253,neo4j,RobustJobSchedulerWrapperTest.recurringJobWithErrorShouldStop,"@Test
public void recurringJobWithErrorShouldStop() throws Exception
{
RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper( actualScheduler, log );
AtomicInteger count = new AtomicInteger();
Error e = new Error();
JobHandle jobHandle = robustWrapper.scheduleRecurring( ""JobName"", 1, () ->{
count.incrementAndGet();
throw e;
}
);
Thread.sleep( 50 );
assertEventually( ""run count"", count::get, Matchers.equalTo( 1 ), DEFAULT_TIMEOUT_MS , MILLISECONDS );
robustWrapper.cancelAndWaitTermination( jobHandle );
verify( log, timeout( DEFAULT_TIMEOUT_MS ).times( 1 ) ).error( ""Uncaught error rethrown"", e );
}",concurrency,1
254,activemq,SimpleNetworkTest.testConduitBridge,"@Test
public void testConduitBridge() throws Exception {
MessageConsumer consumer1 = remoteSession.createConsumer(included);
MessageConsumer consumer2 = remoteSession.createConsumer(included);
MessageProducer producer = localSession.createProducer(included);
producer.setDeliveryMode(NON_PERSISTENT);
Thread.sleep(2000);
for (int i = 0; i < MESSAGE_COUNT; i++) {
Message test = localSession.createTextMessage(""test-"" + i);
producer.send(test);
assertNotNull(consumer1.receive(1000));
assertNotNull(consumer2.receive(1000));
}
assertNull(consumer1.receive(1000));
assertNull(consumer2.receive(1000));
}",async wait,0
255,fastjson,Issue1584.test_for_issue,"@Test
public void test_for_issue() throws Exception {
ParserConfig config = new ParserConfig();
String json = ""{\""k\"":1,\""v\"":\""A\""}"";
{
Map.Entry entry = JSON.parseObject(json, Map.Entry.class, config);
assertEquals(""v"", entry.getKey());
assertEquals(""A"", entry.getValue());
}
config.putDeserializer(Map.Entry.class, new ObjectDeserializer() {
public <T> T deserialze(DefaultJSONParser parser, Type type, Object fieldName) {
JSONObject object = parser.parseObject();
Object k = object.get(""k"");
Object v = object.get(""v"");
return ((T) (Collections.singletonMap(k, v).entrySet().iterator().next()));
}
public int getFastMatchToken() {
return 0;
}
});
Map.Entry entry = JSON.parseObject(json, Map.Entry.class, config);
assertEquals(1, entry.getKey());
assertEquals(""A"", entry.getValue());
}",unordered collections,3
256,hadoop,TestDelegationTokenForProxyUser.testWebHdfsDoAs,"@Test
public void testWebHdfsDoAs() throws Exception {
LOG.info(""START: testWebHdfsDoAs()"");
((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
final UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER);
LOG.info(""ugi.getShortUserName()="" + ugi.getShortUserName());
final WebHdfsFileSystem webhdfs = WebHdfsTestUtil.getWebHdfsFileSystemAs(ugi, config);
final Path root = new Path(""/"");
cluster.getFileSystem().setPermission(root, new FsPermission(((short) (0777))));
{
final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER));
final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
conn.disconnect();
final Object responsePath = m.get(Path.class.getSimpleName());
LOG.info(""responsePath="" + responsePath);
Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
}
{
final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER) {
@Override
public String getName() {
return ""DOas"";
}
});
final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
conn.disconnect();
final Object responsePath = m.get(Path.class.getSimpleName());
LOG.info(""responsePath="" + responsePath);
Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
}
final Path f = new Path(""/testWebHdfsDoAs/a.txt"");
{
final PutOpParam.Op op = Op.CREATE;
final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
out.write(""Hello, webhdfs user!"".getBytes());
out.close();
final FileStatus status = webhdfs.getFileStatus(f);
LOG.info(""status.getOwner()="" + status.getOwner());
Assert.assertEquals(PROXY_USER, status.getOwner());
}
{
final PostOpParam.Op op = Op.APPEND;
final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
out.write(""\nHello again!"".getBytes());
out.close();
final FileStatus status = webhdfs.getFileStatus(f);
LOG.info(""status.getOwner()="" + status.getOwner());
LOG.info(""status.getLen()  ="" + status.getLen());
Assert.assertEquals(PROXY_USER, status.getOwner());
}
}",test order dependency,4
257,facebook-java-business-sdk,ServerSideTest.CustomDataParametersTest,"@Test
public void CustomDataParametersTest() {
APIContext context = new APIContext(""ACCESS_TOKEN"").enableDebug(true);
UserData userData = new UserData().email(""abc@eg.com"");
HashMap<String, String> customProperties = new HashMap<String, String>();
customProperties.put(""Key1"", ""Value1"");
customProperties.put(""Key2"", ""Value2"");
List<Content> contents = new ArrayList<Content>();
contents.add(new Content().productId(""1"").brand(""brandA""));
contents.add(new Content().productId(""2"").brand(""brandB""));
List<String> contentIds = new ArrayList<String>();
contentIds.add(""123"");
contentIds.add(""456"");
String contentCategory = ""content_categoryA"";
String contentName = ""content_nameA"";
String currency = ""USD"";
CustomData customData = new CustomData().contentIds(contentIds).customProperties(customProperties).contents(contents).contentCategory(contentCategory).contentName(contentName).currency(currency).deliveryCategory(curbside).value(123.45F);
Event testEvent = new Event();
testEvent.eventName(""Purchase"").eventTime(System.currentTimeMillis() / 1000L).userData(userData).dataProcessingOptions(new String[]{  }).customData(customData);
EventRequest eventRequest = new EventRequest(""123"", context);
eventRequest.addDataItem(testEvent);
String serializedPayload = eventRequest.getSerializedPayload();
String cpString = new Gson().toJson(customProperties);
String serializedContents = new Gson().toJson(contents);
String serializedContentIds = new Gson().toJson(contentIds);
Assert.assertTrue(serializedPayload.contains(cpString.substring(1, cpString.length() - 1)));
Assert.assertTrue(serializedPayload.contains(serializedContents));
Assert.assertTrue(serializedPayload.contains(serializedContentIds));
Assert.assertTrue(serializedPayload.contains(currency.toLowerCase()));
Assert.assertTrue(serializedPayload.contains(contentCategory));
Assert.assertTrue(serializedPayload.contains(contentName));
Assert.assertTrue(serializedPayload.contains(curbside.toString()));
}",unordered collections,3
258,hadoop,TestMetricsSystemImpl.testInitFirstVerifyCallBacks,"@Test
public void testInitFirstVerifyCallBacks() throws Exception {
DefaultMetricsSystem.shutdown();
new ConfigBuilder().add(""*.period"", 8).add(""test.sink.test.class"", TestSink.class.getName()).add(""test.*.source.filter.exclude"", ""s0"").add(""test.source.s1.metric.filter.exclude"", ""X*"").add(""test.sink.sink1.metric.filter.exclude"", ""Y*"").add(""test.sink.sink2.metric.filter.exclude"", ""Y*"").save(TestMetricsConfig.getTestFilename(""hadoop-metrics2-test""));
MetricsSystemImpl ms = new MetricsSystemImpl(""Test"");
ms.start();
ms.register(""s0"", ""s0 desc"", new TestSource(""s0rec""));
TestSource s1 = ms.register(""s1"", ""s1 desc"", new TestSource(""s1rec""));
s1.c1.incr();
s1.xxx.incr();
s1.g1.set(2);
s1.yyy.incr(2);
s1.s1.add(0);
MetricsSink sink1 = mock(MetricsSink.class);
MetricsSink sink2 = mock(MetricsSink.class);
ms.registerSink(""sink1"", ""sink1 desc"", sink1);
ms.registerSink(""sink2"", ""sink2 desc"", sink2);
ms.publishMetricsNow();
try {
verify(sink1, timeout(200).times(2)).putMetrics(r1.capture());
verify(sink2, timeout(200).times(2)).putMetrics(r2.capture());
} finally {
ms.stop();
ms.shutdown();
}
List<MetricsRecord> mr1 = r1.getAllValues();
List<MetricsRecord> mr2 = r2.getAllValues();
checkMetricsRecords(mr1);
assertEquals(""output"", mr1, mr2);
}",unordered collections,3
259,botbuilder-java,AdditionalPropertiesSerializerTests.canSerializeAdditionalProperties,"@Test
public void canSerializeAdditionalProperties() throws Exception {
Foo foo = new Foo();
foo.bar = ""hello.world"";
foo.baz = new ArrayList<>();
foo.baz.add(""hello"");
foo.baz.add(""hello.world"");
foo.qux = new HashMap<>();
foo.qux.put(""hello"", ""world"");
foo.qux.put(""a.b"", ""c.d"");
foo.qux.put(""bar.a"", ""ttyy"");
foo.qux.put(""bar.b"", ""uuzz"");
foo.additionalProperties = new HashMap<>();
foo.additionalProperties.put(""bar"", ""baz"");
foo.additionalProperties.put(""a.b"", ""c.d"");
foo.additionalProperties.put(""properties.bar"", ""barbar"");
String serialized = new JacksonAdapter().serialize(foo);
Assert.assertEquals(""{\""$type\"":\""foo\"",\""properties\"":{\""bar\"":\""hello.world\"",\""props\"":{\""baz\"":[\""hello\"",\""hello.world\""],\""q\"":{\""qux\"":{\""hello\"":\""world\"",\""a.b\"":\""c.d\"",\""bar.b\"":\""uuzz\"",\""bar.a\"":\""ttyy\""}}}},\""bar\"":\""baz\"",\""a.b\"":\""c.d\"",\""properties.bar\"":\""barbar\""}"", serialized);
}",unordered collections,3
260,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRebindReferenceable,"@Test
public void testRebindReferenceable() throws Exception {
final Name name = new CompositeName(""test"");
final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
namingContext.bind(name, referenceable);
TestObjectReferenceable newReferenceable = new TestObjectReferenceable(""newAddr"");
namingContext.rebind(name, newReferenceable);
Object result = namingContext.lookup(name);
assertEquals(newReferenceable.addr, result);
newReferenceable = new TestObjectReferenceable(""yetAnotherNewAddr"");
testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newReferenceable);
result = namingContext.lookup(name);
assertEquals(newReferenceable.addr, result);
}",test order dependency,4
261,amazon-instant-access-sdk-java,InstantAccessRequestTest.testSerialize,"@Test
public void testSerialize() throws SerializationException {
GetUserIdSerializableRequest request = new GetUserIdSerializableRequest();
request.setOperation(GETUSERID);
request.setInfoField1(""nobody@amazon.com"");
request.setInfoField2(""AMZN"");
String requestString = serializer.encode(request);
assertEquals(""{\""operation\"":\""GetUserId\"",\""infoField1\"":\""nobody@amazon.com\"",\""infoField2\"":\""AMZN\""}"", requestString);
}",unordered collections,3
262,cdap,WorkflowHttpHandlerTest.testWorkflowTokenPut,"@Test
public void testWorkflowTokenPut() throws Exception {
Assert.assertEquals(200, deploy(WorkflowTokenTestPutApp.class).getStatusLine().getStatusCode());
Id.Application appId = Id.Application.from(Id.Namespace.DEFAULT, WorkflowTokenTestPutApp.NAME);
Id.Workflow workflowId = Id.Workflow.from(appId, WorkflowTokenTestPutApp.WorkflowTokenTestPut.NAME);
Id.Program mapReduceId = Id.Program.from(appId, ProgramType.MAPREDUCE, WorkflowTokenTestPutApp.RecordCounter.NAME);
Id.Program sparkId = Id.Program.from(appId, ProgramType.SPARK, WorkflowTokenTestPutApp.SparkTestApp.NAME);
String outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""firstInput""),
""outputPath"", outputPath, ""put.in.mapper.initialize"", ""true""));
waitState(workflowId, ProgramRunStatus.RUNNING.name());
waitState(workflowId, ""STOPPED"");
List<RunRecord> workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(1, workflowProgramRuns.size());
List<RunRecord> mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(1, mapReduceProgramRuns.size());
outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""secondInput""),
""outputPath"", outputPath, ""put.in.map"", ""true""));
waitState(workflowId, ProgramRunStatus.RUNNING.name());
waitState(workflowId, ""STOPPED"");
workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(2, workflowProgramRuns.size());
mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(2, mapReduceProgramRuns.size());
outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""thirdInput""),
""outputPath"", outputPath, ""put.in.reducer.initialize"", ""true""));
waitState(workflowId, ProgramRunStatus.RUNNING.name());
waitState(workflowId, ""STOPPED"");
workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(3, workflowProgramRuns.size());
mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(3, mapReduceProgramRuns.size());
outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fourthInput""),
""outputPath"", outputPath, ""put.in.reduce"", ""true""));
waitState(workflowId, ProgramRunStatus.RUNNING.name());
waitState(workflowId, ""STOPPED"");
workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(4, workflowProgramRuns.size());
mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(4, mapReduceProgramRuns.size());
outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fifthInput""),
""outputPath"", outputPath, ""closurePutToken"", ""true""));
waitState(workflowId, ProgramRunStatus.RUNNING.name());
waitState(workflowId, ""STOPPED"");
workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(5, workflowProgramRuns.size());
mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.COMPLETED.name());
Assert.assertEquals(1, mapReduceProgramRuns.size());
List<RunRecord> sparkProgramRuns = getProgramRuns(sparkId, ProgramRunStatus.FAILED.name());
Assert.assertEquals(1, sparkProgramRuns.size());
outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""sixthInput""),
""outputPath"", outputPath));
waitState(workflowId, ProgramRunStatus.RUNNING.name());
waitState(workflowId, ""STOPPED"");
workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.COMPLETED.name());
Assert.assertEquals(1, workflowProgramRuns.size());
workflowProgramRuns = getProgramRuns(sparkId, ProgramRunStatus.COMPLETED.name());
Assert.assertEquals(1, workflowProgramRuns.size());
}",async wait,0
263,hbase,TestFlushWithThroughputController.testFlushThroughputTuning,"@Test
public void testFlushThroughputTuning() throws Exception {
Configuration conf = TEST_UTIL.getConfiguration();
conf.set(StoreEngine.STORE_ENGINE_CLASS_KEY, DefaultStoreEngine.class.getName());
conf.setLong(PressureAwareFlushThroughputController.HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_UPPER_BOUND,20L * 1024 * 1024);
conf.setLong(PressureAwareFlushThroughputController.HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_LOWER_BOUND,10L * 1024 * 1024);
conf.set(FlushThroughputControllerFactory.HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY,PressureAwareFlushThroughputController.class.getName());
conf.setInt(PressureAwareFlushThroughputController.HBASE_HSTORE_FLUSH_THROUGHPUT_TUNE_PERIOD,3000);
TEST_UTIL.startMiniCluster(1);
Connection conn = ConnectionFactory.createConnection(conf);
try {
HTableDescriptor htd = new HTableDescriptor(tableName);
htd.addFamily(new HColumnDescriptor(family));
htd.setCompactionEnabled(false);
TEST_UTIL.getHBaseAdmin().createTable(htd);
TEST_UTIL.waitTableAvailable(tableName);
HRegionServer regionServer = TEST_UTIL.getRSForFirstRegionInTable(tableName);
PressureAwareFlushThroughputController throughputController = (PressureAwareFlushThroughputController) regionServer.getFlushThroughputController();
for (Region region : regionServer.getOnlineRegions()) {
region.flush(true);
}
assertEquals(0.0, regionServer.getFlushPressure(), EPSILON);
Thread.sleep(5000);
assertEquals(10L * 1024 * 1024, throughputController.getMaxThroughput(), EPSILON);
Table table = conn.getTable(tableName);
Random rand = new Random();
for (int i = 0; i < 10; i++) {
for (int j = 0; j < 10; j++) {
byte[] value = new byte[256 * 1024];
rand.nextBytes(value);
table.put(new Put(Bytes.toBytes(i * 10 + j)).addColumn(family, qualifier, value));
}
}
Thread.sleep(5000);
double expectedThroughPut = 10L * 1024 * 1024 * (1 + regionServer.getFlushPressure());
assertEquals(expectedThroughPut, throughputController.getMaxThroughput(), EPSILON);
conf.set(FlushThroughputControllerFactory.HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY,NoLimitThroughputController.class.getName());
regionServer.onConfigurationChange(conf);
assertTrue(throughputController.isStopped());
assertTrue(regionServer.getFlushThroughputController() instanceof NoLimitThroughputController);
} finally {
conn.close();
TEST_UTIL.shutdownMiniCluster();
}",async wait,0
264,presto,TestQueuesDb.testResourceGroupConcurrencyThreshold,"@Test
public void testResourceGroupConcurrencyThreshold()
throws Exception
{
String dbConfigUrl1 = getDbConfigUrl();
H2ResourceGroupsDao dao = getDao(dbConfigUrl1);
DistributedQueryRunner queryRunner = createQueryRunner(dbConfigUrl1, dao, ImmutableMap.of(""concurrency-threshold-to-enable-resource-group-refresh"", ""0.1"", ""resource-group-runtimeinfo-refresh-interval"", ""10s""));
MILLISECONDS.sleep(500);
QueryId firstAdhocQuery = createQuery(queryRunner, adhocSession(), LONG_LASTING_QUERY);
waitForQueryState(queryRunner, firstAdhocQuery, RUNNING);
waitForRunningQueryCount(queryRunner, 1);
QueryId secondAdhocQuery = createQuery(queryRunner, adhocSession(), LONG_LASTING_QUERY);
waitForQueryState(queryRunner, secondAdhocQuery, QUEUED);
MILLISECONDS.sleep(500);
waitForQueryState(queryRunner, secondAdhocQuery, RUNNING);
waitForRunningQueryCount(queryRunner, 2);
closeQuietly(queryRunner);
}",async wait,0
265,hive,testCleanup,"@Test
public void testCleanup() throws Exception {
ObjectStore objStore = new ObjectStore();
objStore.setConf(metaStore.getConf());
objStore.deleteRuntimeStats(0);
objStore.addRuntimeStat(createStat(1));
Thread.sleep(2000);
objStore.addRuntimeStat(createStat(2));
int deleted = objStore.deleteRuntimeStats(1);
int deleted = objStore.deleteRuntimeStats(5);
assertEquals(1, deleted);
List<RuntimeStat> all = getRuntimeStats();
assertEquals(1, all.size());
assertEquals(2, all.get(0).getWeight());
}",async wait,0
266,activemq,MemoryLimitTest.testCursorBatch,"@Test
public void testCursorBatch() throws Exception {
ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(""vm://localhost?jms.prefetchPolicy.all=10"");
factory.setOptimizeAcknowledge(true);
Connection conn = factory.createConnection();
conn.start();
Session sess = conn.createSession(false, CLIENT_ACKNOWLEDGE);
Queue queue = sess.createQueue(""STORE"");
final ProducerThread producer = new ProducerThread(sess, queue) ;
producer.setMessageCount(2000);
producer.start();
producer.join();
Thread.sleep(1000);
Destination dest = broker.getDestination(((ActiveMQQueue) (queue)));
LOG.info(""Destination usage: "" + dest.getMemoryUsage());
int percentUsage = dest.getMemoryUsage().getPercentUsage();
assertTrue(""Should be less than 70% of limit but was: "" + percentUsage, percentUsage <= 71);
LOG.info(""Broker usage: "" + broker.getSystemUsage().getMemoryUsage());
assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() <= 71);
MessageConsumer consumer = sess.createConsumer(queue);
Message msg = consumer.receive();
msg.acknowledge();
Thread.sleep(1000);
LOG.info(""Destination usage: "" + dest.getMemoryUsage());
assertTrue(dest.getMemoryUsage().getPercentUsage() >= 478);
LOG.info(""Broker usage: "" + broker.getSystemUsage().getMemoryUsage());
assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() >= 478);
for (int i = 1; i < 2000; i++) {
msg = consumer.receive(1000);
assertNotNull(""Didn't receive message "" + i, msg);
msg.acknowledge();
}
}",async wait,0
267,fastjson,SortFieldTest.test_1,"@Test
public void test_1() throws Exception {
V1 entity = new V1();
String text = JSON.toJSONString(entity, SortField);
System.out.println(text);
Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text);
JSONObject object = JSON.parseObject(text);
text = JSON.toJSONString(object, SortField);
Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text);
}",unordered collections,3
268,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRebind.2,"@Test
public void testRebind() throws Exception {
final Name name = new CompositeName(""test"");
final Object value = new Object();
final Object newValue = new Object();
WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
try {
store.bind(name, value);
store.rebind(name, newValue);
} finally {
WritableServiceBasedNamingStore.popOwner();
}
assertEquals(newValue, store.lookup(name));
}",test order dependency,4
269,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testUnbind,"@Test
public void testUnbind() throws Exception {
final Name name = new CompositeName(""test"");
final Object value = new Object();
namingStore.bind(name, value);
namingContext.unbind(name);
try {
namingStore.lookup(name);
fail(""Should have thrown name not found"");
} catch (NameNotFoundException expect) {}
testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""test"", value);
testActionPermission(JndiPermission.ACTION_UNBIND, namingContext, ""test"");
try {
namingStore.lookup(name);
fail(""Should have thrown name not found"");
} catch (NameNotFoundException expect) {}
}",test order dependency,4
270,activemq,DurableConsumerTest.testConcurrentDurableConsumer,"@Test
public void testConcurrentDurableConsumer() throws Exception {
broker.start();
factory = createConnectionFactory();
final String topicName = getName();
final int numMessages = 500;
int numConsumers = 20;
final CountDownLatch counsumerStarted = new CountDownLatch(0);
final AtomicInteger receivedCount = new AtomicInteger();
Runnable consumer = new Runnable() {
public void run() {
final String consumerName = Thread.currentThread().getName();
int acked = 0;
int received = 0;
try {
while (acked < (numMessages / 2)) {
Connection consumerConnection = factory.createConnection();
((ActiveMQConnection) (consumerConnection)).setWatchTopicAdvisories(false);
consumerConnection.setClientID(consumerName);
Session consumerSession = consumerConnection.createSession(false, CLIENT_ACKNOWLEDGE);
Topic topic = consumerSession.createTopic(topicName);
consumerConnection.start();
MessageConsumer consumer = consumerSession.createDurableSubscriber(topic, consumerName);
counsumerStarted.countDown();
Message msg = null;
do {
msg = consumer.receive(5000);
if (msg != null) {
receivedCount.incrementAndGet();
if (((received++) % 2) == 0) {
msg.acknowledge();
acked++;
}
}
} while (msg == null );
consumerConnection.close();
}
assertTrue(received >= acked);
} catch (Exception e) {
e.printStackTrace();
exceptions.add(e);
}
}
};
ExecutorService executor = Executors.newCachedThreadPool();
for (int i = 0; i < numConsumers; i++) {
executor.execute(consumer);
}
assertTrue(counsumerStarted.await(30, TimeUnit.SECONDS));
Connection producerConnection = factory.createConnection();
((ActiveMQConnection) (producerConnection)).setWatchTopicAdvisories(false);
Session producerSession = producerConnection.createSession(false, AUTO_ACKNOWLEDGE);
Topic topic = producerSession.createTopic(topicName);
MessageProducer producer = producerSession.createProducer(topic);
producerConnection.start();
for (int i = 0; i < numMessages; i++) {
BytesMessage msg = producerSession.createBytesMessage();
msg.writeBytes(payload);
producer.send(msg);
if ((i != 0) && ((i % 100) == 0)) {
LOG.info(""Sent msg "" + i);
}
}
Thread.sleep(2000);
executor.shutdown();
executor.awaitTermination(30, TimeUnit.SECONDS);
assertTrue(""got some messages: "" + receivedCount.get(), receivedCount.get() > numMessages);
assertTrue(""no exceptions, but: "" + exceptions, exceptions.isEmpty());
}",async wait,0
271,RxJava,TestSchedulers.testSchedulingWithDueTime,"@Test
public void testSchedulingWithDueTime() throws InterruptedException {
final CountDownLatch latch = new CountDownLatch(5);
final AtomicInteger counter = new AtomicInteger();
long start = System.currentTimeMillis();
Schedulers.threadPoolForComputation().schedule(null, new Func2<Scheduler, String, Subscription>() {
@Override
public Subscription call(Scheduler scheduler, String state) {
System.out.println(""doing work"");
latch.countDown();
counter.incrementAndGet();
if (latch.getCount() == 0) {
return Subscriptions.empty();
} else {
return scheduler.schedule(state, this, new Date(System.currentTimeMillis() + 50));
}
}
}, new Date(System.currentTimeMillis() + 100));
if (!latch.await(3000, TimeUnit.MILLISECONDS)) {
fail(""didn't execute ... timed out"");
}
long end = System.currentTimeMillis();
assertEquals(5, counter.get());
if ((end - start) < 250) {
fail(""it should have taken over 250ms since each step was scheduled 50ms in the future"");
}
}",concurrency,1
272,continuum,PrepareBuildProjectsTaskExecutorTest.testCheckoutPrepareBuildMultiModuleProject,"@Test
public void testCheckoutPrepareBuildMultiModuleProject() throws Exception {
PrepareBuildProjectsTask task = createTask(""src/test-projects/multi-module/pom.xml"", false, false);
this.prepareBuildQueue.put(task);
List<Project> projects = getProjectDao().getProjectsInGroup(task.getProjectGroupId());
assertEquals(""failed to add all projects"", 3, projects.size());
Project rootProject = getProjectDao().getProjectByName(""multi-module-parent"");
Project moduleA = getProjectDao().getProjectByName(""module-A"");
Project moduleB = getProjectDao().getProjectByName(""module-B"");
while ((!prepareBuildQueue.getQueueSnapshot().isEmpty()) || (prepareBuildTaskQueueExecutor.getCurrentTask() != null)) {
Thread.sleep(10);
}
ProjectScmRoot scmRoot = projectScmRootDao.getProjectScmRoot(task.getProjectScmRootId());
assertEquals(""Failed to update multi-module project"", UPDATED, scmRoot.getState());
File workingDir = configurationService.getWorkingDirectory();
assertTrue(""checkout directory of project 'multi-module-parent' does not exist."", new File(workingDir, Integer.toString(rootProject.getId())).exists());
assertTrue(""checkout directory of project 'module-A' does not exist."", new File(workingDir, Integer.toString(moduleA.getId())).exists());
assertTrue(""checkout directory of project 'module-B' does not exist."", new File(workingDir, Integer.toString(moduleB.getId())).exists());
}",async wait,0
273,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireMultipleLevelEvent,"@Test
public void testFireMultiLevelEvent() throws Exception {
final NamingEventCoordinator coordinator = new NamingEventCoordinator();
final CollectingListener subtreeListener = new CollectingListener(1);
coordinator.addListener(""foo"", EventContext.SUBTREE_SCOPE, subtreeListener);
final CollectingListener subtreeListenerTwo = new CollectingListener(1);
coordinator.addListener(""foo/bar"", EventContext.SUBTREE_SCOPE, subtreeListenerTwo);
final CollectingListener subtreeListenerThree = new CollectingListener(1);
coordinator.addListener(""foo/bar/baz"", EventContext.SUBTREE_SCOPE, subtreeListenerThree);
coordinator.fireEvent(context, new CompositeName(""foo/bar/baz/boo""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);
subtreeListener.latch.await(1, TimeUnit.SECONDS);
subtreeListenerTwo.latch.await(1, TimeUnit.SECONDS);
subtreeListenerThree.latch.await(1, TimeUnit.SECONDS);
assertEquals(1, subtreeListener.capturedEvents.size());
assertEquals(1, subtreeListenerTwo.capturedEvents.size());
assertEquals(1, subtreeListenerThree.capturedEvents.size());
}",test order dependency,4
274,jReddit,KeyValueFormatterTest.testFormatMultipleUTF8,"@Test
public void testFormatMultipleUTF8() {
HashMap<String, String> params = new HashMap<String, String>();
params.put(""a "", ""b, "");
params.put(""c"", ""32626&"");
Assert.assertTrue(""a =b%2C+&c=32626%26"".equals(KeyValueFormatter.format(params, true)) || ""c=32626%26&a =b%2C+"".equals(KeyValueFormatter.format(params, true)));
}",unordered collections,3
275,androidx,testOneTimeRequest_noInitialDelay,"@Test
public void testOneTimeRequest_noInitialDelay() {
val request = OneTimeWorkRequestBuilder<TestWorker>().build();
val task = mTaskConverter.convert(request.workSpec);
assertEquals(task.serviceName, WorkManagerGcmService::class.java.name);
assertEquals(task.isPersisted, false);
assertEquals(task.isUpdateCurrent, true);
assertEquals(task.requiredNetwork, Task.NETWORK_STATE_ANY);
assertEquals(task.requiresCharging, false);
assertEquals(task.windowStart, 0L);
assertEquals(task.windowEnd, 0L + EXECUTION_WINDOW_SIZE_IN_SECONDS);
}",time,2
276,aismessages,7b0c4c708b6bb9a6da3d5737bcad1857ade8a931.canHandleUnfragmentedMessageReceived,"@Test
public void canHandleUnfragmentedMessageReceived() {
NMEAMessage unfragmentedNMEAMessage = NMEAMessage.fromString(""!AIVDM,1,1,,B,15MqdBP000G@qoLEi69PVGaN0D0=,0*3A"");
final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>();
context.checking(new Expectations() {{
oneOf(aisMessageHandler).accept(with(aisMessage.getMatcher()));
}});
aisMessageReceiver.accept(unfragmentedNMEAMessage);
assertEquals(AISMessageType.PositionReportClassAScheduled, aisMessage.getCapturedObject().getMessageType());
}",test order dependency,4
277,androidx,testGettersAfterConnected,"@Test
public void testGettersAfterConnected() throws InterruptedException {
prepareLooper();
final int state = MediaPlayerBase.PLAYER_STATE_PLAYING;
final long position = 150000;
final long bufferedPosition = 900000;
final float speed = 0.5f;
mPlayer.mLastPlayerState = state;
mPlayer.mCurrentPosition = position;
mPlayer.mBufferedPosition = bufferedPosition;
mPlayer.mPlaybackSpeed = speed;
long time = System.currentTimeMillis();
MediaController2 controller = createController(mSession.getToken());
assertEquals(state, controller.getPlayerState());
assertEquals(bufferedPosition, controller.getBufferedPosition());
assertEquals(speed, controller.getPlaybackSpeed());
long elapsedTime = System.currentTimeMillis() - time;
final long tolerance = 10;
assertEquals(position + speed * elapsedTime, controller.getCurrentPosition(), tolerance);
}",time,2
278,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireSubTreeEvent,"@Test
public void testFireSubTreeEvent() throws Exception {
final NamingEventCoordinator coordinator = new NamingEventCoordinator();
final CollectingListener objectListener = new CollectingListener(0);
coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
final CollectingListener subtreeListener = new CollectingListener(1);
coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
final CollectingListener oneLevelListener = new CollectingListener(0);
coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.SUBTREE_SCOPE);
subtreeListener.latch.await(1, TimeUnit.SECONDS);
assertTrue(objectListener.capturedEvents.isEmpty());
assertTrue(oneLevelListener.capturedEvents.isEmpty());
assertEquals(1, subtreeListener.capturedEvents.size());
}",test order dependency,4
279,tomcat,TestWsSubprotocols.testWsSubprotocols,"@Test
public void testWsSubprotocols() throws Exception {
Tomcat tomcat = getTomcatInstance();
Context ctx = tomcat.addContext("""", System.getProperty(""java.io.tmpdir""));
ctx.addApplicationListener(new ApplicationListener(Config.class.getName(), false));
Tomcat.addServlet(ctx, ""default"", new DefaultServlet());
ctx.addServletMapping(""/"", ""default"");
tomcat.start();
WebSocketContainer wsContainer = ContainerProvider.getWebSocketContainer();
tomcat.start();
Session wsSession = wsContainer.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp3"")).build(), new URI((""ws"")));
Assert.assertTrue(wsSession.isOpen());
if (wsSession.getNegotiatedSubprotocol() != null) {
Assert.assertTrue(wsSession.getNegotiatedSubprotocol().isEmpty());
}
wsSession.close();
wsSession = wsContainer.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp2"")).build(), new URI((""ws"")));
Assert.assertTrue(wsSession.isOpen());
Assert.assertEquals(""sp2"", wsSession.getNegotiatedSubprotocol());
Assert.assertArrayEquals(new String[]{ ""sp1"", ""sp2"" }, SubProtocolsEndpoint.subprotocols.toArray(new String[2]));
wsSession.close();
}",async wait,0
280,maven-dependency-plugin,TestUnpackMojo.testUnpackOverWriteIfNewer,"@Test
public void testUnpackOverWriteIfNewer() throws Exception {
final long now = System.currentTimeMillis();
mojo.setSilent( false );
stubFactory.setCreateFiles( true );
Artifact artifact = stubFactory.getSnapshotArtifact();
assertTrue( artifact.getFile().setLastModified( now - 20000 ) );
ArtifactItem item = new ArtifactItem( createArtifact( artifact ) );
List<ArtifactItem> list = Collections.singletonList( item );
mojo.setArtifactItems( list );
mojo.setOverWriteIfNewer( true );
mojo.execute();
File unpackedFile = getUnpackedFile( item );
long time = now;
time = time - ( time % 1000 );
time -= 10000;
assertTrue( unpackedFile.setLastModified( time ) );
assertTrue( artifact.getFile().setLastModified( time + 5000 ) );
File marker = new File( mojo.getMarkersDirectory(), artifact.getId().replace( ':', '-' ) + "".marker"" );
assertTrue( marker.setLastModified( time ) );
displayFile( ""unpackedFile"", unpackedFile );
displayFile( ""artifact    "", artifact.getFile() );
displayFile( ""marker      "", marker );
System.out.println( ""mojo.execute()"" );
mojo.execute();
displayFile( ""unpackedFile"", unpackedFile );
displayFile( ""artifact    "", artifact.getFile() );
displayFile( ""marker      "", marker );
System.out.println( ""marker.lastModified() = "" + marker.lastModified() );
System.out.println( ""unpackedFile.lastModified() = "" + unpackedFile.lastModified() );
assertTrue( ""unpackedFile '"" + unpackedFile + ""' lastModified() == "" + marker.lastModified()
+ "": should be different"", marker.lastModified() != unpackedFile.lastModified() );
}",time,2
281,soot,TestDominance.TestSimpleDiamond,"@Test
public void TestSimpleDiamond() {
Node x = new Node(4);
Node n = new Node(1).addkid(new Node(2).addkid(x)).addkid(new Node(3).addkid(x));
Graph g = new Graph(n);
MHGDominatorsFinder<Node> finder = new MHGDominatorsFinder<Node>(g);
DominatorTree<Node> tree = new DominatorTree<Node>(finder);
assertThat(tree.getHeads().size(), is(1));
DominatorNode<Node> head = tree.getHeads().get(0);
assertThat(head.getGode().id, is(1));
Set<Integer> kids = kid_ids(head);
assertThat(kids.size(), is(3));
assertThat(kids, contains(2, 3, 4));
}",unordered collections,3
282,shardingsphere-elasticjob,b022898ef1b8c984e17efb2a422ee45f6b13e46e.assertIsShutdownAlready,"@Test
public void assertIsShutdownAlready() {
shutdownListenerManager.new InstanceShutdownStatusJobListener().dataChanged(""/test_job/instances/127.0.0.1@-@0"", Type.NODE_REMOVED, """");
verify(schedulerFacade, times(0)).shutdownInstance();
}",test order dependency,4
283,ecchronos,TestRepairTask.testPartialRepair,"@Test
public void testPartialRepair() throws InterruptedException {
Collection<LongTokenRange> ranges = new ArrayList<>();
LongTokenRange range1 = new LongTokenRange(1, 2);
LongTokenRange range2 = new LongTokenRange(3, 4);
ranges.add(range1);
ranges.add(range2);
final RepairTask repairTask = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(ranges).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build();
CountDownLatch cdl = startRepair(repairTask, false);
Notification notification = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(range1));
notification.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2));
proxy.notify(notification);
notification = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(range2));
notification.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2));
proxy.notify(notification);
notification = new Notification(""progress"", ""repair:1"", 2, ""Done with repair"");
notification.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2));
proxy.notify(notification);
cdl.await();
assertThat(repairTask.getUnknownRanges()).isNull();
assertThat(repairTask.getCompletedRanges()).containsExactlyElementsOf(ranges);
assertThat(proxy.myOptions.get(RANGES_KEY)).isNotEmpty();
verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true));
verify(repairSessions.get(range1)).start();
verify(repairSessions.get(range2)).start();
verify(repairSessions.get(range1)).finish(eq(SUCCESS));
verify(repairSessions.get(range2)).finish(eq(SUCCESS));
}",unordered collections,3
284,cassandra,testWithMismatchingPending,"@Test
public void testWithMismatchingPending() throws Throwable
{
try(Cluster cluster = init(Cluster.build(2).withConfig(config -> config.with(GOSSIP).with(NETWORK)).start()))
{
cluster.schemaChange(""create table "" + KEYSPACE + "".tbl (id int primary key, t int)"");
insert(cluster.coordinator(1), 0, 100);
cluster.forEach((node) -> node.flush(KEYSPACE));
cluster.get(1).callOnInstance(repair(options(false)));
insert(cluster.coordinator(1), 100, 100);
cluster.forEach((node) -> node.flush(KEYSPACE));
cluster.forEach((node) -> node.runOnInstance(() -> {
ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl"");
FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(cfs));
cfs.disableAutoCompaction();
}));
cluster.get(1).callOnInstance(repair(options(false)));
cluster.get(1).runOnInstance(() -> {
ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl"");
cfs.enableAutoCompaction();
FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(cfs));
});
RepairResult rs = cluster.get(1).callOnInstance(repair(options(true)));
assertTrue(rs.success);
assertFalse(rs.wasInconsistent);
}
}",concurrency,1
285,neo4j,shouldBuildUpGracefullyUntilReachedMinPoolSize,"@Test
public void shouldBuildUpGracefullyUntilReachedMinPoolSize() throws InterruptedException
{
StatefulMonitor stateMonitor = new StatefulMonitor();
FakeClock clock = new FakeClock();
final LinkedQueuePool<Object> pool = getLinkedQueuePool( stateMonitor, clock, 5 );
ExecutorService executor = Executors.newCachedThreadPool();
List<FlyweightHolder<Object>> flyweightHolders = acquireFromPool( pool, 5, executor );
executor.shutdown();
for ( FlyweightHolder<Object> flyweightHolder : flyweightHolders )
{
flyweightHolder.release();
}
executor.awaitTermination( 10, TimeUnit.SECONDS );
assertEquals( -1, stateMonitor.currentPeakSize.get() );
assertEquals( -1, stateMonitor.targetSize.get() );
assertEquals( 0, stateMonitor.disposed.get() );
}",concurrency,1
286,spring-data-keyvalue,scanShouldIterateOverAvailableEntries,"@Test
void scanShouldIterateOverAvailableEntries() {
adapter.put(""1"", object1, COLLECTION_1);
adapter.put(""2"", object2, COLLECTION_1);
CloseableIterator<Map.Entry<Object, Object>> iterator = adapter.entries(COLLECTION_1);
assertThat(iterator.next()).isEqualTo(new AbstractMap.SimpleEntry<>(""1"", object1));
assertThat(iterator.next()).isEqualTo(new AbstractMap.SimpleEntry<>(""2"", object2));
Map.Entry<Object, Object> entry1 = iterator.next();
Map.Entry<Object, Object> entry2 = iterator.next();
assertThat(iterator.hasNext()).isFalse();
}",unordered collections,3
287,commons-lang,RecursiveToStringStyleTest.testPerson,"@Test
public void testPerson() {
final Person p = new Person();
p.name = ""John Doe"";
p.age = 33;
p.smoker = false;
p.job = new Job();
p.job.title = ""Manager"";
final String pBaseStr = (p.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(p));
final String pJobStr = (p.job.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(p.job));
assertEquals(((pBaseStr + ""[name=John Doe,age=33,smoker=false,job="") + pJobStr) + ""[title=Manager]]"", new ReflectionToStringBuilder(p, new RecursiveToStringStyle()).toString());
}",unordered collections,3
288,pulsar,MessageIdTest.producerSendAsync,"@Test
@Test(timeOut = 10000)
public void producerSendAsync() throws PulsarClientException {
String key = ""producerSendAsync"";
final String topicName = ""persistent://prop/cluster/namespace/topic-"" + key;
final String subscriptionName = ""my-subscription-"" + key;
final String messagePredicate = ""my-message-"" + key + ""-"";
final int numberOfMessages = 30;
Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName)
.enableBatching(false)
.messageRoutingMode(MessageRoutingMode.SinglePartition)
.create();
Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(topicName).subscriptionName(subscriptionName)
.subscribe();
Set<MessageId> messageIds = new HashSet<>();
List<Future<MessageId>> futures = new ArrayList<>();
for (int i = 0; i < numberOfMessages; i++) {
String message = messagePredicate + i;
futures.add(producer.sendAsync(message.getBytes()));
}
MessageIdImpl previousMessageId = null;
for (Future<MessageId> f : futures) {
try {
MessageIdImpl currentMessageId = (MessageIdImpl) f.get();
if (previousMessageId != null) {
Assert.assertTrue(currentMessageId.compareTo(previousMessageId) > 0,
""Message Ids should be in ascending order"");
}
messageIds.add(currentMessageId);
previousMessageId = currentMessageId;
} catch (Exception e) {
Assert.fail(""Failed to publish message, Exception: "" + e.getMessage());
}
}
log.info(""Message IDs = "" + messageIds);
Assert.assertEquals(messageIds.size(), numberOfMessages, ""Not all messages published successfully"");
for (int i = 0; i < numberOfMessages; i++) {
Message<byte[]> message = consumer.receive();
Assert.assertEquals(new String(message.getData()), messagePredicate + i);
MessageId messageId = message.getMessageId();
Assert.assertTrue(messageIds.remove(messageId), ""Failed to receive message"");
}
log.info(""Message IDs = "" + messageIds);
Assert.assertEquals(messageIds.size(), 0, ""Not all messages received successfully"");
consumer.unsubscribe();
}",async wait,0
289,OpenSearch,testListenerFailures,"@Test
public void testListenerFailures() throws InterruptedException {
int iters = iterations(10, 100);
for (int i = 0; i < iters; i++) {
try (TestIteration iteration = new TestIteration()) {
iteration.transport.endConnectMode();
final CountDownLatch latch = new CountDownLatch(1);
final AtomicInteger finalFailures = new AtomicInteger();
final AtomicReference<Throwable> finalFailure = new AtomicReference<>();
final AtomicReference<TestResponse> response = new AtomicReference<>();
ActionListener<TestResponse> actionListener = new ActionListener<TestResponse>();
final AtomicInteger preSendFailures = new AtomicInteger();
iteration.transportClientNodesService.execute((node, retryListener) -> {
if (rarely()) {
preSendFailures.incrementAndGet();
throw new IllegalArgumentException();
}
iteration.transportService.sendRequest(node, ""action"", new TestRequest(),
TransportRequestOptions.EMPTY, new TransportResponseHandler<TestResponse>() {
}, actionListener);
assertThat(latch.await(1, TimeUnit.SECONDS), equalTo(true));
assertThat(preSendFailures.get() + iteration.transport.failures() + iteration.transport.successes(), lessThanOrEqualTo(1));
if (iteration.transport.successes() == 1) {
assertThat(finalFailures.get(), equalTo(0));
assertThat(finalFailure.get(), nullValue());
assertThat(response.get(), notNullValue());
} else {
assertThat(finalFailures.get(), equalTo(1));
assertThat(finalFailure.get(), notNullValue());
assertThat(response.get(), nullValue());
if (preSendFailures.get() == 0 && iteration.transport.failures() == 0) {
assertThat(finalFailure.get(), instanceOf(NoNodeAvailableException.class));
}
}
assertThat(iteration.transport.triedNodes().size(), lessThanOrEqualTo(iteration.listNodesCount));
assertThat(iteration.transport.triedNodes().size(), equalTo(iteration.transport.connectTransportExceptions() + iteration.transport.failures() + iteration.transport.successes()));
});
}
}
}",async wait,0
290,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindingsNameNotFound,"@Test
public void testListBindingsNameNotFound() throws Exception {
try {
namingContext.listBindings(new CompositeName(""test""));
fail(""Should have thrown and NameNotFoundException"");
} catch (NameNotFoundException expected) {
}
try {
testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, ""test"");
fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
} catch (NameNotFoundException expected) {
}
}",test order dependency,4
291,trino,testAuthenticationFromMultipleThreadsWithCachedToken,"@Test
public void testAuthenticationFromMultipleThreadsWithCachedToken()
{
ExecutorService executor = newCachedThreadPool(daemonThreadsNamed(this.getClass().getName() + ""%n""));
MockTokenPoller tokenPoller = new MockTokenPoller()
.withResult(URI.create(""http://token.uri""), successful(new Token(""valid-token"")));
MockRedirectHandler redirectHandler = new MockRedirectHandler()
.sleepOnRedirect(Duration.ofMillis(10));
ExternalAuthenticator authenticator = new ExternalAuthenticator(redirectHandler, tokenPoller, KnownToken.memoryCached(), Duration.ofSeconds(1));
List<Future<Request>> requests = times(
4, () -> authenticator.authenticate(null, getUnauthorizedResponse(""Bearer x_token_server=\""http://token.uri\"", x_redirect_server=\""http://redirect.uri\"""")))
.map(executor::submit)
.collect(toImmutableList());
ConcurrentRequestAssertion assertion = new ConcurrentRequestAssertion(requests);
assertion.requests()
.extracting(Request::headers)
.extracting(headers -> headers.get(AUTHORIZATION))
.containsOnly(""Bearer valid-token"");
assertion.assertThatNoExceptionsHasBeenThrown();
assertThat(redirectHandler.getRedirectionCount()).isEqualTo(1);
}",concurrency,1
292,alluxio,journalBlockCreation,"@Test
public void journalBlockCreation() throws Exception {
FileSystem fs = mCluster.getClient();
BlockMaster blockMaster =
mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class);
AlluxioURI file = new AlluxioURI(""/test"");
FileSystemTestUtils.createByteFile(fs, file, WritePType.MUST_CACHE, 10);
URIStatus status = fs.getStatus(file);
Long blockId = status.getBlockIds().get(0);
assertNotNull(blockMaster.getBlockInfo(blockId));
mCluster.stopMasters();
mCluster.startMasters();
AlluxioMasterProcess masterProcess = mCluster.getLocalAlluxioMaster().getMasterProcess();
assertNotNull(masterProcess.getMaster(BlockMaster.class).getBlockInfo(blockId));
}",async wait,0
293,neo4j,schema.IndexPopulationIT.shutdownDatabaseDuringIndexPopulations,"@Test
public void shutdownDatabaseDuringIndexPopulations() {
AssertableLogProvider assertableLogProvider = new AssertableLogProvider(true);
File storeDir = directory.directory(""shutdownDbTest"");
Label testLabel = Label.label(""testLabel"");
String propertyName = ""testProperty"";
GraphDatabaseService shutDownDb = new TestGraphDatabaseFactory().setInternalLogProvider(assertableLogProvider).newEmbeddedDatabase(storeDir);
prePopulateDatabase(shutDownDb, testLabel, propertyName);
try (final Transaction transaction = shutDownDb.beginTx()) {
shutDownDb.schema().indexFor(testLabel).on(propertyName).create();
transaction.success();
}
shutDownDb.shutdown();
assertableLogProvider.assertNone(AssertableLogProvider.inLog(IndexPopulationJob.class).anyError());
}",concurrency,1
294,realm-java,executeTransactionAsync_callbacksShouldBeClearedBeforeCalling,"@Test
public void executeTransactionAsync_callbacksShouldBeClearedBeforeCalling() {
final AtomicInteger callbackCounter = new AtomicInteger(0);
final Realm foregroundRealm = looperThread.getRealm();
foregroundRealm.setAutoRefresh(false);
foregroundRealm.executeTransactionAsync(new Realm.Transaction() {
@Override
public void execute(Realm realm) {
realm.createObject(AllTypes.class);
}
}, new Realm.Transaction.OnSuccess() {
@Override
public void onSuccess() {
assertEquals(0, callbackCounter.getAndIncrement());
foregroundRealm.beginTransaction();
foregroundRealm.createObject(AllTypes.class);
foregroundRealm.commitTransaction();
}
});
foregroundRealm.executeTransactionAsync(new Realm.Transaction() {
@Override
public void execute(Realm realm) {
realm.createObject(AllTypes.class);
looperThread.postRunnableDelayed(new Runnable() {
@Override
public void run() {
foregroundRealm.sharedRealm.refresh();
foregroundRealm.setAutoRefresh(true);
}
}, 50);
}
}, new Realm.Transaction.OnSuccess() {
@Override
public void onSuccess() {
assertEquals(1, callbackCounter.getAndIncrement());
looperThread.testComplete();
}
});
}",async wait,0
295,hbase,TestGzipFilter.testScannerResultCodes,"@Test
public void testScannerResultCodes() throws Exception {
Header[] headers = new Header[3];
headers[0] = new Header(""Content-Type"", Constants.MIMETYPE_XML);
headers[1] = new Header(""Accept"", Constants.MIMETYPE_JSON);
headers[2] = new Header(""Accept-Encoding"", ""gzip"");
Response response = client.post((""/"" + TABLE) + ""/scanner"", headers, ""<Scanner/>"".getBytes());
assertEquals(response.getCode(), 201);
String scannerUrl = response.getLocation();
assertNotNull(scannerUrl);
response = client.get(scannerUrl);
assertEquals(response.getCode(), 200);
response = client.get(scannerUrl);
assertEquals(response.getCode(), 204);
}",test order dependency,4
296,pulsar,MessageIdTest.testChecksumReconnection,"@Test
public void testChecksumReconnection() throws Exception {
final String topicName = ""persistent"";
ProducerImpl<byte[]> prod = ((ProducerImpl<byte[]>) (pulsarClient.newProducer().topic(topicName).enableBatching(false).messageRoutingMode(SinglePartition).create()));
ProducerImpl<byte[]> producer = spy(prod);
doReturn(producer.brokerChecksumSupportedVersion() + 1).when(producer).brokerChecksumSupportedVersion();
doAnswer(( invocationOnMock) -> prod.getState()).when(producer).getState();
doAnswer(( invocationOnMock) -> prod.getClientCnx()).when(producer).getClientCnx();
doAnswer(( invocationOnMock) -> prod.cnx()).when(producer).cnx();
Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(topicName).subscriptionName(""my-sub"").subscribe();
stopBroker();
((PulsarClientImpl) (pulsarClient)).timer().stop();
ClientCnx mockClientCnx = spy(new ClientCnx(new ClientConfigurationData(), ((PulsarClientImpl) (pulsarClient)).eventLoopGroup()));
doReturn(producer.brokerChecksumSupportedVersion() - 1).when(mockClientCnx).getRemoteEndpointProtocolVersion();
prod.setClientCnx(mockClientCnx);
CompletableFuture<MessageId> future1 = producer.sendAsync(""message-1"".getBytes());
byte[] a2 = ""message-2"".getBytes();
TypedMessageBuilder<byte[]> msg2 = producer.newMessage().value(a2);
CompletableFuture<MessageId> future2 = msg2.sendAsync();
((TypedMessageBuilderImpl<byte[]>) (msg2)).getContent().put(a2.length - 1, ((byte) ('3')));
prod.setClientCnx(null);
startBroker();
prod.grabCnx();
try {
future1.get(10, TimeUnit.SECONDS);
future2.get(10, TimeUnit.SECONDS);
} catch (Exception e) {
e.printStackTrace();
fail(""Broker shouldn't verify checksum for corrupted message and it shouldn't fail"");
}
((ConsumerImpl<byte[]>) (consumer)).grabCnx();
Message<byte[]> msg = consumer.receive(1, TimeUnit.SECONDS);
assertEquals(new String(msg.getData()), ""message-1"");
msg = consumer.receive(1, TimeUnit.SECONDS);
assertEquals(new String(msg.getData()), ""message-3"");
}",async wait,0
297,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRegisterURLSchemeHandler,"@Test
public void testRegisterURLSchemeHandler() throws Exception {
InitialContext ictx = new InitialContext(null);
try {
ictx.lookup(""foobar:something"");
Assert.fail(""Precondition: the foobar: scheme should not yet be registered"");
} catch (NamingException ne) {
}
ObjectFactory tof = new TestObjectFactory();
InitialContext.addUrlContextFactory(""foobar"", tof);
String something = (String) ictx.lookup(""foobar:something"");
Assert.assertTrue(""The object should now be provided by our TestObjectFactory"", something.startsWith(""TestObject:""));
try {
InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory());
Assert.fail(""Should throw an IllegalArgumentException since the associated factory object doesn't match the registration"");
} catch (IllegalArgumentException iae) {
}
Assert.assertEquals(""The foobar: scheme should still be registered"", something, ictx.lookup(""foobar:something""));
InitialContext.removeUrlContextFactory(""foobar"", tof);
try {
ictx.lookup(""foobar:something"");
Assert.fail(""The foobar: scheme should not be registered any more"");
} catch (NamingException ne) {
}
}",test order dependency,4
298,hbase,TestMasterWrongRS.testRsReportsWrongServerName,"@Test
public void testRsReportsWrongServerName() throws Exception {
MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster();
MiniHBaseClusterRegionServer firstServer = ((MiniHBaseClusterRegionServer) (cluster.getRegionServer(0)));
HRegionServer secondServer = cluster.getRegionServer(1);
HServerInfo hsi = firstServer.getServerInfo();
firstServer.setHServerInfo(new HServerInfo(hsi.getServerAddress(), hsi.getInfoPort(), hsi.getHostname()));
Thread.sleep(2000);
assertTrue(firstServer.isOnline());
assertEquals(2, cluster.getLiveRegionServerThreads().size());
secondServer.getHServerInfo().setServerAddress(new HServerAddress(""0.0.0.0"", 60010));
Thread.sleep(2000);
assertTrue(secondServer.isOnline());
assertEquals(1, cluster.getLiveRegionServerThreads().size());
}",async wait,0
299,hbase,TestFromClientSide.testRegionCachePreWarm,"@Test
public void testRegionCachePreWarm() throws Exception {
final byte[] TABLENAME = Bytes.toBytes(""testCachePrewarm"");
Configuration conf = TEST_UTIL.getConfiguration();
TEST_UTIL.createTable(TABLENAME, FAMILY);
HTable.setRegionCachePrefetch(conf, TABLENAME, false);
assertFalse(""The table is disabled for region cache prefetch"", HTable.getRegionCachePrefetch(conf, TABLENAME));
HTable table = new HTable(conf, TABLENAME);
TEST_UTIL.createMultiRegions(table, FAMILY);
Get g = new Get(Bytes.toBytes(""aaa""));
table.get(g);
assertEquals(""Number of cached region is incorrect "", 1, HConnectionManager.getCachedRegionCount(conf, TABLENAME));
HTable.setRegionCachePrefetch(conf, TABLENAME, true);
assertTrue(""The table is enabled for region cache prefetch"", HTable.getRegionCachePrefetch(conf, TABLENAME));
HTable.setRegionCachePrefetch(conf, TABLENAME, false);
assertFalse(""The table is disabled for region cache prefetch"", HTable.getRegionCachePrefetch(conf, TABLENAME));
HTable.setRegionCachePrefetch(conf, TABLENAME, true);
assertTrue(""The table is enabled for region cache prefetch"", HTable.getRegionCachePrefetch(conf, TABLENAME));
table.getConnection().clearRegionCache();
assertEquals(""Number of cached region is incorrect "", 0, HConnectionManager.getCachedRegionCount(conf, TABLENAME));
Get g2 = new Get(Bytes.toBytes(""bbb""));
table.get(g2);
int prefetchRegionNumber = conf.getInt(""hbase.client.prefetch.limit"", 10) / 2;
LOG.info(""Testing how many regions cached"");
assertTrue(prefetchRegionNumber < HConnectionManager.getCachedRegionCount(conf, TABLENAME));
table.getConnection().clearRegionCache();
Get g3 = new Get(Bytes.toBytes(""abc""));
table.get(g3);
assertTrue(prefetchRegionNumber < HConnectionManager.getCachedRegionCount(conf, TABLENAME));
}",async wait,0
300,mina,VmPipeEventOrderTest.testSessionCreated,"@Test
public void testSessionCreated() throws Exception {
final Semaphore semaphore = new Semaphore(0);
final StringBuffer stringBuffer = new StringBuffer();
VmPipeAcceptor vmPipeAcceptor = new VmPipeAcceptor();
final VmPipeAddress vmPipeAddress = new VmPipeAddress(12345);
vmPipeAcceptor.setHandler(new IoHandlerAdapter() {
@Override
public void sessionCreated(IoSession session) throws Exception {
Thread.sleep(1000);
stringBuffer.append(""A"");
}
@Override
public void sessionOpened(IoSession session) throws Exception {
stringBuffer.append(""B"");
}
@Override
public void messageReceived(IoSession session, Object message) throws Exception {
stringBuffer.append(""C"");
}
@Override
public void sessionClosed(IoSession session) throws Exception {
stringBuffer.append(""D"");
semaphore.release();
}
});
vmPipeAcceptor.bind(vmPipeAddress);
final VmPipeConnector vmPipeConnector = new VmPipeConnector();
vmPipeConnector.getFilterChain().addLast(""executor"", new ExecutorFilter());
vmPipeConnector.setHandler(new IoHandlerAdapter() {
@Override
public void sessionOpened(IoSession session) throws Exception {
session.write(IoBuffer.wrap(new byte[1]));
}
});
ConnectFuture connectFuture = vmPipeConnector.connect(vmPipeAddress);
connectFuture.awaitUninterruptibly();
connectFuture.getSession().close();
semaphore.tryAcquire(1, TimeUnit.SECONDS);
vmPipeAcceptor.unbind(vmPipeAddress);
Assert.assertEquals(""ABCD"", stringBuffer.toString());
}",concurrency,1
301,hadoop,TestFairScheduler.testContinuousScheduling,"@Test
public void testContinuousScheduling() throws Exception {
FairScheduler fs = new FairScheduler();
Configuration conf = createConfiguration();
conf.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true);
fs.reinitialize(conf, resourceManager.getRMContext());
Assert.assertTrue(""Continuous scheduling should be enabled."", fs.isContinuousSchedulingEnabled());
RMNode node1 = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""127.0.0.1"");
NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
fs.handle(nodeEvent1);
Assert.assertEquals(fs.getClusterCapacity().getMemory(), 8 * 1024);
Assert.assertEquals(fs.getClusterCapacity().getVirtualCores(), 8);
ApplicationAttemptId appAttemptId = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++);
fs.addApplication(appAttemptId, ""queue11"", ""user11"");
List<ResourceRequest> ask = new ArrayList<ResourceRequest>();
ResourceRequest request = createResourceRequest(1024, 1, ANY, 1, 1, true);
ask.add(request);
fs.allocate(appAttemptId, ask, new ArrayList<ContainerId>(), null, null);
Thread.sleep(fs.getConf().getContinuousSchedulingSleepMs() + 500);
Resource consumption = fs.applications.get(appAttemptId).getCurrentConsumption();
Assert.assertEquals(1024, consumption.getMemory());
Assert.assertEquals(1, consumption.getVirtualCores());
}",async wait,0
302,hbase,TestZooKeeperScanPolicyObserver.testScanPolicyObserver,"@Test
public void testScanPolicyObserver() throws Exception {
byte[] tableName = Bytes.toBytes(""testScanPolicyObserver"");
HTableDescriptor desc = new HTableDescriptor(tableName);
HColumnDescriptor hcd = new HColumnDescriptor(F).setMaxVersions(10).setTimeToLive(1);
desc.addFamily(hcd);
TEST_UTIL.getHBaseAdmin().createTable(desc);
HTable t = new HTable(new Configuration(TEST_UTIL.getConfiguration()), tableName);
long now = EnvironmentEdgeManager.currentTimeMillis();
ZooKeeperWatcher zkw = HConnectionManager.getConnection(TEST_UTIL.getConfiguration()).getZooKeeperWatcher();
ZooKeeper zk = zkw.getRecoverableZooKeeper().getZooKeeper();
ZKUtil.createWithParents(zkw, node);
zk.setData(node, Bytes.toBytes(now - (3600 * 1000)), -1);
LOG.debug(""Set time: "" + Bytes.toLong(Bytes.toBytes(now - (3600 * 1000))));
long ts = now - 2000;
Put p = new Put(R);
p.add(F, Q, ts, Q);
t.put(p);
p = new Put(R);
p.add(F, Q, ts + 1, Q);
t.put(p);
Get g = new Get(R);
g.setMaxVersions(10);
Result r = t.get(g);
assertEquals(2, r.size());
TEST_UTIL.flush(tableName);
TEST_UTIL.compact(tableName, true);
g = new Get(R);
g.setMaxVersions(10);
r = t.get(g);
assertEquals(2, r.size());
zk.setData(node, Bytes.toBytes(now), -1);
LOG.debug(""Set time: "" + now);
TEST_UTIL.compact(tableName, true);
g = new Get(R);
g.setMaxVersions(10);
r = t.get(g);
assertEquals(0, r.size());
t.close();
}",async wait,0
303,graylog2-server,ContentPackTest.shouldDeserializeSerializedContentPack,"@Test
public void shouldDeserializeSerializedContentPack() throws Exception {
final ContentPack contentPack = createTestContentPack();
final URL contentPackURL = ContentPackTest.class.getResource(""expected_content_pack.json"");
Path path = Paths.get(contentPackURL.toURI());
String expectedJSON = String.join("""", Files.readAllLines(path)).replace(""\n"", """").replace(""\r"", """");
final String jsonTxt = objectMapper.writeValueAsString(contentPack);
assertThat(jsonTxt).isEqualTo(expectedJSON);
final ContentPack readContentPack = objectMapper.readValue(jsonTxt, ContentPack.class);
assertThat(readContentPack.id()).isEqualTo(contentPack.id());
assertThat(readContentPack.version()).isEqualTo(contentPack.version());
assertThat(readContentPack.revision()).isEqualTo(contentPack.revision());
}",unordered collections,3
304,tuscany,ScopeAnnotationTestCase.atScope1,"@Test
public void atScope1() throws Exception {
System.out.println(""atScope1"");
BThread b1 = new BThread(""ThreadB1"");
BThread b2 = new BThread(""ThreadB2"");
CThread c1 = new CThread(""ThreadC1"");
CThread c2 = new CThread(""ThreadC2"");
b1.start();
b2.start();
c1.start();
c2.start();
b1.join();
b2.join();
c1.join();
c2.join();
Assert.assertEquals(""None"", b1.failedReason);
Assert.assertEquals(""None"", b2.failedReason);
Assert.assertEquals(""None"", c1.failedReason);
Assert.assertEquals(""None"", c2.failedReason);
}",concurrency,1
305,ignite,IgnitePdsThreadInterruptionTest.testInterruptsOnLFSRead,"@Test
public void testInterruptsOnLFSRead() throws Exception {
final Ignite ignite = startGrid();
ignite.active(true);
final int valLen = 8192;
final byte[] payload = new byte[valLen];
final int maxKey = 10000;
Thread[] workers = new Thread[THREADS_CNT];
final IgniteCache<Object, Object> cache = ignite.cache(CACHE_NAME);
for (int i = 0; i < maxKey; i++) {
cache.put(i, payload);
}
final AtomicReference<Throwable> fail = new AtomicReference<>();
Runnable clo = new Runnable() {
@Override
public void run() {
cache.get(ThreadLocalRandom.current().nextInt(maxKey / 5));
}
};
for (int i = 0; i < workers.length; i++) {
workers[i] = new Thread(clo);
workers[i].setName(""reader-"" + i);
workers[i].setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
@Override
public void uncaughtException(Thread t, Throwable e) {
fail.compareAndSet(null, e);
}
});
}
for (Thread worker : workers) {
worker.start();
}
for (int i = 0; i < (workers.length / 2); i++) {
workers[i].interrupt();
}
Thread.sleep(3000);
stop = true;
for (Thread worker : workers) {
worker.join();
}
Throwable t = fail.get();
assertNull(t);
int verifiedKeys = 0;
for (int i = 0; i < maxKey; i++) {
byte[] val = ((byte[]) (cache.get(i)));
if (val != null) {
assertEquals(""Illegal length"", valLen, val.length);
verifiedKeys++;
}
}
}",concurrency,1
306,pulsar,shouldTerminateWhenFutureIsCancelled,"@Test
public void shouldTerminateWhenFutureIsCancelled() throws InterruptedException {
GracefulExecutorServicesShutdown shutdown = GracefulExecutorServicesShutdown.initiate();
shutdown.timeout(Duration.ofMillis(15000));
ExecutorService executorService = mock(ExecutorService.class);
when(executorService.isShutdown()).thenReturn(true);
AtomicBoolean terminated = new AtomicBoolean();
AtomicBoolean awaitTerminationInterrupted = new AtomicBoolean();
when(executorService.isTerminated()).thenAnswer(invocation -> terminated.get());
when(executorService.awaitTermination(anyLong(), any())).thenAnswer(invocation  -> {
long timeout = invocation.getArgument(0);
TimeUnit unit = invocation.getArgument(1);
try {
Thread.sleep(unit.toMillis(timeout));
} catch (InterruptedException e) {
awaitTerminationInterrupted.set(true);
Thread.currentThread().interrupt();
throw e;
}
throw new IllegalStateException(""Thread.sleep should have been interrupted"");
});
when(executorService.shutdownNow()).thenAnswer(invocation -> {
terminated.set(true);
return null;
});
shutdown.shutdown(executorService);
CompletableFuture<Void> future = shutdown.handle();
future.cancel(false);
Awaitility.await().untilAsserted(() -> assertTrue(awaitTerminationInterrupted.get(),
""awaitTermination should have been interrupted""));
verify(executorService, times(1)).awaitTermination(anyLong(), any());
verify(executorService, times(1)).shutdownNow();
}",concurrency,1
307,cxf,AnyTest.returnAny1,"@Test
private Void returnAny1(Context context) {
Notifier notifier = testUtilities.rhinoCallConvert(""testAny1ToClientChalk"", Notifier.class, testUtilities.javaToJS(getAddress()));
boolean notified = notifier.waitForJavascript(1000 * 10);
assertTrue(notified);
Integer errorStatus = testUtilities.rhinoEvaluateConvert(""globalErrorStatus"", Integer.class);
assertNull(errorStatus);
String errorText = testUtilities.rhinoEvaluateConvert(""globalErrorStatusText"", String.class);
assertNull(errorText);
String chalk = ((String) (testUtilities.rhinoEvaluate(""globalResponseObject._any.object._chalk"")));
assertEquals(""dover"", chalk);
return null;
}",async wait,0
308,camel,FtpReconnectAttemptServerStoppedIT.testFromFileToFtp,"@Test
public void testFromFileToFtp() throws Exception {
service.suspend();
template.sendBodyAndHeader(""file:{{ftp.root.dir}}/reconnect"", ""Hello World"", FILE_NAME, ""hello.txt"");
MockEndpoint mock = getMockEndpoint(""mock:result"");
mock.expectedMessageCount(0);
Thread.sleep(3000);
assertMockEndpointsSatisfied();
mock.reset();
mock.expectedMessageCount(1);
service.resume();
Thread.sleep(3000);
assertMockEndpointsSatisfied();
}",async wait,0
309,kafka,testForceMetadataRefreshForPatternSubscriptionDuringRebalance,"@Test
public void testForceMetadataRefreshForPatternSubscriptionDuringRebalance() {
final String consumerId = ""consumer"";
subscriptions.subscribe(Pattern.compile("".*""), rebalanceListener);
client.updateMetadata(TestUtils.metadataUpdateWith(1, singletonMap(topic1, 1)));
assertEquals(singleton(topic1), subscriptions.subscription());
client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE));
client.prepareMetadataUpdate(metadataResponse);
client.prepareResponse(joinGroupFollowerResponse(1, consumerId, ""leader"", Errors.NONE));
client.prepareResponse(new MockClient.RequestMatcher() {
@Override
public boolean matches(AbstractRequest body) {
SyncGroupRequest sync = (SyncGroupRequest) body;
return sync.memberId().equals(consumerId) &&
sync.generationId() == 1 &&
sync.groupAssignment().isEmpty();
}
}, syncGroupResponse(singletonList(t1p), Errors.NONE));
partitionAssignor.prepare(singletonMap(consumerId, singletonList(t1p)));
coordinator.poll(time.timer(Long.MAX_VALUE));
final Set<String> updatedSubscriptionSet = new HashSet<>(Arrays.asList(topic1, topic2));
assertEquals(updatedSubscriptionSet, subscriptions.subscription());
metadata.requestUpdate();
client.poll(Long.MAX_VALUE, time.milliseconds());
assertFalse(coordinator.rejoinNeededOrPending());
}",concurrency,1
310,cassandra,testTrackMetadata_rowMarkerDelete,"@Test
public void testTrackMetadata_rowMarkerDelete() throws Throwable
{
createTable(""CREATE TABLE %s (a int, PRIMARY KEY (a))"");
ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable());
execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a=1"");
cfs.forceBlockingFlush();
assertEquals(1, cfs.getLiveSSTables().size());
StatsMetadata metadata = cfs.getLiveSSTables().iterator().next().getSSTableMetadata();
assertEquals(9999, metadata.minTimestamp);
assertEquals(9999, metadata.maxTimestamp);
assertEquals(System.currentTimeMillis()/1000, metadata.maxLocalDeletionTime, 5);
cfs.forceMajorCompaction();
StatsMetadata metadata2 = cfs.getLiveSSTables().iterator().next().getSSTableMetadata();
assertEquals(metadata.maxLocalDeletionTime, metadata2.maxLocalDeletionTime);
assertEquals(metadata.minTimestamp, metadata2.minTimestamp);
assertEquals(metadata.maxTimestamp, metadata2.maxTimestamp);
}",time,2
311,cassandra,testTrackMetadata_rowTombstone,"@Test
public void testTrackMetadata_rowTombstone() throws Throwable
{
createTable(""CREATE TABLE %s (a int, b int, c text, PRIMARY KEY (a, b))"");
ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable());
execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a = 1"");
cfs.forceBlockingFlush();
assertEquals(1, cfs.getLiveSSTables().size());
StatsMetadata metadata = cfs.getLiveSSTables().iterator().next().getSSTableMetadata();
assertEquals(9999, metadata.minTimestamp);
assertEquals(9999, metadata.maxTimestamp);
assertEquals(System.currentTimeMillis()/1000, metadata.maxLocalDeletionTime, 5);
assertEquals(nowInSec(), metadata.maxLocalDeletionTime, DELTA);
cfs.forceMajorCompaction();
StatsMetadata metadata2 = cfs.getLiveSSTables().iterator().next().getSSTableMetadata();
assertEquals(metadata.maxLocalDeletionTime, metadata2.maxLocalDeletionTime);
assertEquals(metadata.minTimestamp, metadata2.minTimestamp);
assertEquals(metadata.maxTimestamp, metadata2.maxTimestamp);
}",time,2
312,androidx,testPredictiveLayoutAdd2,"@Test
public void testPredictiveLayoutAdd2() throws Throwable {
preparePredictiveLayout();
mActivityTestRule.runOnUiThread(new Runnable() {
@Override
public void run() {
mActivity.addItems(50, new int[]{300, 300, 300, 300});
}
});
waitForItemAnimationStart();
waitForItemAnimation(5000);
assertEquals(54, mGridView.getSelectedPosition());
assertEquals(RecyclerView.SCROLL_STATE_IDLE, mGridView.getScrollState());
}",async wait,0
313,androidx,onReceive,"@Test
public class Test {
public void onReceive() {
object broadcastReceiver = TestBroadcast();
context.registerReceiver(
broadcastReceiver,
IntentFilter(BROADCAST_ACTION)
);
String value = ""value"" ;
context.sendBroadcast(Intent(BROADCAST_ACTION).putExtra(EXTRA_STRING, value));
shadowOf(getMainLooper()).idle() ;
assertWithMessage(""Broadcast receiver did not execute"")
.that(broadcastReceiver.broadcastExecuted.await(1, SECONDS))
.isTrue();
assertThat(broadcastReceiver.extraValue.get()).isEqualTo(value);
assertThat(broadcastReceiver.job.get().isCancelled).isTrue();
}
}",async wait,0
314,hadoop,TestWritableName.testSetName,"@Test
public void testSetName() throws Exception {
Configuration conf = new Configuration();
WritableName.setName(SimpleWritable.class, testName);
Class<?> test = WritableName.getClass(testName, conf);
assertTrue(test.equals(SimpleWritable.class));
}",test order dependency,4
315,okhttp,DuplexTest.duplexWithRedirect,"@Test
public void duplexWithRedirect() throws Exception {
enableProtocol(HTTP_2);
MockDuplexResponseBody mockDuplexResponseBody = enqueueResponseWithBody(new MockResponse().clearHeaders().setResponseCode(HttpURLConnection.HTTP_MOVED_PERM).addHeader(""Location: /b""), new MockDuplexResponseBody().sendResponse(""/a has moved!\n"").requestIOException().exhaustResponse());
server.enqueue(new MockResponse().setBody(""this is /b""));
Call call = client.newCall(new Request.Builder().url(server.url(""/"")).post(new AsyncRequestBody()).build());
try (final Response response = call.execute()) {
BufferedSource responseBody = response.body().source();
assertThat(responseBody.readUtf8Line()).isEqualTo(""this is /b"");
}
BufferedSink requestBody = ((AsyncRequestBody) (call.request().body())).takeSink();
try {
requestBody.writeUtf8(""request body\n"");
requestBody.flush();
fail();
} catch (IOException expected) {
assertThat(expected.getMessage()).isEqualTo(""stream was reset: CANCEL"");
}
mockDuplexResponseBody.awaitSuccess();
assertThat(listener.recordedEventTypes()).containsExactly(""CallStart"", ""DnsStart"", ""DnsEnd"", ""ConnectStart"", ""SecureConnectStart"", ""SecureConnectEnd"", ""ConnectEnd"", ""ConnectionAcquired"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""RequestBodyStart"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""ConnectionReleased"", ""CallEnd"", ""RequestFailed"");
}",async wait,0
316,derby,ErrorMessageTest.testDeadlockTimeout,"@Test
public void testDeadlockTimeout() throws SQLException, InterruptedException {
setAutoCommit(false);
Statement s = createStatement();
assertUpdateCount(s, 1, ""update t set text='xxx' where id=1"");
Connection c2 = openDefaultConnection();
c2.setAutoCommit(false);
Statement s2 = c2.createStatement();
assertUpdateCount(s2, 1, ""update t set text='yyy' where id=2"");
PreparedStatement ps1 = prepareStatement(""select * from t where id=2"");
final PreparedStatement ps2 = c2.prepareStatement(""select * from t where id=1"");
final Barrier barrier = new Barrier(2);
final SQLException[] holder = new SQLException[2];
final Throwable[] unexpected = new Throwable[1];
Thread t = new Thread(new Runnable() {
public void run() {
try {
barrier.await();
JDBC.assertDrainResults(ps2.executeQuery());
} catch (SQLException e) {
holder[0] = e;
} catch (Throwable t) {
unexpected[0] = t;
}
}
});
t.start();
barrier.await();
try {
JDBC.assertDrainResults(ps1.executeQuery());
} catch (SQLException e) {
holder[1] = e;
}
t.join();
if (unexpected[0] != null) {
fail(""Helper thread failed unexpectedly"", unexpected[0]);
}
assertFalse(""No deadlock"", (holder[0] == null) && (holder[1] == null));
if ((holder[0] != null) && (holder[1] != null)) {
printStackTrace(holder[0]);
printStackTrace(holder[1]);
fail(""Only one of the waiters should be aborted"");
}
SQLException deadlock = (holder[0] == null) ? holder[1] : holder[0];
assertSQLState(""Not a deadlock"", ""40001"", deadlock);
String[] lines = deadlock.getMessage().split(""\n"");
assertEquals(""Unexpected number of lines in message"", 8, lines.length);
Pattern[] patterns = new Pattern[]{ Pattern.compile(""Lock : ROW, T, \\(\\d+,\\d+\\)""), Pattern.compile("" *Waiting XID : \\{\\d+, S\\} , APP, "" + ""select \\* from t where id=(1|2)""), Pattern.compile("" *Granted XID : \\{\\d+, X\\} *"") };
for (int i = 0; i < (patterns.length * 2); i++) {
String line = lines[i + 1];
Matcher m = patterns[i % patterns.length].matcher(line);
assertTrue(""mismatch: "" + line, m.matches());
}
s.close();
s2.close();
c2.rollback();
c2.close();
}",async wait,0
317,druid,KafkaLookupExtractorFactoryTest.testStartStop,"@Test
public void testStartStop() {
final KafkaStream<String, String> kafkaStream = PowerMock.createStrictMock(KafkaStream.class);
final ConsumerIterator<String, String> consumerIterator = PowerMock.createStrictMock(ConsumerIterator.class);
final ConsumerConnector consumerConnector = PowerMock.createStrictMock(ConsumerConnector.class);
EasyMock.expect(consumerConnector.createMessageStreamsByFilter(EasyMock.anyObject(TopicFilter.class), EasyMock.anyInt(), EasyMock.eq(DEFAULT_STRING_DECODER), EasyMock.eq(DEFAULT_STRING_DECODER))).andReturn(ImmutableList.of(kafkaStream)).once();
EasyMock.expect(kafkaStream.iterator()).andReturn(consumerIterator).anyTimes();
EasyMock.expect(consumerIterator.hasNext()).andAnswer(getBlockingAnswer()).anyTimes();
EasyMock.expect(cacheManager.createCache()).andReturn(cacheHandler).once();
EasyMock.expect(cacheHandler.getCache()).andReturn(new ConcurrentHashMap<String, String>()).once();
cacheHandler.close();
EasyMock.expectLastCall();
final AtomicBoolean threadWasInterrupted = new AtomicBoolean(false);
consumerConnector.shutdown();
EasyMock.expectLastCall().andAnswer(new IAnswer<Object>() {
@Override
public Object answer() {
threadWasInterrupted.set(Thread.currentThread().isInterrupted());
return null;
}
}).times(2);
PowerMock.replay(cacheManager, cacheHandler, kafkaStream, consumerConnector, consumerIterator);
final KafkaLookupExtractorFactory factory = new KafkaLookupExtractorFactory(cacheManager, TOPIC, ImmutableMap.of(""zookeeper.connect"", ""localhost""), 10000L, false) {
@Override
ConsumerConnector buildConnector(Properties properties) {
return consumerConnector;
}
};
Assert.assertTrue(factory.start());
Assert.assertTrue(factory.close());
Assert.assertTrue(factory.getFuture().isDone());
Assert.assertFalse(threadWasInterrupted.get());
PowerMock.verify(cacheManager, cacheHandler);
}",concurrency,1
318,mockito,TimeoutTest.should_try_to_verify_correct_number_of_times,"@Test
public void should_try_to_verify_correct_number_of_times() {
Timeout t = new Timeout(10, 50, mode, durationChecker);
doThrow(error).when(mode).verify(data);
when(durationChecker.isVerificationStillInProgress(anyLong())).thenReturn(true, true, true, true, true, false);
try {
t.verify(data);
fail();
} catch (MockitoAssertionError e) {
}
verify(mode, times(5)).verify(data);
}",time,2
319,liquibase,DependencyUtilTest.testIndependentBranchesCase,"@Test
public void testIndependentBranchesCase() {
graph.add(""a"", ""b"");
graph.add(""b"", ""c1"");
graph.add(""b"", ""c2"");
graph.add(""o"", ""p1"");
graph.add(""p1"", ""r1"");
graph.add(""r1"", ""s"");
graph.add(""o"", ""p2"");
graph.add(""p2"", ""r2"");
graph.add(""r2"", ""s2"");
graph.add(""r2"", ""s3"");
graph.add(""x"", ""y"");
graph.computeDependencies();
List<String> expected =
Arrays.asList(""a"", ""o"", ""x"", ""b"", ""p1"", ""p2"", ""y"", ""c1"", ""c2"", ""r1"", ""r2"", ""s"", ""s2"", ""s3"");
Assert.assertEquals(expected, dependencyOrder);
}",unordered collections,3
320,xtext-eclipse,DocumentLockerTest.testPriorityReadOnlyCancelsReaders,"@Test
public void testPriorityReadOnlyCancelsReaders() throws Exception {
Thread.interrupted();
XtextDocument document = new XtextDocument(createTokenSource(), null, outdatedStateManager, operationCanceledManager);
XtextResource resource = new XtextResource();
new XtextResourceSet().getResources().add(resource);
document.setInput(resource);
CountDownLatch check = new CountDownLatch(1);
Runnable runnable = new Runnable() {
@Override
public void run() {
document.readOnly(new CancelableUnitOfWork<Object, XtextResource>() {
@Override
public Object exec(XtextResource state, CancelIndicator cancelIndicator) throws Exception {
check.countDown();
int wait = 4000;
int i = 0;
while (!cancelIndicator.isCanceled()) {
Thread.sleep(10L);
if (i > wait) {
throw new InterruptedException();
}
i = i + 1;
}
return null;
}
});
}
};
Thread thread = new Thread(runnable);
thread.start();
check.await();
document.priorityReadOnly(( r) -> null);
Assert.assertFalse(thread.isInterrupted());
}",test order dependency,4
321,hadoop,TestPeerCache.testAddAndRetrieve,"@Test
public void testAddAndRetrieve() throws Exception {
PeerCache cache = PeerCache.getInstance(3, 100000);
DatanodeID dnId = new DatanodeID(""192.168.0.1"",
""fakehostname"", ""fake_storage_id"",
100, 101, 102);
FakePeer peer = new FakePeer(dnId, false);
cache.put(dnId, peer);
assertTrue(!peer.isClosed());
assertEquals(1, cache.size());
assertEquals(peer, cache.get(dnId, false));
assertEquals(0, cache.size());
cache.close();
}",test order dependency,4
322,triplea,close,"@Test
void close() throws Exception {
when(webSocketClient.getConnection()).thenReturn(webSocket);
when(webSocketClient.isOpen()).thenReturn(true);
webSocketConnection.close();
Thread.sleep(10);
verify(webSocket).close();
}",async wait,0
323,blueocean-plugin,AbstractRunImplTest.earlyUnstableStatusShouldReportPunStateAsRunningAndResultAsUnknown,"@Test
public void earlyUnstableStatusShouldReportPunStateAsRunningAndResultAsUnknown() throws Exception {
WorkflowJob p = j.createProject(WorkflowJob.class, ""project"");
URL resource = Resources.getResource(getClass(), ""earlyUnstableStatusShouldReportPunStateAsRunningAndResultAsUnknown.jenkinsfile"");
String jenkinsFile = Resources.toString(resource, Charsets.UTF_8);
p.setDefinition(new CpsFlowDefinition(jenkinsFile, true));
p.save();
Run r = p.scheduleBuild2(0).waitForStart();
String url = ""/organizations/jenkins/pipelines/project/runs/"" + r.getId() + ""/"";
Map m = request().get(url).build(Map.class);
j.waitForMessage(""Running on master"", r);
while (!""FINISHED"".equals(m.get(""state"").toString())) {
Assert.assertEquals(""RUNNING"", m.get(""state""));
Assert.assertEquals(""UNKNOWN"", m.get(""result""));
Thread.sleep(1000);
m = request().get(url).build(Map.class);
}
Assert.assertEquals(""FINISHED"", m.get(""state""));
Assert.assertEquals(""UNSTABLE"", m.get(""result""));
}",async wait,0
324,nomulus,testSuccess_multipartTldsWithSharedSuffixes,"@Test
public void testSuccess_multipartTldsWithSharedSuffixes() throws Exception {
createTlds(""bar.foo.tld"", ""foo.tld"", ""tld"");
assertCommandAndResponse(""login_valid.xml"", ""login_response.xml"");
assertCommandAndResponse(
""contact_create_sh8013.xml"",
ImmutableMap.of(),
""contact_create_response_sh8013.xml"",
ImmutableMap.of(""CRDATE"", ""2000-06-01T00:00:00Z""),
DateTime.parse(""2000-06-01T00:00:00Z""));
assertCommandAndResponse(
""contact_create_jd1234.xml"",
""contact_create_response_jd1234.xml"",
DateTime.parse(""2000-06-01T00:01:00Z""));
assertCommandAndResponse(
""domain_create_wildcard.xml"",
ImmutableMap.of(""HOSTNAME"", ""example.bar.foo.tld""),
""domain_create_response.xml"",
ImmutableMap.of(
""NAME"", ""example.bar.foo.tld"",
""CRDATE"", ""2000-06-01T00:02:00.0Z"",
""EXDATE"", ""2002-06-01T00:02:00.0Z""),
DateTime.parse(""2000-06-01T00:02:00Z""));
}",time,2
325,cdap,MetadataHttpHandlerTestRun.testSystemMetadataRetrieval,"@Test
public void testSystemMetadataRetrieval() throws Exception {
appClient.deploy(DEFAULT, createAppJarFile(AllProgramsApp.class));
Id.Stream streamId = Stream.from(DEFAULT, STREAM_NAME);
Set<String> streamSystemTags = getTags(streamId, SYSTEM);
Assert.assertEquals(ImmutableSet.of(STREAM_NAME), streamSystemTags);
Map<String, String> streamSystemProperties = getProperties(streamId, SYSTEM);
final String creationTime = ""creation-time"";
String description = ""description"";
String schema = ""schema"";
String ttl = ""ttl"";
Assert.assertTrue(""Expected creation time to exist but it does not"", streamSystemProperties.containsKey(creationTime));
long createTime = Long.parseLong(streamSystemProperties.get(creationTime));
Assert.assertTrue(""Stream create time should be within the last hour - "" + createTime, createTime > (System.currentTimeMillis() - TimeUnit.HOURS.toMillis(1)));
Assert.assertEquals(ImmutableMap.of(schema, Schema.recordOf(""stringBody"", Field.of(""body"", Schema.of(STRING))).toString(), ttl, String.valueOf(Long.MAX_VALUE), description, ""test stream"", creationTime, String.valueOf(createTime)), streamSystemProperties);
long newTtl = 100000L;
streamClient.setStreamProperties(streamId, new StreamProperties(newTtl, null, null));
streamSystemProperties = getProperties(streamId, SYSTEM);
Assert.assertEquals(ImmutableMap.of(schema, Schema.recordOf(""stringBody"", Field.of(""body"", Schema.of(STRING))).toString(), ttl, String.valueOf(newTtl * 1000), description, ""test stream"", creationTime, String.valueOf(createTime)), streamSystemProperties);
Set<MetadataRecord> streamSystemMetadata = getMetadata(streamId, SYSTEM);
Assert.assertEquals(ImmutableSet.of(new MetadataRecord(streamId, MetadataScope.SYSTEM, streamSystemProperties, streamSystemTags)), streamSystemMetadata);
Id.Stream.View view = View.from(streamId, ""view"");
Schema viewSchema = Schema.recordOf(""record"", Field.of(""viewBody"", Schema.nullableOf(Schema.of(BYTES))));
streamViewClient.createOrUpdate(view, new ViewSpecification(new FormatSpecification(""format"", viewSchema)));
Set<String> viewSystemTags = getTags(view, SYSTEM);
Assert.assertEquals(ImmutableSet.of(""view"", STREAM_NAME), viewSystemTags);
Map<String, String> viewSystemProperties = getProperties(view, SYSTEM);
Assert.assertEquals(viewSchema.toString(), viewSystemProperties.get(schema));
ImmutableSet<String> viewUserTags = ImmutableSet.of(""viewTag"");
addTags(view, viewUserTags);
Assert.assertEquals(ImmutableSet.of(new MetadataRecord(view, MetadataScope.USER, ImmutableMap.<String, String>of(), viewUserTags), new MetadataRecord(view, MetadataScope.SYSTEM, viewSystemProperties, viewSystemTags)), getMetadata(view));
Id.DatasetInstance datasetInstance = DatasetInstance.from(DEFAULT, DATASET_NAME);
Set<String> dsSystemTags = getTags(datasetInstance, SYSTEM);
Assert.assertEquals(ImmutableSet.of(DATASET_NAME, BATCH_TAG, EXPLORE_TAG), dsSystemTags);
Map<String, String> dsSystemProperties = getProperties(datasetInstance, SYSTEM);
Assert.assertTrue(""Expected creation time to exist but it does not"", dsSystemProperties.containsKey(creationTime));
createTime = Long.parseLong(dsSystemProperties.get(creationTime));
Assert.assertTrue(""Dataset create time should be within the last hour - "" + createTime, createTime > (System.currentTimeMillis() - TimeUnit.HOURS.toMillis(1)));
Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), description, ""test dataset"", creationTime, String.valueOf(createTime)), dsSystemProperties);
datasetClient.update(datasetInstance, ImmutableMap.of(PROPERTY_TTL, ""100000""));
dsSystemProperties = getProperties(datasetInstance, SYSTEM);
Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), description, ""test dataset"", ttl, ""100000"", creationTime, String.valueOf(createTime)), dsSystemProperties);
Id.Artifact artifactId = getArtifactId();
Assert.assertEquals(ImmutableSet.of(new MetadataRecord(artifactId, MetadataScope.SYSTEM, ImmutableMap.<String, String>of(), ImmutableSet.of(AllProgramsApp.class.getSimpleName()))), getMetadata(artifactId, SYSTEM));
Id.Application app = Application.from(DEFAULT, NAME);
Assert.assertEquals(ImmutableMap.builder().put((FLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpFlow.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR2.NAME, NAME).put((SERVICE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpService.NAME, NAME).put((SPARK.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpSpark.NAME, NAME).put((WORKER.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorker.NAME, NAME).put((WORKFLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorkflow.NAME, NAME).put((""schedule"" + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_NAME, (AllProgramsApp.SCHEDULE_NAME + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_DESCRIPTION).build(), getProperties(app, SYSTEM));
Assert.assertEquals(ImmutableSet.of(AllProgramsApp.class.getSimpleName(), NAME), getTags(app, SYSTEM));
assertProgramSystemMetadata(Program.from(app, FLOW, NAME), ""Realtime"");
assertProgramSystemMetadata(Program.from(app, WORKER, NAME), ""Realtime"");
assertProgramSystemMetadata(Program.from(app, SERVICE, NAME), ""Realtime"");
assertProgramSystemMetadata(Program.from(app, MAPREDUCE, NAME), ""Batch"");
assertProgramSystemMetadata(Program.from(app, SPARK, NAME), ""Batch"");
assertProgramSystemMetadata(Program.from(app, WORKFLOW, NAME), ""Batch"");
}",async wait,0
326,ormlite-core,QueryBuilderTest.testQueryRaw,"@Test
public void testQueryRaw() throws Exception {
Dao<Foo, Integer> dao = createDao(Foo.class, true);
Foo foo = new Foo();
foo.stringField = ""zipper"";
dao.create(foo);
QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
assertEquals(1, qb.countOf());
GenericRawResults<String[]> results = qb.queryRaw();
List<String[]> stringResults = results.getResults();
assertEquals(1, stringResults.size());
assertEquals(Integer.toString(foo.id), stringResults.get(0)[0]);
assertEquals(foo.stringField, stringResults.get(0)[3]);
}",unordered collections,3
327,hadoop,TestDFSIO.testRead,"@Test
public void testRead() throws Exception {
FileSystem fs = cluster.getFileSystem();
long tStart = System.currentTimeMillis();
bench.readTest(fs);
long execTime = System.currentTimeMillis() - tStart;
bench.analyzeResult(fs, TestType.TEST_TYPE_READ, execTime);
}",test order dependency,4
328,spring-data-couchbase,MappingCouchbaseConverterTests.writesAndReadsClassContainingCustomConvertedObjects,"@Test
void writesAndReadsClassContainingCustomConvertedObjects() {
List<Object> converters = new ArrayList<>();
converters.add(BigDecimalToStringConverter.INSTANCE);
converters.add(StringToBigDecimalConverter.INSTANCE);
CustomConversions customConversions = new CouchbaseCustomConversions(converters);
converter.setCustomConversions(customConversions);
converter.afterPropertiesSet();
((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(customConversions.getSimpleTypeHolder());
CouchbaseDocument converted = new CouchbaseDocument();
final String weightStr = ""12.34"";
final BigDecimal weight = new BigDecimal(weightStr);
final CustomObject addy = new CustomObject(weight);
List<CustomObject> listOfObjects = new ArrayList<>();
listOfObjects.add(addy);
Map<String, CustomObject> mapOfObjects = new HashMap<>();
mapOfObjects.put(""obj0"", addy);
mapOfObjects.put(""obj1"", addy);
CustomObjectEntity entity = new CustomObjectEntity(addy, listOfObjects, mapOfObjects);
converter.write(entity, converted);
CouchbaseDocument source = new CouchbaseDocument();
source.put(""_class"", CustomObjectEntity.class.getName());
CouchbaseDocument objectDoc = new CouchbaseDocument();
objectDoc.put(""weight"", weightStr);
source.put(""object"", objectDoc);
CouchbaseList listOfObjectsDoc = new CouchbaseList();
listOfObjectsDoc.put(objectDoc);
source.put(""listOfObjects"", listOfObjectsDoc);
CouchbaseDocument mapOfObjectsDoc = new CouchbaseDocument();
mapOfObjectsDoc.put(""obj0"", objectDoc);
mapOfObjectsDoc.put(""obj1"", objectDoc);
source.put(""mapOfObjects"", mapOfObjectsDoc);
assertThat(converted.export().toString()).isEqualTo(source.export().toString());
CustomObjectEntity readConverted = converter.read(CustomObjectEntity.class, source);
assertThat(readConverted.object.weight).isEqualTo(addy.weight);
assertThat(readConverted.listOfObjects.get(0).weight).isEqualTo(listOfObjects.get(0).weight);
assertThat(readConverted.mapOfObjects.get(""obj0"").weight).isEqualTo(mapOfObjects.get(""obj0"").weight);
assertThat(readConverted.mapOfObjects.get(""obj1"").weight).isEqualTo(mapOfObjects.get(""obj1"").weight);
}",unordered collections,3
329,hbase,TestAssignmentManagerMetrics.testRITAssignmentManagerMetrics,"@Test
public void testRITAssignmentManagerMetrics() throws Exception {
final TableName TABLENAME = TableName.valueOf(name.getMethodName());
final byte[] FAMILY = Bytes.toBytes(""family"");
Table table = null;
try {
table = TEST_UTIL.createTable(TABLENAME, FAMILY);
final byte[] row = Bytes.toBytes(""row"");
final byte[] qualifier = Bytes.toBytes(""qualifier"");
final byte[] value = Bytes.toBytes(""value"");
Put put = new Put(row);
put.addColumn(FAMILY, qualifier, value);
table.put(put);
Thread.sleep(msgInterval * 3);
MetricsAssignmentManagerSource amSource =
master.getAssignmentManager().getAssignmentManagerMetrics().getMetricsProcSource();
metricsHelper.assertGauge(MetricsAssignmentManagerSource.RIT_COUNT_NAME, 0, amSource);
metricsHelper.assertGauge(MetricsAssignmentManagerSource.RIT_COUNT_OVER_THRESHOLD_NAME, 0,
amSource);
ColumnFamilyDescriptor hcd = ColumnFamilyDescriptorBuilder.newBuilder(FAMILY).build();
TableDescriptor htd = TableDescriptorBuilder.newBuilder(TABLENAME).addColumnFamily(hcd).
addCoprocessorWithSpec(""hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2"").
build();
try {
TEST_UTIL.getAdmin().modifyTable(htd);
fail(""Expected region failed to open"");
} catch (IOException e) {
LOG.info(""Expected exception"", e);
}
Thread.sleep(msgInterval * 3);
metricsHelper.assertGauge(MetricsAssignmentManagerSource.RIT_COUNT_NAME, 2, amSource);
metricsHelper.assertGauge(MetricsAssignmentManagerSource.RIT_COUNT_OVER_THRESHOLD_NAME, 2,
amSource);
} finally {
if (table != null) {
table.close();
}
}
}",async wait,0
330,androidx,invalidationInAnotherInstance_closed,"@Test
public void invalidationInAnotherInstance_closed() throws Exception {
final SampleDatabase db1 = openDatabase(true);
final SampleDatabase db2 = openDatabase(true);
final SampleDatabase db3 = openDatabase(true);
final CountDownLatch invalidated1 = prepareTableObserver(db1);
final Pair<CountDownLatch, CountDownLatch> changed1 = prepareLiveDataObserver(db1);
final CountDownLatch invalidated2 = prepareTableObserver(db2);
final Pair<CountDownLatch, CountDownLatch> changed2 = prepareLiveDataObserver(db2);
final CountDownLatch invalidated3 = prepareTableObserver(db3);
final Pair<CountDownLatch, CountDownLatch> changed3 = prepareLiveDataObserver(db3);
db2.getCustomerDao().insert(CUSTOMER_1);
assertTrue(invalidated1.await(3, TimeUnit.SECONDS));
assertTrue(changed1.first.await(3, TimeUnit.SECONDS));
assertTrue(invalidated2.await(3, TimeUnit.SECONDS));
assertTrue(changed2.first.await(3, TimeUnit.SECONDS));
assertTrue(invalidated3.await(3, TimeUnit.SECONDS));
assertTrue(changed3.first.await(3, TimeUnit.SECONDS));
db3.close();
db2.getCustomerDao().insert(CUSTOMER_2);
assertTrue(changed1.second.await(3, TimeUnit.SECONDS));
assertTrue(changed2.second.await(3, TimeUnit.SECONDS));
assertFalse(changed3.second.await(300, TimeUnit.MILLISECONDS));
}",async wait,0
331,androidx,testSetCallbackWithNull,"@Test
public void testSetCallbackWithNull() throws Exception {
mSession.setActive(true);
mCallback.reset(1);
mSession.setCallback(null, mHandler);
assertEquals(""Callback shouldn't be called."", 0, mCallback.mOnPlayCalledCount);
}",async wait,0
332,teku,SyncCommitteeGossipAcceptanceTest.shouldContainSyncCommitteeAggregates,"@Test
public void shouldContainSyncCommitteeAggregates() throws Exception {
primaryNode.start();
primaryNode.startEventListener(List.of(contribution_and_proof));
secondaryNode.start();
secondaryNode.startEventListener(List.of(contribution_and_proof));
validatorClient.start();
primaryNode.waitForEpoch(1);
secondaryNode.waitForFullSyncCommitteeAggregate();
validatorClient.stop();
secondaryNode.stop();
primaryNode.stop();
assertThat(primaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isGreaterThanOrEqualTo(8)).count()).isGreaterThan(0);
assertThat(secondaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isLessThan(8)).count()).isGreaterThan(0);
}",async wait,0
333,activemq,PluginBrokerTest.assertMessageValid,"@Test
protected void assertMessageValid(int index, Message message) throws JMSException {
assertEquals(""localhost"", message.getStringProperty(""BrokerPath""));
ActiveMQMessage amqMsg = ((ActiveMQMessage) (message));
if (index == 7) {
assertEquals(2000, amqMsg.getExpiration() - amqMsg.getTimestamp());
} else if (index == 9) {
assertEquals(60000, amqMsg.getExpiration() - amqMsg.getTimestamp());
} else {
assertEquals(1000, amqMsg.getExpiration() - amqMsg.getTimestamp());
}
super.assertMessageValid(index, message);
}",time,2
334,cxf,ServerPersistenceTest.testRecovery,"@Test
public void testRecovery() throws Exception {
SpringBusFactory bf = new SpringBusFactory();
bus = bf.createBus();
BusFactory.setDefaultBus(bus);
LOG.fine((""Created bus "" + bus) + "" with default cfg"");
ControlService cs = new ControlService();
Control control = cs.getControlPort();
updateAddressPort(control, PORT);
assertTrue(""Failed to start greeter"", control.startGreeter(SERVER_LOSS_CFG));
LOG.fine(""Started greeter server."");
greeterBus = new SpringBusFactory().createBus(CFG);
LOG.fine(((""Created bus "" + greeterBus) + "" with cfg : "") + CFG);
BusFactory.setDefaultBus(greeterBus);
greeterBus.getExtension(RMManager.class).getRMAssertion().getBaseRetransmissionInterval().setMilliseconds(new BigInteger(""60000""));
GreeterService gs = new GreeterService();
Greeter greeter = gs.getGreeterPort();
updateAddressPort(greeter, PORT);
LOG.fine(""Created greeter client."");
ConnectionHelper.setKeepAliveConnection(greeter, true);
Client c = ClientProxy.getClient(greeter);
HTTPConduit hc = ((HTTPConduit) (c.getConduit()));
HTTPClientPolicy cp = hc.getClient();
cp.setDecoupledEndpoint((""http:example.com""));
out = new OutMessageRecorder();
in = new InMessageRecorder();
greeterBus.getOutInterceptors().add(out);
greeterBus.getInInterceptors().add(in);
LOG.fine(""Configured greeter client."");
Response<GreetMeResponse>[] responses = cast(new Response[4]);
responses[0] = greeter.greetMeAsync(""one"");
responses[1] = greeter.greetMeAsync(""two"");
responses[2] = greeter.greetMeAsync(""three"");
verifyMissingResponse(responses);
control.stopGreeter(SERVER_LOSS_CFG);
LOG.fine(""Stopped greeter server"");
out.getOutboundMessages().clear();
in.getInboundMessages().clear();
control.startGreeter(CFG);
String nl = System.getProperty(""line.separator"");
LOG.fine((""Restarted greeter server"" + nl) + nl);
verifyServerRecovery(responses);
out.getOutboundMessages().clear();
in.getInboundMessages().clear();
responses[3] = greeter.greetMeAsync(""four"");
verifyRetransmissionQueue();
greeterBus.shutdown(true);
control.stopGreeter(CFG);
bus.shutdown(true);
}",async wait,0
335,appbase,TestMonitor.testMonitor,"@Test
public void testMonitor() throws IOException, InterruptedException {
monitor.setScanInterval(5);
assertTrue(monitor.getEntries().isEmpty());
File fooFile = touchFile(""foo"", ""foo1"");
Thread.sleep(MONITOR_CHECK_DELAY);
Collection<TestInstance> entries = monitor.getEntries();
assertEquals(1, entries.size());
TestInstance[] entryArray = new TestInstance[1];
entryArray = entries.toArray(entryArray);
TestInstance fooInst = entryArray[0];
assertEquals(""foo1"", fooInst.getMessage());
touchFile(""bar"", ""bar1"");
Thread.sleep(MONITOR_CHECK_DELAY);
entries = monitor.getEntries();
assertEquals(2, entries.size());
TestInstance fooCheck = monitor.get(""foo"");
TestUtil.testArray(entryNames(entries), new String[]{ ""foo1"", ""bar1"" });
assertEquals(fooCheck, fooInst);
touchFile(""foo"", ""foo2"");
Thread.sleep(MONITOR_CHECK_DELAY);
entries = monitor.getEntries();
assertEquals(2, entries.size());
TestUtil.testArray(entryNames(entries), new String[]{ ""foo2"", ""bar1"" });
fooCheck = monitor.get(""foo"");
assertNotSame(fooInst, fooCheck);
assertEquals(""foo2"", fooCheck.getMessage());
fooFile.delete();
Thread.sleep(MONITOR_CHECK_DELAY);
entries = monitor.getEntries();
assertEquals(1, entries.size());
TestUtil.testArray(entryNames(entries), new String[]{ ""bar1"" });
}",async wait,0
336,hbase,TestGzipFilter.testErrorNotGzipped,"@Test
public void testErrorNotGzipped() throws Exception {
Header[] headers = new Header[2];
headers[0] = new Header(""Accept"", Constants.MIMETYPE_BINARY);
headers[1] = new Header(""Accept-Encoding"", ""gzip"");
Response response = client.get(((((""/"" + TABLE) + ""/"") + ROW_1) + ""/"") + COLUMN_2, headers);
assertEquals(response.getCode(), 404);
String contentEncoding = response.getHeader(""Content-Encoding"");
assertTrue((contentEncoding == null) || (!contentEncoding.contains(""gzip"")));
response = client.get(""/"" + TABLE, headers);
assertEquals(response.getCode(), 405);
contentEncoding = response.getHeader(""Content-Encoding"");
assertTrue((contentEncoding == null) || (!contentEncoding.contains(""gzip"")));
}",test order dependency,4
337,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testOnlyExternalContextAllowsCache,"@Test
public void testOnlyExternalContextAllowsCache() throws Exception {
KernelServices services = createKernelServicesBuilder(AdditionalInitialization.MANAGEMENT)
.build();
Assert.assertTrue(services.isSuccessfulBoot());
List<ModelNode> list = parse(ModelTestUtils.readResource(this.getClass(), ""subsystem.xml""));
for (ModelNode addOp : list) {
PathAddress addr = PathAddress.pathAddress(addOp.require(ModelDescriptionConstants.OP_ADDR));
if (addr.size() == 2 && addr.getLastElement().getKey().equals(NamingSubsystemModel.BINDING) && BindingType.forName(addOp.get(NamingBindingResourceDefinition.BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT) {
addOp.get(NamingBindingResourceDefinition.CACHE.getName()).set(true);
services.executeForFailure(addOp);
addOp.remove(NamingBindingResourceDefinition.CACHE.getName());
ModelTestUtils.checkOutcome(services.executeOperation(addOp));
ModelTestUtils.checkFailed(services.executeOperation(Util.getWriteAttributeOperation(addr, NamingBindingResourceDefinition.CACHE.getName(), new ModelNode(true))));
} else {
ModelTestUtils.checkOutcome(services.executeOperation(addOp));
}
}",test order dependency,4
338,hadoop,TestHftpFileSystem.testHftpCustomUriPortWithDefaultPorts,"@Test
public void testHftpCustomUriPortWithDefaultPorts() throws IOException {
resetFileSystem();
Configuration conf = new Configuration();
URI uri = URI.create() ;
HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort());
assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort());
assertEquals(uri, fs.getUri());
assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName());
}",test order dependency,4
339,testcontainers-java,appliesOuterTimeout,"@Test
public void appliesOuterTimeout() {
final WaitStrategy underTest = new WaitAllStrategy()
.withStrategy(strategy1)
.withStartupTimeout(Duration.ofMillis(10));
doAnswer(invocation -> {
Uninterruptibles.sleepUninterruptibly(20, TimeUnit.MILLISECONDS);
return null;
}).when(strategy1).waitUntilReady(eq(container));
assertThrows(""The outer strategy timeout applies"", TimeoutException.class, () -> {
underTest.waitUntilReady(container);
});
}",async wait,0
340,dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testListDetail,"@Test
public void testListDetail() throws RemotingException {
String result = port.telnet(null, ""-l"");
assertEquals(""dubbo://127.0.0.1:20887"", result);
}",test order dependency,4
341,opentelemetry-java-instrumentation,OpenTelemetryAppenderConfigTest.logWithExtras,"@Test
void logWithExtras() {
Instant start = Instant.now();
List<LogData> logDataList = logExporter.getFinishedLogItems();
assertThat(logDataList).hasSize(1);
LogData logData = logDataList.get(0);
assertThat(logData.getResource()).isEqualTo(resource);
assertThat(logData.getInstrumentationLibraryInfo()).isEqualTo(instrumentationLibraryInfo);
assertThat(logData.getBody().asString()).isEqualTo(""log message 1"");
assertThat(logData.getEpochNanos()).isGreaterThanOrEqualTo(TimeUnit.MILLISECONDS.toNanos(start.toEpochMilli())).isLessThanOrEqualTo(TimeUnit.MILLISECONDS.toNanos(Instant.now().toEpochMilli()));
assertThat(logData.getSeverity()).isEqualTo(INFO);
assertThat(logData.getSeverityText()).isEqualTo(""INFO"");
assertThat(logData.getAttributes().size()).isEqualTo(3);
assertThat(logData.getAttributes().get(EXCEPTION_TYPE)).isEqualTo(IllegalStateException.class.getName());
assertThat(logData.getAttributes().get(EXCEPTION_MESSAGE)).isEqualTo(""Error!"");
assertThat(logData.getAttributes().get(EXCEPTION_STACKTRACE)).contains(""logWithExtras"");
}",time,2
342,cdap,TestFrameworkTestRun.testAppWithServices,"@Test
public void testAppWithServices() throws Exception {
ApplicationManager applicationManager = deployApplication(AppWithServices.class);
LOG.info(""Deployed."");
ServiceManager serviceManager = applicationManager.getServiceManager(AppWithServices.SERVICE_NAME).start();
serviceManager.waitForStatus(true);
LOG.info(""Service Started"");
URL serviceURL = serviceManager.getServiceURL(15, TimeUnit.SECONDS);
Assert.assertNotNull(serviceURL);
URL url = new URL(serviceURL, ""ping2"");
HttpRequest request = HttpRequest.get(url).build();
HttpResponse response = HttpRequests.execute(request);
Assert.assertEquals(200, response.getResponseCode());
url = new URL(serviceURL, ""failure"");
request = HttpRequest.get(url).build();
response = HttpRequests.execute(request);
Assert.assertEquals(500, response.getResponseCode());
Assert.assertTrue(response.getResponseBodyAsString().contains(""Exception""));
url = new URL(serviceURL, ""verifyClassLoader"");
request = HttpRequest.get(url).build();
response = HttpRequests.execute(request);
Assert.assertEquals(200, response.getResponseCode());
RuntimeMetrics serviceMetrics = serviceManager.getMetrics();
serviceMetrics.waitForinput(3, 5, TimeUnit.SECONDS);
Assert.assertEquals(3, serviceMetrics.getInput());
Assert.assertEquals(2, serviceMetrics.getProcessed());
Assert.assertEquals(1, serviceMetrics.getException());
RuntimeMetrics handlerMetrics = getMetricsManager().getServiceHandlerMetrics(Id.Namespace.DEFAULT.getId(),
AppWithServices.APP_NAME,
AppWithServices.SERVICE_NAME,
AppWithServices.SERVICE_NAME);
handlerMetrics.waitForinput(3, 5, TimeUnit.SECONDS);
Assert.assertEquals(3, handlerMetrics.getInput());
Assert.assertEquals(2, handlerMetrics.getProcessed());
Assert.assertEquals(1, handlerMetrics.getException());
LOG.info(""DatasetUpdateService Started"");
Map<String, String> args
= ImmutableMap.of(AppWithServices.WRITE_VALUE_RUN_KEY, AppWithServices.DATASET_TEST_VALUE,
AppWithServices.WRITE_VALUE_STOP_KEY, AppWithServices.DATASET_TEST_VALUE_STOP);
ServiceManager datasetWorkerServiceManager = applicationManager
.getServiceManager(AppWithServices.DATASET_WORKER_SERVICE_NAME).start(args);
WorkerManager datasetWorker =
applicationManager.getWorkerManager(AppWithServices.DATASET_UPDATE_WORKER).start(args);
datasetWorkerServiceManager.waitForStatus(true);
ServiceManager noopManager = applicationManager.getServiceManager(""NoOpService"").start();
serviceManager.waitForStatus(true, 2, 1);
String result = callServiceGet(noopManager.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY);
String decodedResult = new Gson().fromJson(result, String.class);
Assert.assertEquals(AppWithServices.DATASET_TEST_VALUE, decodedResult);
handlerMetrics = getMetricsManager().getServiceHandlerMetrics(Id.Namespace.DEFAULT.getId(),
AppWithServices.APP_NAME,
""NoOpService"",
""NoOpHandler"");
handlerMetrics.waitForinput(1, 5, TimeUnit.SECONDS);
Assert.assertEquals(1, handlerMetrics.getInput());
Assert.assertEquals(1, handlerMetrics.getProcessed());
Assert.assertEquals(0, handlerMetrics.getException());
String path = String.format(""discover/%s/%s"",
AppWithServices.APP_NAME, AppWithServices.DATASET_WORKER_SERVICE_NAME);
url = new URL(serviceURL, path);
request = HttpRequest.get(url).build();
response = HttpRequests.execute(request);
Assert.assertEquals(200, response.getResponseCode());
datasetWorker.stop();
datasetWorkerServiceManager.stop();
datasetWorkerServiceManager.waitForStatus(false);
LOG.info(""DatasetUpdateService Stopped"");
serviceManager.stop();
serviceManager.waitForStatus(false);
LOG.info(""ServerService Stopped"");
result = callServiceGet(noopManager.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP);
decodedResult = new Gson().fromJson(result, String.class);
Assert.assertEquals(AppWithServices.DATASET_TEST_VALUE_STOP, decodedResult);
result = callServiceGet(noopManager.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP_2);
decodedResult = new Gson().fromJson(result, String.class);
Assert.assertEquals(AppWithServices.DATASET_TEST_VALUE_STOP_2, decodedResult);
}",concurrency,1
343,openapi-generator,AbstractJavaCodegenTest.testAdditionalModelTypeAnnotationsSemiColon,"@Test
public void testAdditionalModelTypeAnnotationsSemiColon() throws Exception {
OpenAPI openAPI = TestUtils.createOpenAPI();
final AbstractJavaCodegen codegen = new P_AbstractJavaCodegen();
codegen.additionalProperties().put(ADDITIONAL_MODEL_TYPE_ANNOTATIONS, ""@Foo;@Bar"");
codegen.processOpts();
codegen.preprocessOpenAPI(openAPI);
final List<String> additionalModelTypeAnnotations = new ArrayList<String>();
additionalModelTypeAnnotations.add(""@Foo"");
additionalModelTypeAnnotations.add(""@Bar"");
Assert.assertEquals(codegen.getAdditionalModelTypeAnnotations(), additionalModelTypeAnnotations);
}",unordered collections,3
344,hbase,TestStoreFile.testHFileLink,"@Test
public void testHFileLink() throws IOException {
final String columnFamily = ""f"";
HRegionInfo hri = new HRegionInfo(Bytes.toBytes(""table-link""));
Path storedir = new Path(new Path(FSUtils.getRootDir(conf), new Path(hri.getTableNameAsString(), hri.getEncodedName())), columnFamily);
StoreFile.Writer writer = new StoreFile.WriterBuilder(conf, cacheConf, this.fs, 8 * 1024).withOutputDir(storedir).build();
Path storeFilePath = writer.getPath();
writeStoreFile(writer);
writer.close();
Path dstPath = new Path(FSUtils.getRootDir(conf), new Path(""test-region"", columnFamily));
HFileLink.create(conf, this.fs, dstPath, hri, storeFilePath.getName());
Path linkFilePath = new Path(dstPath, HFileLink.createHFileLinkName(hri, storeFilePath.getName()));
StoreFile hsf = new StoreFile(this.fs, linkFilePath, conf, cacheConf, BloomType.NONE, NoOpDataBlockEncoder.INSTANCE);
assertTrue(hsf.isLink());
int count = 1;
HFileScanner s = hsf.createReader().getScanner(false, false);
s.seekTo();
while (s.next()) {
count++;
}
assertEquals(((LAST_CHAR - FIRST_CHAR) + 1) * ((LAST_CHAR - FIRST_CHAR) + 1), count);
}",test order dependency,4
345,junit-quickcheck,ExhaustingAGivenSetButIncludingAnotherTest.manyParameters,"@Test
public void manyParameters() throws Exception {
assertThat(testResult(ManyParameters.class), isSuccessful());
assertEquals(16, ManyParameters.iterations);
assertEquals(asList(-1, -2, -4), ManyParameters.firstTestCases.subList(0, 3));
assertEquals(asList(-1, -2, -4), ManyParameters.firstTestCases.subList(4, 7));
assertEquals(asList(-1, -2, -4), ManyParameters.firstTestCases.subList(8, 11));
assertEquals(asList(-1, -2, -4), ManyParameters.firstTestCases.subList(12, 15));
assertEquals(asList('r', 'r', 'r', 'r', 'y', 'y', 'y', 'y'), ManyParameters.secondTestCases.subList(0, 8));
}",unordered collections,3
346,jetty,project.MavenMetadataTest.testIsExpiredTimestampYesterday,"@Test
public void testIsExpiredTimestampYesterday() {
LocalDateTime yesterday = LocalDateTime.now().minusDays(1);
String timestamp = getTimestampFormatter().format(yesterday);
assertTrue(MavenMetadata.isExpiredTimestamp(timestamp), ""Timestamp should be stale: "" + timestamp);
}",time,2
347,continuum,AbstractContinuumTest.waitAddProject,"@Test
public void waitAddProject(String title) throws Exception {
String condition = ""selenium.browserbot.getCurrentWindow().document.title.replace(/^\\s*/, \""\"").replace(/\\s*$/, \""\"") != \'\' && selenium.browserbot.getCurrentWindow().document.getElementById(\'footer\') != null"";
getSelenium().waitForCondition(condition, maxWaitTimeInMs);
Assert.assertEquals(getTitle(), title);
}",async wait,0
348,karaf,FeaturesServiceImplTest.testStartDoesNotFailWithNonExistentVersion,"@Test
public void testStartDoesNotFailWithNonExistentVersion() {
BundleContext bundleContext = EasyMock.createMock(BundleContext.class);
final Map<String, Map<String, Feature>> features = new HashMap<String, Map<String, Feature>>();
Map<String, Feature> versions = new HashMap<String, Feature>();
versions.put(""1.0.0"", new FeatureImpl(""transaction"", ""1.0.0""));
versions.put(""2.0.0"", new FeatureImpl(""transaction"", ""2.0.0""));
features.put(""transaction"", versions);
Map<String, Feature> versions2 = new HashMap<String, Feature>();
versions2.put(""1.0.0"", new FeatureImpl(""ssh"", ""1.0.0""));
features.put(""ssh"", versions2);
final FeaturesServiceImpl impl = new FeaturesServiceImpl() ;
impl.setBundleContext(bundleContext);
try {
Thread.currentThread().setContextClassLoader(new URLClassLoader(new URL[0]));
impl.setBoot(""transaction;version=1.2,ssh;version=1.0.0"");
impl.start();
assertFalse(""Feature transaction 1.0.0 should not be installed"", impl.isInstalled(impl.getFeature(""transaction"", ""1.0.0"")));
assertFalse(""Feature transaction 2.0.0 should not be installed"", impl.isInstalled(impl.getFeature(""transaction"", ""2.0.0"")));
assertFalse(""Feature ssh should be installed"", impl.isInstalled(impl.getFeature(""ssh"", ""1.0.0"")));
} catch (Exception e) {
fail(String.format(""Service should not throw start-up exception but log the error instead: %s"", e));
}
}",async wait,0
349,google-cloud-eclipse,CreateAppEngineStandardWtpProjectTest.testNoTestClassesInDeploymentAssembly,"@Test
public void testNoTestClassesInDeploymentAssembly()
throws InvocationTargetException, CoreException {
CreateAppEngineWtpProject creator = new CreateAppEngineStandardWtpProject(config, adaptable);
creator.execute(monitor);
ProjectUtils.waitForProjects(project);
assertNoTestClassesInDeploymentAssembly();
}
private void assertNoTestClassesInDeploymentAssembly() throws CoreException {
StructureEdit core = StructureEdit.getStructureEditForRead(project);
WorkbenchComponent component = core.getComponent();
assertNotNull(component);
boolean seenMainSourcePath = false;
List<ComponentResource> resources = component.getResources();
for (ComponentResource resource : resources) {
assertFalse(containsSegment(resource.getSourcePath(), ""test""));
if (resource.getSourcePath().equals(new Path(""/src/main/java""))
&& resource.getRuntimePath().equals(new Path(""/WEB-INF/classes""))) {
seenMainSourcePath = true;
}
}
assertTrue(seenMainSourcePath);
}",async wait,0
350,activemq,NoDuplicateOnTopicNetworkTest.testProducerConsumerTopic,"@Test
public void testProducerConsumerTopic() throws Exception {
final CountDownLatch consumerStarted = new CountDownLatch(1);
Thread producerThread = new Thread(new Runnable());
final TopicWithDuplicateMessages consumer = new TopicWithDuplicateMessages();
Thread consumerThread = new Thread(new Runnable() );
consumerThread.start();
LOG.info(""Started Consumer"");
assertTrue(""consumer started eventually"", consumerStarted.await(10, TimeUnit.SECONDS));
Thread.sleep(2000);
producerThread.start();
LOG.info(""Started Producer"");
producerThread.join();
consumerThread.join();
int duplicateCount = 0;
Map<String, String> map = new HashMap<String, String>();
for (String msg : consumer.getMessageStrings()) {
if (map.containsKey(msg)) {
LOG.info(""got duplicate: "" + msg);
duplicateCount++;
}
map.put(msg, msg);
}
if (suppressDuplicateTopicSubs || (dispatchPolicy instanceof PriorityNetworkDispatchPolicy)) {
assertEquals(""no duplicates"", 0, duplicateCount);
assertEquals(""got all required messages: "" + map.size(), consumer.getNumMessages(), map.size());
} else {
assertTrue(""we got some duplicates"", duplicateCount > 0);
}
}",concurrency,1
351,androidx,testStopTimer_withCleanUp,"@Test
public void testStopTimer_withCleanUp() throws InterruptedException {
TestTimeLimitExceededListener listenerSpy = spy(mListener);
mWorkTimer.startTimer(WORKSPEC_ID_1, 100, listenerSpy);
mWorkTimer.stopTimer(WORKSPEC_ID_1);
Thread.sleep(100);
verify(listenerSpy, times(0)).onTimeLimitExceeded(WORKSPEC_ID_1);
assertThat(mWorkTimer.getTimerMap().size(), is(0));
assertThat(mWorkTimer.getListeners().size(), is(0));
}",async wait,0
352,cukes,b483e1a8f261b80a66291a42fc455256b0b5059c.shouldReturnBodyWhenEnabledAndNoMax,"@Test
public void shouldReturnBodyWhenEnabledAndNoMax() {
String body = ""{\n"" +
""  \""error\"": \""not found\""\n"" +
""}"";
HttpResponseFacade mock = mock(HttpResponseFacade.class);
when(mock.response()).thenReturn(generateResponse(
""application/json"",
404,
body.getBytes()));
((HttpAssertionFacadeImpl) facade).facade = mock;
world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");
validateException(
200,
""1 expectation failed.\n"" +
""Expected status code \""200\"" but was \""404\"" with body:\n"" +
""\""\""\""\n"" +
body +
""\n\""\""\"".\n"");
}",test order dependency,4
353,RxNetty,ProxyTest.testProxy,"@Test
public void testProxy() throws NoSuchMethodException, IllegalAccessException, InvocationTargetException {
Queue<String> output = ExamplesTestUtil.runClientInMockedEnvironment(ProxyClient.class);
HttpResponse expectedHeader = new DefaultHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK);
expectedHeader.headers().add(((CharSequence) (""X-Proxied-By"")), ""RxNetty"");
expectedHeader.headers().add(TRANSFER_ENCODING, CHUNKED);
String expectedHeaderString = HttpMessageFormatter.formatResponse(expectedHeader.protocolVersion(), expectedHeader.status(), expectedHeader.headers().iteratorCharSequence());
assertThat(""Unexpected number of messages echoed"", output, hasSize(2));
assertThat(""Unexpected response."", output, contains(expectedHeaderString, ""HelloWorld!""));
}",concurrency,1
354,struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testRender_ok.2,"@Test
public void testRender_ok() {
final Mock mockResponse = mock(RenderResponse.class);
mockResponse.stubs().method(ANYTHING);
PortletMode mode = PortletMode.VIEW;
Map<String, String[]> requestParams = new HashMap<String, String[]>();
requestParams.put(ACTION_PARAM, new String[] { ""/view/testAction"" });
requestParams.put(EVENT_ACTION, new String[] { ""true"" });
requestParams.put(MODE_PARAM, new String[] { mode.toString() });
Map<String, Object> sessionMap = new HashMap<String, Object>();
Map<String, String> initParams = new HashMap<String, String>();
initParams.put(""viewNamespace"", ""/view"");
initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE,
""true"");
initPortletConfig(initParams, new HashMap<String, Object>());
initRequest(requestParams, new HashMap<String, Object>(), sessionMap,
PortletMode.VIEW, WindowState.NORMAL, false, null);
setupActionFactory(""/view"", ""testAction"", ""success"",
EasyMock.createNiceMock(ValueStack.class));
mockInvocation.expects(once()).method(""getStack"")
.will(returnValue(null));
try {
dispatcher
.setActionProxyFactory((ActionProxyFactory) mockActionFactory
.proxy());
dispatcher.init((PortletConfig) mockConfig.proxy());
dispatcher.render((RenderRequest) mockRequest.proxy(),
(RenderResponse) mockResponse.proxy());
} catch (Exception e) {
e.printStackTrace();
fail(""Error occured"");
}
}",test order dependency,4
355,RxJava,OperatorRetryTest.testRetryWithBackpressure,"@Test
public void testRetryWithBackpressure() throws InterruptedException {
final int NUM_RETRIES = RxRingBuffer.SIZE * 2;
for (int i = 0; i < 400; i++) {
@SuppressWarnings(""unchecked"")
Observer<String> observer = mock(Observer.class);
Observable<String> origin = Observable.create(new FuncWithErrors(NUM_RETRIES));
TestSubscriber<String> ts = new TestSubscriber<String>(observer);
origin.retry().observeOn(Schedulers.computation()).unsafeSubscribe(ts);
ts.awaitTerminalEvent(5, TimeUnit.SECONDS);
InOrder inOrder = inOrder(observer);
verify(observer, never()).onError(any(Throwable.class));
inOrder.verify(observer, times(NUM_RETRIES + 1)).onNext(""beginningEveryTime"");
inOrder.verify(observer, times(1)).onNext(""onSuccessOnly"");
inOrder.verify(observer, times(1)).onCompleted();
inOrder.verifyNoMoreInteractions();
}
}",concurrency,1
356,cdap,MetricsQueryTestRun.testingUserServiceGaugeMetrics,"@Test
public void testingUserServiceGaugeMetrics() throws Exception {
MetricsCollector collector =
collectionService.getCollector(getUserServiceContext(Constants.DEFAULT_NAMESPACE, ""WordCount"", ""CounterService"",
""CountRunnable""));
collector.increment(""gmetric"", 1);
collector.gauge(""gmetric"", 10);
collector.increment(""gmetric"", 1);
TimeUnit.SECONDS.sleep(1);
collector.gauge(""gmetric"", 10);
TimeUnit.SECONDS.sleep(2);
String runnableRequest =
""/system/apps/WordCount/services/CounterService/runnables/CountRunnable/gmetric?aggregate=true"";
String serviceRequest =
""/system/apps/WordCount/services/CounterService/gmetric?aggregate=true"";
testSingleMetric(runnableRequest, 10);
testSingleMetric(serviceRequest, 10);
}",async wait,0
357,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookup,"@Test
public void testLookup() throws Exception {
final Name name = new CompositeName(""test"");
final Object object = new Object();
namingStore.bind(name, object);
Object result = namingContext.lookup(name);
assertEquals(object, result);
result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
assertEquals(object, result);
}",test order dependency,4
358,oryx,ALSServingInputProducerIT.testALSInputProducer,"@Test
public void testALSInputProducer() throws Exception {
Map<String, Object> overlayConfig = new HashMap<>();
overlayConfig.put(""oryx.serving.application-resources"", ""\""com.cloudera.oryx.app.serving,com.cloudera.oryx.app.serving.als\"""");
overlayConfig.put(""oryx.serving.model-manager-class"", ALSServingModelManager.class.getName());
Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());
startMessaging();
startServer(config);
@SuppressWarnings(""unchecked"")
TopicProducer<String, String> inputProducer = ((TopicProducer<String, String>) (getServingLayer().getContext().getServletContext().getAttribute(INPUT_PRODUCER_KEY)));
String[] inputs = new String[]{ ""abc,123,1.5"", ""xyz,234,-0.5"", ""AB,10,0"" };
List<Pair<String, String>> keyMessages;
try (final CloseableIterator<Pair<String, String>> data = new ConsumeData(INPUT_TOPIC, getZKPort()).iterator()) {
log.info(""Starting consumer thread"");
ConsumeTopicRunnable consumeInput = new ConsumeTopicRunnable(data);
new Thread(consumeInput).start();
Thread.sleep(3000);
for (String input : inputs) {
inputProducer.send("""", input);
}
Thread.sleep(1000);
keyMessages = consumeInput.getKeyMessages();
}
for (int i = 0; i < keyMessages.size(); i++) {
Pair<String, String> keyMessage = keyMessages.get(i);
assertEquals("""", keyMessage.getFirst());
assertEquals(inputs[i], keyMessage.getSecond());
}
assertEquals(inputs.length, keyMessages.size());
}",async wait,0
359,hbase,TestAsyncSnapshotAdminApi.testTakeSnapshot,"@Test
public void testTakeSnapshot() throws Exception {
String snapshotName1 = ""snapshotName1"";
String snapshotName2 = ""snapshotName2"";
TableName tableName = TableName.valueOf(""testTakeSnapshot"");
Admin syncAdmin = TEST_UTIL.getAdmin();
try {
Table table = TEST_UTIL.createTable(tableName, Bytes.toBytes(""f1""));
for (int i = 0; i < 3000; i++) {
table.put(new Put(Bytes.toBytes(i)).addColumn(Bytes.toBytes(""f1""), Bytes.toBytes(""cq""),
Bytes.toBytes(i)));
}
admin.snapshot(snapshotName1, tableName).get();
admin.snapshot(snapshotName2, tableName).get();
List<SnapshotDescription> snapshots = syncAdmin.listSnapshots();
Collections.sort(snapshots, (snap1, snap2) -> {
Assert.assertNotNull(snap1);
Assert.assertNotNull(snap1.getName());
Assert.assertNotNull(snap2);
Assert.assertNotNull(snap2.getName());
return snap1.getName().compareTo(snap2.getName());
});
Assert.assertEquals(snapshotName1, snapshots.get(0).getName());
Assert.assertEquals(tableName, snapshots.get(0).getTableName());
Assert.assertEquals(SnapshotType.FLUSH, snapshots.get(0).getType());
Assert.assertEquals(snapshotName2, snapshots.get(1).getName());
Assert.assertEquals(tableName, snapshots.get(1).getTableName());
Assert.assertEquals(SnapshotType.FLUSH, snapshots.get(1).getType());
} finally {
syncAdmin.deleteSnapshot(snapshotName1);
syncAdmin.deleteSnapshot(snapshotName2);
TEST_UTIL.deleteTable(tableName);
}",async wait,0
360,hadoop,TestPeerCache.testExpiry,"@Test
public void testExpiry() throws Exception {
final int CAPACITY = 3;
final int EXPIRY_PERIOD = 10;
PeerCache cache = PeerCache.getInstance(CAPACITY, EXPIRY_PERIOD);
DatanodeID dnIds[] = new DatanodeID[CAPACITY];
FakePeer peers[] = new FakePeer[CAPACITY];
for (int i = 0; i < CAPACITY; ++i) {
dnIds[i] = new DatanodeID(""192.168.0.1"",
""fakehostname_"" + i, ""fake_storage_id"",
100, 101, 102);
peers[i] = new FakePeer(dnIds[i], false);
}
for (int i = 0; i < CAPACITY; ++i) {
cache.put(dnIds[i], peers[i]);
}
Thread.sleep(EXPIRY_PERIOD * 50);
assertEquals(0, cache.size());
for (int i = 0; i < CAPACITY; ++i) {
assertTrue(peers[i].isClosed());
}
Thread.sleep(EXPIRY_PERIOD * 50);
cache.close();
}",test order dependency,4
361,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindings.2.,"@Test
public void testListBindings() throws Exception {
final Object value = new Object();
bindObject(ServiceName.JBOSS.append(""TestBean""), value);
bindObject(ServiceName.JBOSS.append(""foo"", ""TestBean""), value);
bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""TestBean""), value);
bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""), value);
store.add(ServiceName.JBOSS.append(""foos"", ""bar""));
store.add(ServiceName.JBOSS.append(""fo"", ""bar""));
store.add(ServiceName.JBOSS.append(""foo"", ""ba"", ""baz""));
store.add(ServiceName.JBOSS.append(""foo"", ""bart"", ""baz""));
store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba""));
store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt""));
store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art""));
store.add(ServiceName.JBOSS.append(""other"", ""one""));
List<Binding> list = store.listBindings(new CompositeName(""""));
assertEquals(5, list.size());
assertContains(list, ""TestBean"", Object.class);
assertContains(list, ""foo"", NamingContext.class);
assertContains(list, ""fo"", NamingContext.class);
assertContains(list, ""foos"", NamingContext.class);
assertContains(list, ""other"", NamingContext.class);
list = store.listBindings(new CompositeName(""foo""));
assertEquals(4, list.size());
assertContains(list, ""TestBean"", Object.class);
assertContains(list, ""ba"", NamingContext.class);
assertContains(list, ""bart"", NamingContext.class);
assertContains(list, ""bar"", NamingContext.class);
for (Binding binding : list) {
if (binding.getName().equals(""bar"")) {
final Object bean = Context.class.cast(binding.getObject()).lookup(""TestBean"");
assertNotNull(bean);
assertEquals(value, bean);
}
}
}",test order dependency,4
362,armeria,ServiceRequestCancellationTest.shouldCompleteLogWhenCancelledByClient,"@Test
void shouldCompleteLogWhenCancelledByClient(SessionProtocol protocol) {
final ClientFactory factory = ClientFactory.builder().build();
final WebClient client = WebClient.builder(server.uri(protocol)).factory(factory).build();
final CompletableFuture<AggregatedHttpResponse> responseFuture = client.get(""/reset"").aggregate();
await().untilAtomic(ctxRef, Matchers.notNullValue());
factory.close();
final RequestLog log = ctxRef.get().log().whenComplete().join();
if (protocol.isMultiplex()) {
assertThat(log.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""received a RST_STREAM frame: CANCEL"");
assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class);
} else {
assertThat(log.responseCause()).isInstanceOf(ClosedSessionException.class);
assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class);
}
}",test order dependency,4
363,platform_frameworks_support,basicSwipeTest,"@Test
public void basicSwipeTest(int dir, int swipeDirs, int targetX) throws Throwable {
final RecyclerView recyclerView = setup(0, swipeDirs);
mLayoutManager.expectLayouts(1);
setRecyclerView(recyclerView);
mLayoutManager.waitForLayout(1);
final RecyclerView.ViewHolder target = mRecyclerView
.findViewHolderForAdapterPosition(1);
TouchUtils.dragViewToX(getInstrumentation(), target.itemView, Gravity.CENTER, targetX);
Thread.sleep(100);
final SwipeRecord swipe = mCalback.getSwipe(target);
assertNotNull(swipe);
assertEquals(dir, swipe.dir);
assertEquals(1, mItemTouchHelper.mRecoverAnimations.size());
assertEquals(1, mItemTouchHelper.mPendingCleanup.size());
mLayoutManager.expectLayouts(1);
mAdapter.deleteAndNotify(1, 1);
mLayoutManager.waitForLayout(1);
waitForAnimations();
assertEquals(0, mItemTouchHelper.mRecoverAnimations.size());
assertEquals(0, mItemTouchHelper.mPendingCleanup.size());
assertTrue(mCalback.isCleared(target));
}",async wait,0
364,Mapper,IdTest.testCompositeKeys,"@Test
public void testCompositeKeys() {
EntityHelper.initEntityNameMap(UserCompositeKeys.class, config);
EntityTable entityTable = EntityHelper.getEntityTable(UserCompositeKeys.class);
Assert.assertNotNull(entityTable);
Set<EntityColumn> columns = entityTable.getEntityClassColumns();
Assert.assertEquals(2, columns.size());
Assert.assertEquals(2, entityTable.getEntityClassPKColumns().size());
for (EntityColumn column : columns) {
Assert.assertTrue(column.isId());
}
ResultMap resultMap = entityTable.getResultMap(configuration);
Assert.assertEquals(2, resultMap.getResultMappings().size());
Assert.assertTrue(resultMap.getResultMappings().get(0).getFlags().contains(ID));
Assert.assertTrue(resultMap.getResultMappings().get(1).getFlags().contains(ID));
Assert.assertEquals(""<where> AND name = #{name} AND orgId = #{orgId}</where>"", SqlHelper.wherePKColumns(UserCompositeKeys.class));
}",unordered collections,3
365,wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindingsWithContinuation,"@Test
public void testListBindingsWithContinuation() throws Exception {
bindListWithContinuations();
NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName(""comp""));
checkListWithContinuationsResults(results);
results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, Arrays.asList(
new JndiPermission(""test"", ""listBindings"")), namingContext, ""comp"");
checkListWithContinuationsResults(results);
}",test order dependency,4
366,google-cloud-eclipse,XmlValidatorTest.testValidate_badXml,"@Test
public void testValidate_badXml() throws IOException, CoreException {
XmlValidator validator = new XmlValidator();
validator.setHelper(new AppEngineWebXmlValidator());
IFile file = createBogusProjectFile();
byte[] badXml = BAD_XML.getBytes(StandardCharsets.UTF_8);
validator.validate(file, badXml);
IMarker[] emptyMarkers =
ProjectUtils.waitUntilNoMarkersFound(file, PROBLEM, true, DEPTH_ZERO);
ArrayAssertions.assertIsEmpty(emptyMarkers);
}",async wait,0
367,hadoop,TestSecurityUtil.testBuildTokenServiceSockAddr,"@Test
public void testBuildTokenServiceSockAddr() {
assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""LocalHost"", 123)).toString());
assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""127.0.0.1"", 123)).toString());
assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(NetUtils.createSocketAddr(""127.0.0.1"", 123)).toString());
}",test order dependency,4
368,hadoop,TestDFSIO.testWrite,"@Test
public void testWrite() throws Exception {
FileSystem fs = cluster.getFileSystem();
long tStart = System.currentTimeMillis();
bench.writeTest(fs);
long execTime = System.currentTimeMillis() - tStart;
bench.analyzeResult(fs, TestType.TEST_TYPE_WRITE, execTime);
}",test order dependency,4
369,pulsar,socketTest,"@Test
public void socketTest() throws Exception {
URI consumeUri = URI.create(CONSUME_URI);
URI produceUri = URI.create(PRODUCE_URI);
WebSocketClient consumeClient = new WebSocketClient();
SimpleConsumerSocket consumeSocket = new SimpleConsumerSocket();
WebSocketClient produceClient = new WebSocketClient();
SimpleProducerSocket produceSocket = new SimpleProducerSocket();
try {
consumeClient.start();
ClientUpgradeRequest consumeRequest = new ClientUpgradeRequest();
Future<Session> consumerFuture = consumeClient.connect(consumeSocket, consumeUri, consumeRequest);
log.info(""Connecting to : {}"", consumeUri);
ClientUpgradeRequest produceRequest = new ClientUpgradeRequest();
produceClient.start();
Future<Session> producerFuture = produceClient.connect(produceSocket, produceUri, produceRequest);
Thread.sleep(1000);
Assert.assertTrue(consumerFuture.get().isOpen());
Assert.assertTrue(producerFuture.get().isOpen());
consumeSocket.awaitClose(1, TimeUnit.SECONDS);
produceSocket.awaitClose(1, TimeUnit.SECONDS);
Assert.assertTrue(produceSocket.getBuffer().size() > 0);
Assert.assertEquals(produceSocket.getBuffer(), consumeSocket.getBuffer());
} finally {
try {
consumeClient.stop();
produceClient.stop();
} catch (Exception e) {
log.error(e.getMessage());
}
}
}",async wait,0
